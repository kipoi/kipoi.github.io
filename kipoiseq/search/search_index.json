{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"index.html","text":"kipoiseq Standard set of data-loaders for training and making predictions for DNA sequence-based models. All dataloaders in kipoiseq.dataloaders decorated with @kipoi_dataloader (SeqIntervalDl and StringSeqIntervalDl) are compatible Kipoi models and can be directly used when specifying a new model in model.yaml : ... default_dataloader: defined_as: kipoiseq.dataloaders.SeqIntervalDl default_args: auto_resize_len: 1000 # override default args in SeqIntervalDl dependencies: pip: - kipoiseq ... Installation pip install kipoiseq Optional dependencies: pip install cyvcf2, pyranges conda install cyvcf2, pyranges Getting started from kipoiseq.dataloaders import SeqIntervalDl dl = SeqIntervalDl.init_example() # use the provided example files # your own files dl = SeqIntervalDl(\"intervals.bed\", \"genome.fa\") len(dl) # length of the dataset dl[0] # get one instance. # returns a dictionary: # dict(inputs=<one-hot-encoded-array>, # targets=<additional columns in the bed file>, # metadata=dict(ranges=GenomicRanges(chr=, start, end)... all = dl.load_all() # load the whole dataset # load batches of data it = dl.batch_iter(32, num_workers=8) # load batches of data in parallel using 8 workers # returns a dictionary with all three keys: inputs, targets, metadata it = dl.batch_train_iter(32, num_workers=8) # returns a tuple: (inputs, targets), can be used directly with keras' `model.fit_generator` More info: - Follow the getting-started colab notebook . - See docs How to write your own data-loaders Read the pytorch Data Loading and Processing Tutorial to become more familiar with transforms and dataloaders Read the code for SeqIntervalDl in kipoiseq/dataloaders/sequence.py you can skip the @kipoi_dataloader and the long yaml doc-string. These are only required if you want to use dataloaders in Kipoi's model.yaml files. Explore the available transforms ( functional , class-based ) or extractors ( kipoiseq , genomelake )","title":"Home"},{"location":"index.html#kipoiseq","text":"Standard set of data-loaders for training and making predictions for DNA sequence-based models. All dataloaders in kipoiseq.dataloaders decorated with @kipoi_dataloader (SeqIntervalDl and StringSeqIntervalDl) are compatible Kipoi models and can be directly used when specifying a new model in model.yaml : ... default_dataloader: defined_as: kipoiseq.dataloaders.SeqIntervalDl default_args: auto_resize_len: 1000 # override default args in SeqIntervalDl dependencies: pip: - kipoiseq ...","title":"kipoiseq"},{"location":"index.html#installation","text":"pip install kipoiseq Optional dependencies: pip install cyvcf2, pyranges conda install cyvcf2, pyranges","title":"Installation"},{"location":"index.html#getting-started","text":"from kipoiseq.dataloaders import SeqIntervalDl dl = SeqIntervalDl.init_example() # use the provided example files # your own files dl = SeqIntervalDl(\"intervals.bed\", \"genome.fa\") len(dl) # length of the dataset dl[0] # get one instance. # returns a dictionary: # dict(inputs=<one-hot-encoded-array>, # targets=<additional columns in the bed file>, # metadata=dict(ranges=GenomicRanges(chr=, start, end)... all = dl.load_all() # load the whole dataset # load batches of data it = dl.batch_iter(32, num_workers=8) # load batches of data in parallel using 8 workers # returns a dictionary with all three keys: inputs, targets, metadata it = dl.batch_train_iter(32, num_workers=8) # returns a tuple: (inputs, targets), can be used directly with keras' `model.fit_generator` More info: - Follow the getting-started colab notebook . - See docs","title":"Getting started"},{"location":"index.html#how-to-write-your-own-data-loaders","text":"Read the pytorch Data Loading and Processing Tutorial to become more familiar with transforms and dataloaders Read the code for SeqIntervalDl in kipoiseq/dataloaders/sequence.py you can skip the @kipoi_dataloader and the long yaml doc-string. These are only required if you want to use dataloaders in Kipoi's model.yaml files. Explore the available transforms ( functional , class-based ) or extractors ( kipoiseq , genomelake )","title":"How to write your own data-loaders"},{"location":"dataloaders.html","text":"BedDataset BedDataset(self, tsv_file, label_dtype=None, bed_columns=3, num_chr=False, ambiguous_mask=None, incl_chromosomes=None, excl_chromosomes=None, ignore_targets=False) Reads a tsv file in the following format: chr start stop task1 task2 ... Arguments tsv_file : tsv file type bed_columns : number of columns corresponding to the bed file. All the columns after that will be parsed as targets num_chr : if specified, 'chr' in the chromosome name will be dropped label_dtype : specific data type for labels, Example: float or np.float32 ambiguous_mask : if specified, rows containing only ambiguous_mask values will be skipped incl_chromosomes : exclusive list of chromosome names to include in the final dataset. if not None, only these will be present in the dataset excl_chromosomes : list of chromosome names to omit from the dataset. ignore_targets : if True, target variables are ignored StringSeqIntervalDl StringSeqIntervalDl(self, intervals_file, fasta_file, num_chr_fasta=False, label_dtype=None, auto_resize_len=None, use_strand=False, force_upper=True, ignore_targets=False) Dataloader for a combination of fasta and tab-delimited input files such as bed files. The dataloader extracts regions from the fasta file as defined in the tab-delimited intervals_file . Returned sequences are of the type np.array([str]). Arguments intervals_file : bed3+ file path containing intervals + (optionally) labels example fasta_file : Reference genome FASTA file path. example num_chr_fasta : True, the the dataloader will make sure that the chromosomes don't start with chr. label_dtype : None, datatype of the task labels taken from the intervals_file. Example - str, int, float, np.float32 auto_resize_len : None, required sequence length. use_strand : reverse-complement fasta sequence if bed file defines negative strand. Requires a bed6 file force_upper : Force uppercase output of sequences ignore_targets : if True, don't return any target variables Output schema inputs : shape=() , DNA sequence as string targets : shape=(None,) , (optional) values following the bed-entries metadata : ranges : Genomic ranges: chr, start, end, name, strand SeqIntervalDl SeqIntervalDl(self, intervals_file, fasta_file, num_chr_fasta=False, label_dtype=None, auto_resize_len=None, use_strand=False, alphabet_axis=1, dummy_axis=None, alphabet='ACGT', ignore_targets=False, dtype=None) Dataloader for a combination of fasta and tab-delimited input files such as bed files. The dataloader extracts regions from the fasta file as defined in the tab-delimited intervals_file and converts them into one-hot encoded format. Returned sequences are of the type np.array with the shape inferred from the arguments: alphabet_axis and dummy_axis . Arguments intervals_file : bed3+ file path containing intervals + (optionally) labels example fasta_file : Reference genome FASTA file path. example num_chr_fasta : True, the the dataloader will make sure that the chromosomes don't start with chr. label_dtype : None, datatype of the task labels taken from the intervals_file. Example: str, int, float, np.float32 auto_resize_len : None, required sequence length. use_strand : reverse-complement fasta sequence if bed file defines negative strand. Requires a bed6 file alphabet_axis : axis along which the alphabet runs (e.g. A,C,G,T for DNA) dummy_axis : defines in which dimension a dummy axis should be added. None if no dummy axis is required. alphabet : alphabet to use for the one-hot encoding. This defines the order of the one-hot encoding. Can either be a list or a string: 'ACGT' or ['A, 'C', 'G', 'T']. Default: 'ACGT' dtype : defines the numpy dtype of the returned array. Example: int, np.int32, np.float32, float ignore_targets : if True, don't return any target variables Output schema inputs : shape=(None, 4) , One-hot encoded DNA sequence targets : shape=(None,) , (optional) values following the bed-entry - chr start end target1 target2 .... metadata : ranges : Genomic ranges: chr, start, end, name, strand AnchoredGTFDl AnchoredGTFDl(self, gtf_file, fasta_file, num_upstream, num_downstream, gtf_filter='gene_type == \"protein_coding\"', anchor='tss', transform=<function one_hot_dna at 0x7fa5a7306ea0>, interval_attrs=['gene_id', 'Strand'], use_strand=True) Dataloader for a combination of fasta and gtf files. The dataloader extracts fixed length regions around anchor points. Anchor points are extracted from the gtf based on the anchor parameter. The sequences corresponding to the region are then extracted from the fasta file and optionally trnasformed using a function given by the transform parameter. Arguments gtf_file : Path to a gtf file (str) example fasta_file : Reference genome FASTA file path (str) example num_upstream : Number of nt by which interval is extended upstream of the anchor point num_downstream : Number of nt by which interval is extended downstream of the anchor point gtf_filter : Allows to filter the gtf before extracting the anchor points. Can be str, callable or None. If str, it is interpreted as argument to pandas .query(). If callable, it is interpreted as function that filters a pandas dataframe and returns the filtered df. anchor : Defines the anchor points. Can be str or callable. If it is a callable, it is treated as function that takes a pandas dataframe and returns a modified version of the dataframe where each row represents one anchor point, the position of which is stored in the column called anchor_pos. If it is a string, a predefined function is loaded. Currently available are tss (anchor is the start of a gene), start_codon (anchor is the start of the start_codon), stop_codon (anchor is the position right after the stop_codon), polya (anchor is the position right after the end of a gene). transform : Callable (or None) to transform the extracted sequence (e.g. one-hot) interval_attrs : Metadata to extract from the gtf, e.g. [\"gene_id\", \"Strand\"] use_strand : True or False Output schema inputs : shape=(None, 4) , exon sequence with flanking intronic sequence targets : metadata : gene_id : gene_id Strand : Strand ranges : Genomic ranges: chr, start, end, name, strand MMSpliceDl MMSpliceDl(self, gtf_file, fasta_file, intron5prime_len=100, intron3prime_len=100, transform=None, **kwargs) Dataloader for splicing models. With inputs as gtf annotation file and fasta file, each output is an exon sequence with flanking intronic seuqences. Intronic sequnce lengths specified by the users. Returned sequences are of the type np.array([str]) Arguments gtf_file : file path; Genome annotation GTF file example fasta_file : Reference Genome sequence in fasta format example intron5prime_len : 5' intronic sequence length to take. intron3prime_len : 3' intronic sequence length to take. transform : transformation operation applied to the returned sequence. It needs to take seq, intron5prime_len and intron3prime_len as arguments. Output schema inputs : shape=() , exon sequence with flanking intronic sequence targets : metadata : geneID : geneID transcriptID : transcriptID ranges : Genomic ranges: chr, start, end, name, strand","title":"Dataloaders"},{"location":"dataloaders.html#beddataset","text":"BedDataset(self, tsv_file, label_dtype=None, bed_columns=3, num_chr=False, ambiguous_mask=None, incl_chromosomes=None, excl_chromosomes=None, ignore_targets=False) Reads a tsv file in the following format: chr start stop task1 task2 ... Arguments tsv_file : tsv file type bed_columns : number of columns corresponding to the bed file. All the columns after that will be parsed as targets num_chr : if specified, 'chr' in the chromosome name will be dropped label_dtype : specific data type for labels, Example: float or np.float32 ambiguous_mask : if specified, rows containing only ambiguous_mask values will be skipped incl_chromosomes : exclusive list of chromosome names to include in the final dataset. if not None, only these will be present in the dataset excl_chromosomes : list of chromosome names to omit from the dataset. ignore_targets : if True, target variables are ignored","title":"BedDataset"},{"location":"dataloaders.html#stringseqintervaldl","text":"StringSeqIntervalDl(self, intervals_file, fasta_file, num_chr_fasta=False, label_dtype=None, auto_resize_len=None, use_strand=False, force_upper=True, ignore_targets=False) Dataloader for a combination of fasta and tab-delimited input files such as bed files. The dataloader extracts regions from the fasta file as defined in the tab-delimited intervals_file . Returned sequences are of the type np.array([str]). Arguments intervals_file : bed3+ file path containing intervals + (optionally) labels example fasta_file : Reference genome FASTA file path. example num_chr_fasta : True, the the dataloader will make sure that the chromosomes don't start with chr. label_dtype : None, datatype of the task labels taken from the intervals_file. Example - str, int, float, np.float32 auto_resize_len : None, required sequence length. use_strand : reverse-complement fasta sequence if bed file defines negative strand. Requires a bed6 file force_upper : Force uppercase output of sequences ignore_targets : if True, don't return any target variables Output schema inputs : shape=() , DNA sequence as string targets : shape=(None,) , (optional) values following the bed-entries metadata : ranges : Genomic ranges: chr, start, end, name, strand","title":"StringSeqIntervalDl"},{"location":"dataloaders.html#seqintervaldl","text":"SeqIntervalDl(self, intervals_file, fasta_file, num_chr_fasta=False, label_dtype=None, auto_resize_len=None, use_strand=False, alphabet_axis=1, dummy_axis=None, alphabet='ACGT', ignore_targets=False, dtype=None) Dataloader for a combination of fasta and tab-delimited input files such as bed files. The dataloader extracts regions from the fasta file as defined in the tab-delimited intervals_file and converts them into one-hot encoded format. Returned sequences are of the type np.array with the shape inferred from the arguments: alphabet_axis and dummy_axis . Arguments intervals_file : bed3+ file path containing intervals + (optionally) labels example fasta_file : Reference genome FASTA file path. example num_chr_fasta : True, the the dataloader will make sure that the chromosomes don't start with chr. label_dtype : None, datatype of the task labels taken from the intervals_file. Example: str, int, float, np.float32 auto_resize_len : None, required sequence length. use_strand : reverse-complement fasta sequence if bed file defines negative strand. Requires a bed6 file alphabet_axis : axis along which the alphabet runs (e.g. A,C,G,T for DNA) dummy_axis : defines in which dimension a dummy axis should be added. None if no dummy axis is required. alphabet : alphabet to use for the one-hot encoding. This defines the order of the one-hot encoding. Can either be a list or a string: 'ACGT' or ['A, 'C', 'G', 'T']. Default: 'ACGT' dtype : defines the numpy dtype of the returned array. Example: int, np.int32, np.float32, float ignore_targets : if True, don't return any target variables Output schema inputs : shape=(None, 4) , One-hot encoded DNA sequence targets : shape=(None,) , (optional) values following the bed-entry - chr start end target1 target2 .... metadata : ranges : Genomic ranges: chr, start, end, name, strand","title":"SeqIntervalDl"},{"location":"dataloaders.html#anchoredgtfdl","text":"AnchoredGTFDl(self, gtf_file, fasta_file, num_upstream, num_downstream, gtf_filter='gene_type == \"protein_coding\"', anchor='tss', transform=<function one_hot_dna at 0x7fa5a7306ea0>, interval_attrs=['gene_id', 'Strand'], use_strand=True) Dataloader for a combination of fasta and gtf files. The dataloader extracts fixed length regions around anchor points. Anchor points are extracted from the gtf based on the anchor parameter. The sequences corresponding to the region are then extracted from the fasta file and optionally trnasformed using a function given by the transform parameter. Arguments gtf_file : Path to a gtf file (str) example fasta_file : Reference genome FASTA file path (str) example num_upstream : Number of nt by which interval is extended upstream of the anchor point num_downstream : Number of nt by which interval is extended downstream of the anchor point gtf_filter : Allows to filter the gtf before extracting the anchor points. Can be str, callable or None. If str, it is interpreted as argument to pandas .query(). If callable, it is interpreted as function that filters a pandas dataframe and returns the filtered df. anchor : Defines the anchor points. Can be str or callable. If it is a callable, it is treated as function that takes a pandas dataframe and returns a modified version of the dataframe where each row represents one anchor point, the position of which is stored in the column called anchor_pos. If it is a string, a predefined function is loaded. Currently available are tss (anchor is the start of a gene), start_codon (anchor is the start of the start_codon), stop_codon (anchor is the position right after the stop_codon), polya (anchor is the position right after the end of a gene). transform : Callable (or None) to transform the extracted sequence (e.g. one-hot) interval_attrs : Metadata to extract from the gtf, e.g. [\"gene_id\", \"Strand\"] use_strand : True or False Output schema inputs : shape=(None, 4) , exon sequence with flanking intronic sequence targets : metadata : gene_id : gene_id Strand : Strand ranges : Genomic ranges: chr, start, end, name, strand","title":"AnchoredGTFDl"},{"location":"dataloaders.html#mmsplicedl","text":"MMSpliceDl(self, gtf_file, fasta_file, intron5prime_len=100, intron3prime_len=100, transform=None, **kwargs) Dataloader for splicing models. With inputs as gtf annotation file and fasta file, each output is an exon sequence with flanking intronic seuqences. Intronic sequnce lengths specified by the users. Returned sequences are of the type np.array([str]) Arguments gtf_file : file path; Genome annotation GTF file example fasta_file : Reference Genome sequence in fasta format example intron5prime_len : 5' intronic sequence length to take. intron3prime_len : 3' intronic sequence length to take. transform : transformation operation applied to the returned sequence. It needs to take seq, intron5prime_len and intron3prime_len as arguments. Output schema inputs : shape=() , exon sequence with flanking intronic sequence targets : metadata : geneID : geneID transcriptID : transcriptID ranges : Genomic ranges: chr, start, end, name, strand","title":"MMSpliceDl"},{"location":"extractors.html","text":"MultiSampleVCF MultiSampleVCF(self, *args, **kwargs) NumberVariantQuery NumberVariantQuery(self, max_num=inf, min_num=0) Closure for variant query. Filter variants for interval if number of variants in given limits. VariantIntervalQueryable VariantIntervalQueryable(self, vcf, variant_intervals:List[Tuple[Iterable[kipoiseq.dataclasses.Variant], kipoiseq.dataclasses.Interval]], progress=False) IntervalSeqBuilder IntervalSeqBuilder(self, /, *args, **kwargs) String builder for pyfaidx.Sequence and Interval objects. VariantSeqExtractor VariantSeqExtractor(self, fasta_file:str=None, reference_sequence:kipoiseq.extractors.base.BaseExtractor=None) SingleVariantVCFSeqExtractor SingleVariantVCFSeqExtractor(self, fasta_file, vcf_file) Fetch list of sequence in which each variant applied based on given vcf file. SingleSeqVCFSeqExtractor SingleSeqVCFSeqExtractor(self, fasta_file, vcf_file) Fetch sequence in which all variant applied based on given vcf file. variants_to_pyranges variants_to_pyranges(variants:List[kipoiseq.dataclasses.Variant]) -> pyranges.pyranges.PyRanges Create pyrange object given list of variant objects. Args: variants: list of variant objects have CHROM, POS, REF, ALT properties. BaseVariantMatcher BaseVariantMatcher(self, vcf_file:str, gtf_path:str=None, bed_path:str=None, pranges:pyranges.pyranges.PyRanges=None, intervals:List[kipoiseq.dataclasses.Interval]=None, interval_attrs:List[str]=None, vcf_lazy:bool=True, variant_batch_size:int=10000) Base variant intervals matcher SingleVariantMatcher SingleVariantMatcher(self, *args, **kwargs) Match and iterate variants with intervals.","title":"Extractors"},{"location":"extractors.html#multisamplevcf","text":"MultiSampleVCF(self, *args, **kwargs)","title":"MultiSampleVCF"},{"location":"extractors.html#numbervariantquery","text":"NumberVariantQuery(self, max_num=inf, min_num=0) Closure for variant query. Filter variants for interval if number of variants in given limits.","title":"NumberVariantQuery"},{"location":"extractors.html#variantintervalqueryable","text":"VariantIntervalQueryable(self, vcf, variant_intervals:List[Tuple[Iterable[kipoiseq.dataclasses.Variant], kipoiseq.dataclasses.Interval]], progress=False)","title":"VariantIntervalQueryable"},{"location":"extractors.html#intervalseqbuilder","text":"IntervalSeqBuilder(self, /, *args, **kwargs) String builder for pyfaidx.Sequence and Interval objects.","title":"IntervalSeqBuilder"},{"location":"extractors.html#variantseqextractor","text":"VariantSeqExtractor(self, fasta_file:str=None, reference_sequence:kipoiseq.extractors.base.BaseExtractor=None)","title":"VariantSeqExtractor"},{"location":"extractors.html#singlevariantvcfseqextractor","text":"SingleVariantVCFSeqExtractor(self, fasta_file, vcf_file) Fetch list of sequence in which each variant applied based on given vcf file.","title":"SingleVariantVCFSeqExtractor"},{"location":"extractors.html#singleseqvcfseqextractor","text":"SingleSeqVCFSeqExtractor(self, fasta_file, vcf_file) Fetch sequence in which all variant applied based on given vcf file.","title":"SingleSeqVCFSeqExtractor"},{"location":"extractors.html#variants_to_pyranges","text":"variants_to_pyranges(variants:List[kipoiseq.dataclasses.Variant]) -> pyranges.pyranges.PyRanges Create pyrange object given list of variant objects. Args: variants: list of variant objects have CHROM, POS, REF, ALT properties.","title":"variants_to_pyranges"},{"location":"extractors.html#basevariantmatcher","text":"BaseVariantMatcher(self, vcf_file:str, gtf_path:str=None, bed_path:str=None, pranges:pyranges.pyranges.PyRanges=None, intervals:List[kipoiseq.dataclasses.Interval]=None, interval_attrs:List[str]=None, vcf_lazy:bool=True, variant_batch_size:int=10000) Base variant intervals matcher","title":"BaseVariantMatcher"},{"location":"extractors.html#singlevariantmatcher","text":"SingleVariantMatcher(self, *args, **kwargs) Match and iterate variants with intervals.","title":"SingleVariantMatcher"},{"location":"transforms/functional.html","text":"one_hot2string one_hot2string(arr, alphabet=['A', 'C', 'G', 'T']) Convert a one-hot encoded array back to string rc_dna rc_dna(seq) Reverse complement the DNA sequence assert rc_seq(\"TATCG\") == \"CGATA\" assert rc_seq(\"tatcg\") == \"cgata\" rc_rna rc_rna(seq) Reverse complement the RNA sequence assert rc_seq(\"TATCG\") == \"CGATA\" tokenize tokenize(seq, alphabet=['A', 'C', 'G', 'T'], neutral_alphabet=['N']) Convert sequence to integers Arguments seq : Sequence to encode alphabet : Alphabet to use neutral_alphabet : Neutral alphabet -> assign those values to -1 Returns List of length len(seq) with integers from -1 to len(alphabet) - 1 token2one_hot token2one_hot(tokens, alphabet_size=4, neutral_value=0.25, dtype=None) Note: everything out of the alphabet is transformed into np.zeros(alphabet_size) one_hot_dna one_hot_dna(seq, dtype=None) One-hot encode DNA sequence fixed_len fixed_len(seq, length, anchor='center', value='N') Pad and/or trim a list of sequences to have common length. Procedure: Pad the sequence with N's or any other string or list element ( value ) Subset the sequence Note See also: https://keras.io/preprocessing/sequence/ Aplicable also for lists of characters Arguments sequence_vec : list of chars or lists List of sequences that can have various lengths value : Neutral element to pad the sequence with. Can be str or list . length : int or None; Final lenght of sequences. If None, length is set to the longest sequence length. anchor : character; 'start', 'end' or 'center' To which end to anchor the sequences when triming/padding. See examples bellow. Returns List of sequences of the same class as sequence_vec Example >>> sequence = 'CTTACTCAGA' >>> pad_sequence(sequence, 10, anchor=\"start\", value=\"N\") 'CTTACTCAGA' >>> pad_sequence(sequence, 10, anchor=\"end\", value=\"N\") 'CTTACTCAGA' >>> pad_sequences(sequence, 4, anchor=\"center\", value=\"N\") 'ACTC' >>> sequence = 'TCTTTA' >>> pad_sequence(sequence, 10, anchor=\"start\", value=\"N\") 'TCTTTANNNN' >>> pad_sequence(sequence, 10, anchor=\"end\", value=\"N\") 'NNNNTCTTTA' >>> pad_sequences(sequence, 4, anchor=\"center\", value=\"N\") 'CTTT' resize_interval resize_interval(interval, width, anchor='center') Resize the Interval. Returns new Interval instance with correct length. Arguments: interval: pybedtools.Interval object or an object containing start and end attributes width: desired width of the output interval anchor (str): which part of the sequence should be anchored. Choices: 'start', 'center', or 'end' translate translate(seq:str, hg38=False) Translate the DNA/RNA sequence into AA. Note: it stops after it encounters a stop codon Arguments seq : DNA/RNA sequence stop_none : return None if a stop codon is encountered","title":"Functional"},{"location":"transforms/functional.html#one_hot2string","text":"one_hot2string(arr, alphabet=['A', 'C', 'G', 'T']) Convert a one-hot encoded array back to string","title":"one_hot2string"},{"location":"transforms/functional.html#rc_dna","text":"rc_dna(seq) Reverse complement the DNA sequence assert rc_seq(\"TATCG\") == \"CGATA\" assert rc_seq(\"tatcg\") == \"cgata\"","title":"rc_dna"},{"location":"transforms/functional.html#rc_rna","text":"rc_rna(seq) Reverse complement the RNA sequence assert rc_seq(\"TATCG\") == \"CGATA\"","title":"rc_rna"},{"location":"transforms/functional.html#tokenize","text":"tokenize(seq, alphabet=['A', 'C', 'G', 'T'], neutral_alphabet=['N']) Convert sequence to integers Arguments seq : Sequence to encode alphabet : Alphabet to use neutral_alphabet : Neutral alphabet -> assign those values to -1 Returns List of length len(seq) with integers from -1 to len(alphabet) - 1","title":"tokenize"},{"location":"transforms/functional.html#token2one_hot","text":"token2one_hot(tokens, alphabet_size=4, neutral_value=0.25, dtype=None) Note: everything out of the alphabet is transformed into np.zeros(alphabet_size)","title":"token2one_hot"},{"location":"transforms/functional.html#one_hot_dna","text":"one_hot_dna(seq, dtype=None) One-hot encode DNA sequence","title":"one_hot_dna"},{"location":"transforms/functional.html#fixed_len","text":"fixed_len(seq, length, anchor='center', value='N') Pad and/or trim a list of sequences to have common length. Procedure: Pad the sequence with N's or any other string or list element ( value ) Subset the sequence Note See also: https://keras.io/preprocessing/sequence/ Aplicable also for lists of characters Arguments sequence_vec : list of chars or lists List of sequences that can have various lengths value : Neutral element to pad the sequence with. Can be str or list . length : int or None; Final lenght of sequences. If None, length is set to the longest sequence length. anchor : character; 'start', 'end' or 'center' To which end to anchor the sequences when triming/padding. See examples bellow. Returns List of sequences of the same class as sequence_vec Example >>> sequence = 'CTTACTCAGA' >>> pad_sequence(sequence, 10, anchor=\"start\", value=\"N\") 'CTTACTCAGA' >>> pad_sequence(sequence, 10, anchor=\"end\", value=\"N\") 'CTTACTCAGA' >>> pad_sequences(sequence, 4, anchor=\"center\", value=\"N\") 'ACTC' >>> sequence = 'TCTTTA' >>> pad_sequence(sequence, 10, anchor=\"start\", value=\"N\") 'TCTTTANNNN' >>> pad_sequence(sequence, 10, anchor=\"end\", value=\"N\") 'NNNNTCTTTA' >>> pad_sequences(sequence, 4, anchor=\"center\", value=\"N\") 'CTTT'","title":"fixed_len"},{"location":"transforms/functional.html#resize_interval","text":"resize_interval(interval, width, anchor='center') Resize the Interval. Returns new Interval instance with correct length. Arguments: interval: pybedtools.Interval object or an object containing start and end attributes width: desired width of the output interval anchor (str): which part of the sequence should be anchored. Choices: 'start', 'center', or 'end'","title":"resize_interval"},{"location":"transforms/functional.html#translate","text":"translate(seq:str, hg38=False) Translate the DNA/RNA sequence into AA. Note: it stops after it encounters a stop codon Arguments seq : DNA/RNA sequence stop_none : return None if a stop codon is encountered","title":"translate"},{"location":"transforms/transforms.html","text":"Compose Compose(self, transforms) Composes several transforms together. Arguments transforms (list of Transform objects) : list of transforms to compose. Example : >>> transforms.Compose([ >>> transforms.CenterCrop(10), >>> transforms.ToTensor(), >>> ]) DummyAxis DummyAxis(self, axis=None) np.expand_dims wrapper - Insert a dummy axis (calls np.expand_dims) SwapAxes SwapAxes(self, axis1=None, axis2=None) np.swapaxes wrapper If any if the axis is None, do nothing. ResizeInterval ResizeInterval(self, width, anchor='center') Resize the interval OneHot OneHot(self, alphabet=['A', 'C', 'G', 'T'], neutral_alphabet='N', neutral_value=0.25, dtype=None) One-hot encode the sequence Arguments alphabet : alphabet to use for the one-hot encoding. This defines the order of the one-hot encoding. Can either be a list or a string : 'ACGT' or ['A, 'C', 'G', 'T'] neutral_alphabet : which element to use neutral_value : value of the neutral element dtype : defines the numpy dtype of the returned array. alphabet_axis : axis along which the alphabet runs (e.g. A,C,G,T for DNA) dummy_axis : defines in which dimension a dummy axis should be added. None if no dummy axis is required. ReorderedOneHot ReorderedOneHot(self, alphabet=['A', 'C', 'G', 'T'], neutral_alphabet='N', neutral_value=0.25, dtype=None, alphabet_axis=1, dummy_axis=None) Flexible one-hot encoding class that can account for many different one-hot encoding formats. Arguments alphabet : alphabet to use for the one-hot encoding. This defines the order of the one-hot encoding. Can either be a list or a string : 'ACGT' or ['A, 'C', 'G', 'T'] neutral_alphabet : (single string character) neutral element representing neutral_value : value of the neutral element dtype : defines the numpy dtype of the returned array. alphabet_axis : axis along which the alphabet runs (e.g. A,C,G,T for DNA) dummy_axis : defines in which dimension a dummy axis should be added. None if no dummy axis is required. Examples ( None = sequence axis) : - (None, 4) : default - (4, None) : alphabet_axis=0 - (4, 1, None) : alphabet_axis=0, dummy_axis=1 SplitSplicingSeq SplitSplicingSeq(self, exon_cut_l=0, exon_cut_r=0, intron5prime_cut=6, intron3prime_cut=6, acceptor_intron_len=50, acceptor_exon_len=3, donor_exon_len=5, donor_intron_len=13) Split returned splice sequence (exon with flanking intron) to required format. It splits into ['intron5prime', 'acceptor', 'exon', 'donor', 'intron3prime']. 'intron5prime' is the intron 5' of the exon, while 'intron3prime' is from the 3'. Arguments exon_cut_l : when extract exon feature, how many base pair to cut out at the begining of an exon exon_cut_r : when extract exon feature, how many base pair to cut out at the end of an exon (cut out the part that is considered as acceptor site or donor site) intron5prime_cut : how many bp to cut out at the end of acceptor intron that consider as acceptor site intron3prime_cut : how many bp to cut out at the end of donor intron that consider as donor site acceptor_intron_len : what length in acceptor intron to consider for acceptor site model acceptor_exon_len : what length in acceptor exon to consider for acceptor site model donor_intron_len : what length in donor intron to consider for donor site model donor_exon_len : what length in donor exon to consider for donor site model","title":"Class-based"},{"location":"transforms/transforms.html#compose","text":"Compose(self, transforms) Composes several transforms together. Arguments transforms (list of Transform objects) : list of transforms to compose. Example : >>> transforms.Compose([ >>> transforms.CenterCrop(10), >>> transforms.ToTensor(), >>> ])","title":"Compose"},{"location":"transforms/transforms.html#dummyaxis","text":"DummyAxis(self, axis=None) np.expand_dims wrapper - Insert a dummy axis (calls np.expand_dims)","title":"DummyAxis"},{"location":"transforms/transforms.html#swapaxes","text":"SwapAxes(self, axis1=None, axis2=None) np.swapaxes wrapper If any if the axis is None, do nothing.","title":"SwapAxes"},{"location":"transforms/transforms.html#resizeinterval","text":"ResizeInterval(self, width, anchor='center') Resize the interval","title":"ResizeInterval"},{"location":"transforms/transforms.html#onehot","text":"OneHot(self, alphabet=['A', 'C', 'G', 'T'], neutral_alphabet='N', neutral_value=0.25, dtype=None) One-hot encode the sequence Arguments alphabet : alphabet to use for the one-hot encoding. This defines the order of the one-hot encoding. Can either be a list or a string : 'ACGT' or ['A, 'C', 'G', 'T'] neutral_alphabet : which element to use neutral_value : value of the neutral element dtype : defines the numpy dtype of the returned array. alphabet_axis : axis along which the alphabet runs (e.g. A,C,G,T for DNA) dummy_axis : defines in which dimension a dummy axis should be added. None if no dummy axis is required.","title":"OneHot"},{"location":"transforms/transforms.html#reorderedonehot","text":"ReorderedOneHot(self, alphabet=['A', 'C', 'G', 'T'], neutral_alphabet='N', neutral_value=0.25, dtype=None, alphabet_axis=1, dummy_axis=None) Flexible one-hot encoding class that can account for many different one-hot encoding formats. Arguments alphabet : alphabet to use for the one-hot encoding. This defines the order of the one-hot encoding. Can either be a list or a string : 'ACGT' or ['A, 'C', 'G', 'T'] neutral_alphabet : (single string character) neutral element representing neutral_value : value of the neutral element dtype : defines the numpy dtype of the returned array. alphabet_axis : axis along which the alphabet runs (e.g. A,C,G,T for DNA) dummy_axis : defines in which dimension a dummy axis should be added. None if no dummy axis is required. Examples ( None = sequence axis) : - (None, 4) : default - (4, None) : alphabet_axis=0 - (4, 1, None) : alphabet_axis=0, dummy_axis=1","title":"ReorderedOneHot"},{"location":"transforms/transforms.html#splitsplicingseq","text":"SplitSplicingSeq(self, exon_cut_l=0, exon_cut_r=0, intron5prime_cut=6, intron3prime_cut=6, acceptor_intron_len=50, acceptor_exon_len=3, donor_exon_len=5, donor_intron_len=13) Split returned splice sequence (exon with flanking intron) to required format. It splits into ['intron5prime', 'acceptor', 'exon', 'donor', 'intron3prime']. 'intron5prime' is the intron 5' of the exon, while 'intron3prime' is from the 3'. Arguments exon_cut_l : when extract exon feature, how many base pair to cut out at the begining of an exon exon_cut_r : when extract exon feature, how many base pair to cut out at the end of an exon (cut out the part that is considered as acceptor site or donor site) intron5prime_cut : how many bp to cut out at the end of acceptor intron that consider as acceptor site intron3prime_cut : how many bp to cut out at the end of donor intron that consider as donor site acceptor_intron_len : what length in acceptor intron to consider for acceptor site model acceptor_exon_len : what length in acceptor exon to consider for acceptor site model donor_intron_len : what length in donor intron to consider for donor site model donor_exon_len : what length in donor exon to consider for donor site model","title":"SplitSplicingSeq"}]}