<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  
  
  <link rel="shortcut icon" href="../../img/favicon.ico">
  <title>Contributing models - Kipoi documentation</title>
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700" />

  <link rel="stylesheet" href="../../css/theme.css" />
  <link rel="stylesheet" href="../../css/theme_extra.css" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/styles/github.min.css" />
  
  <script>
    // Current page data
    var mkdocs_page_name = "Contributing models";
    var mkdocs_page_input_path = "tutorials/contributing_models.md";
    var mkdocs_page_url = null;
  </script>
  
  <script src="../../js/jquery-2.1.1.min.js" defer></script>
  <script src="../../js/modernizr-2.8.3.min.js" defer></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
        <a href="../.." class="icon icon-home"> Kipoi documentation</a>
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
                <ul>
                    <li class="toctree-l1"><a class="reference internal" href="../..">Home</a>
                    </li>
                </ul>
                <p class="caption"><span class="caption-text">Using</span></p>
                <ul>
                    <li class="toctree-l1"><a class="reference internal" href="../../using/python/">Python</a>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../../using/cli/">CLI</a>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../../using/R/">R</a>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../../using/plugins/">Plugins</a>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../../using/03_Model_sources/">Private and public model sources</a>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../../using/04_Installing_on_OSX/">Installing on OSX</a>
                    </li>
                </ul>
                <p class="caption"><span class="caption-text">Contributing</span></p>
                <ul>
                    <li class="toctree-l1"><a class="reference internal" href="../../contributing/01_Getting_started/">Getting started</a>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../../contributing/02_Writing_model.yaml/">model.yaml</a>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../../contributing/04_Writing_dataloader.py/">dataloader.py</a>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../../contributing/03_Writing_dataloader.yaml/">dataloader.yaml</a>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../../contributing/05_Writing_model.py/">model.py</a>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../../contributing/06_dumping_models_programatically/">Multiple very similar models</a>
                    </li>
                </ul>
                <p class="caption"><span class="caption-text">Tutorials</span></p>
                <ul class="current">
                    <li class="toctree-l1 current"><a class="reference internal current" href="./">Contributing models</a>
    <ul class="current">
    <li class="toctree-l2"><a class="reference internal" href="#kipoi-basics">Kipoi basics</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#model">Model</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#dataloader">Dataloader</a>
        <ul>
    <li class="toctree-l4"><a class="reference internal" href="#writing-your-own-dataloader">Writing your own dataloader</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#folder-layout">Folder layout</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#contributing-a-simple-iris-classifier">Contributing a simple Iris-classifier</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#outline">Outline</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#1-train-the-model">1. Train the model</a>
        <ul>
    <li class="toctree-l4"><a class="reference internal" href="#load-and-pre-process-the-data">Load and pre-process the data</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#train-an-example-model">Train an example model</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#2-set-the-model-directory-up">2. Set the model directory up:</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#3-store-the-files-in-a-temporary-directory">3. Store the files in a temporary directory</a>
        <ul>
    <li class="toctree-l4"><a class="reference internal" href="#3a-static-files-for-dataloader">3a. Static files for dataloader</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#3b-model-definition-weights">3b. Model definition / weights</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#3c-example-files-for-the-dataloader">3c. Example files for the dataloader</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#4-write-the-modelyaml">4 Write the model.yaml</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#5-and-6-write-the-dataloaderyaml-and-dataloaderpy">5 and 6 Write the dataloader.yaml and dataloader.py</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#7-test-the-model">7 Test the model</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#8-publish-data-on-zenodo-or-figshare">8. Publish data on zenodo or figshare</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#9-update-modelyaml-and-dataloaderyaml">9 Update model.yaml and dataloader.yaml</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#9-test-again">9 Test again</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#10-commit-and-push">10 Commit and push</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#accessing-local-models-through-kipoi">Accessing local models through kipoi</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#best-practices">Best practices</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#recap">Recap</a>
    </li>
    </ul>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../python-api/">Python API</a>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../R-api/">R API</a>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../tf_binding_models/">Comparing models</a>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../composing_models/">Composing models</a>
                    </li>
                </ul>
                <ul>
                    <li class="toctree-l1"><a class="reference internal" href="../../faq/">FAQ</a>
                    </li>
                </ul>
                <p class="caption"><span class="caption-text">Api</span></p>
                <ul>
                    <li class="toctree-l1"><a class="reference internal" href="../../api/list_/">list</a>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../../api/install_/">install</a>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../../api/model/">Model</a>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../../api/dataloader/">Dataloader</a>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../../api/pipeline/">Pipeline</a>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../../api/sources/">sources</a>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../../api/metadata/">metadata</a>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../../api/readers/">readers</a>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../../api/writers/">writers</a>
                    </li>
                </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="../..">Kipoi documentation</a>
      </nav>

      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../..">Docs</a> &raquo;</li>
    
      
        
          <li>Tutorials &raquo;</li>
        
      
    
    <li>Contributing models</li>
    <li class="wy-breadcrumbs-aside">
      
        <a href="http://github.com/kipoi/kipoi/edit/master/docs/tutorials/contributing_models.md"
          class="icon icon-github"> Edit on GitHub</a>
      
    </li>
  </ul>
  
  <hr/>
</div>

          <div role="main">
            <div class="section">
              
                <p>Generated from <a href="https://github.com/kipoi/kipoi/blob/master/notebooks/contributing_models.ipynb">notebooks/contributing_models.ipynb</a></p>
<h1 id="contributing-a-model-to-the-kipoi-model-repository">Contributing a model to the Kipoi model repository</h1>
<p>This notebook will show you how to contribute a model to the <a href="https://github.com/kipoi/models">Kipoi model repository</a>. For a simple 'model contribution checklist' see also <a href="http://kipoi.org/docs/contributing/01_Getting_started">http://kipoi.org/docs/contributing/01_Getting_started</a>.</p>
<h2 id="kipoi-basics">Kipoi basics</h2>
<p>Contributing a model to Kipoi means writing a sub-folder with all the required files to the <a href="https://github.com/kipoi/models">Kipoi model repository</a> via pull request.</p>
<p>Two main components of the model repository are <strong>model</strong> and <strong>dataloader</strong>.</p>
<p><img alt="img" src="/docs/img/kipoi-workflow.png" /></p>
<h3 id="model">Model</h3>
<p>Model takes as input numpy arrays and outputs numpy arrays. In practice, a model needs to implement the <code>predict_on_batch(x)</code> method, where <code>x</code> is dictionary/list of numpy arrays. The model contributor needs to provide one of the following:</p>
<ul>
<li>Serialized Keras model</li>
<li>Serialized Sklearn model</li>
<li>Custom model inheriting from <code>keras.model.BaseModel</code>.</li>
<li>all the required files, i.e. weights need to be loaded in the <code>__init__</code></li>
</ul>
<p>See <a href="http://kipoi.org/docs/contributing/02_Writing_model.yaml/">http://kipoi.org/docs/contributing/02_Writing_model.yaml/</a> and <a href="http://kipoi.org/docs/contributing/05_Writing_model.py/">http://kipoi.org/docs/contributing/05_Writing_model.py/</a> for more info.</p>
<h3 id="dataloader">Dataloader</h3>
<p>Dataloader takes raw file paths or other parameters as argument and outputs modelling-ready numpy arrays. </p>
<p>Before writing your own dataloader take a look at our <a href="https://github.com/kipoi/kipoiseq">kipoiseq</a> repository to see whether your use-case is covered by the available dataloaders.</p>
<h4 id="writing-your-own-dataloader">Writing your own dataloader</h4>
<p>Technically, dataloading can be done through a generator---batch-by-batch, sample-by-sample---or by just returning the whole dataset. The goal is to work really with raw files (say fasta, bed, vcf, etc in bioinformatics), as this allows to make model predictions on new datasets without going through the burden of running custom pre-processing scripts. The model contributor needs to implement one of the following:</p>
<ul>
<li>PreloadedDataset</li>
<li>Dataset</li>
<li>BatchDataset</li>
<li>SampleIterator</li>
<li>BatchIterator</li>
<li>SampleGenerator</li>
<li>BatchGenerator</li>
</ul>
<p>See <a href="http://kipoi.org/docs/contributing/04_Writing_dataloader.py/">http://kipoi.org/docs/contributing/04_Writing_dataloader.py/</a> for more info.</p>
<h3 id="folder-layout">Folder layout</h3>
<p>Here is an example folder structure of a Kipoi model:</p>
<pre><code>MyModel
├── dataloader.py     # implements the dataloader (only necessary if you wrote your own dataloader)
├── dataloader.yaml   # describes the dataloader (only necessary if you wrote your own dataloader)
└── model.yaml         # describes the model
</code></pre>
<p>The <code>model.yaml</code> and <code>dataloader.yaml</code> files a complete description about the model, the dataloader and the files they depend on.</p>
<h2 id="contributing-a-simple-iris-classifier">Contributing a simple Iris-classifier</h2>
<p>Details about the individual files will be revealed throught the tutorial below. A simple Keras model will be trained to predict the Iris plant class from the well-known <a href="archive.ics.uci.edu/ml/datasets/Iris">Iris</a> dataset.</p>
<h3 id="outline">Outline</h3>
<ol>
<li>Train the model</li>
<li>Generate the model directory</li>
<li>Store all data files required for the model and the dataloader in a temporary folder</li>
<li>Write <code>model.yaml</code></li>
<li>Write <code>dataloader.yaml</code></li>
<li>Write <code>dataloader.py</code></li>
<li>Test with the model with <code>$ kipoi test .</code></li>
<li>Publish data files on zenodo</li>
<li>Update <code>model.yaml</code> and <code>dataloader.yaml</code> to contain the links</li>
<li>Test again</li>
<li>Commit, push and generate a pull request</li>
</ol>
<h3 id="1-train-the-model">1. Train the model</h3>
<h4 id="load-and-pre-process-the-data">Load and pre-process the data</h4>
<pre><code class="language-python">import pandas as pd
import os
from sklearn.preprocessing import LabelBinarizer, StandardScaler

from sklearn import datasets
iris = datasets.load_iris()
</code></pre>
<pre><code class="language-python"># view more info about the dataset
# print(iris[&quot;DESCR&quot;])
</code></pre>
<pre><code class="language-python"># Data pre-processing
y_transformer = LabelBinarizer().fit(iris[&quot;target&quot;])
x_transformer = StandardScaler().fit(iris[&quot;data&quot;])
</code></pre>
<pre><code class="language-python">x = x_transformer.transform(iris[&quot;data&quot;])
y = y_transformer.transform(iris[&quot;target&quot;])
</code></pre>
<pre><code class="language-python">x[:3]
</code></pre>
<pre><code>array([[-0.90068117,  1.03205722, -1.3412724 , -1.31297673],
       [-1.14301691, -0.1249576 , -1.3412724 , -1.31297673],
       [-1.38535265,  0.33784833, -1.39813811, -1.31297673]])
</code></pre>
<pre><code class="language-python">y[:3]
</code></pre>
<pre><code>array([[1, 0, 0],
       [1, 0, 0],
       [1, 0, 0]])
</code></pre>
<h4 id="train-an-example-model">Train an example model</h4>
<p>Let's train a simple linear-regression model using Keras.</p>
<pre><code class="language-python">from keras.models import Model
import keras.layers as kl

inp = kl.Input(shape=(4, ), name=&quot;features&quot;)
out = kl.Dense(units=3)(inp)
model = Model(inp, out)
model.compile(&quot;adam&quot;, &quot;categorical_crossentropy&quot;)

model.fit(x, y, verbose=0)
</code></pre>
<pre><code>Using TensorFlow backend.


WARNING:tensorflow:From /nfs/research1/stegle/users/rkreuzhu/conda-envs/kipoi_interpret/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:2857: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead
WARNING:tensorflow:From /nfs/research1/stegle/users/rkreuzhu/conda-envs/kipoi_interpret/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1340: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead





&lt;keras.callbacks.History at 0x2ab58e8ba860&gt;
</code></pre>
<h3 id="2-set-the-model-directory-up">2. Set the model directory up:</h3>
<p>In reality, you would also need to </p>
<ol>
<li>Fork the <a href="https://github.com/kipoi/models">kipoi/models repository</a></li>
<li>Clone your repository fork, ignoring all the git-lfs files<ul>
<li><code>$ git clone git@github.com:&lt;your_username&gt;/models.git</code></li>
</ul>
</li>
<li>Create a new folder <code>&lt;mynewmodel&gt;</code></li>
</ol>
<h3 id="3-store-the-files-in-a-temporary-directory">3. Store the files in a temporary directory</h3>
<p>All the data of the model will have to be published on zenodo or figshare before the pull request is performed. While setting the Kipoi model up, it is handy the keep the models in a temporary directory in the model folder, which we will delete prior to the pull request.</p>
<pre><code class="language-python"># create the model directory
!mkdir contribution_sample_model
# create the temporary directory where we will keep the files that should later be published in zenodo or figshare
!mkdir contribution_sample_model/tmp
</code></pre>
<p>Now we can change the current working directory to the model directory:</p>
<pre><code class="language-python">import os
os.chdir(&quot;contribution_sample_model&quot;)
</code></pre>
<h4 id="3a-static-files-for-dataloader">3a. Static files for dataloader</h4>
<p>Since in our case here we require to write a new dataloader. The dataloader can use some trained transformer instances (here the <code>LabelBinarizer</code> and <code>StandardScaler</code> transformers form sklearn). These should be uploaded with the model files and then referenced correctly in the <code>dataloader.yaml</code> file. We will store the required files in the temporary folder:</p>
<pre><code class="language-python">import pickle
</code></pre>
<pre><code class="language-python">with open(&quot;tmp/y_transformer.pkl&quot;, &quot;wb&quot;) as f:
    pickle.dump(y_transformer, f, protocol=2)

with open(&quot;tmp/x_transformer.pkl&quot;, &quot;wb&quot;) as f:
    pickle.dump(x_transformer, f, protocol=2)
</code></pre>
<pre><code class="language-python">! ls tmp
</code></pre>
<pre><code>x_transformer.pkl  y_transformer.pkl
</code></pre>
<h4 id="3b-model-definition-weights">3b. Model definition / weights</h4>
<p>Now that we have the static files that are required by the dataloader, we also need to store the model architecture and weights:</p>
<pre><code class="language-python"># Architecture
with open(&quot;tmp/model.json&quot;, &quot;w&quot;) as f:
    f.write(model.to_json())

# Weights
model.save_weights(&quot;tmp/weights.h5&quot;)
</code></pre>
<p>Alternatively if we would be using a scikit-learn model we would save the pickle file:</p>
<pre><code class="language-python"># Alternatively, for the scikit-learn model we would save the pickle file
from sklearn.linear_model import LogisticRegression
from sklearn.multiclass import OneVsRestClassifier
lr = OneVsRestClassifier(LogisticRegression())
lr.fit(x, y)

with open(&quot;tmp/sklearn_model.pkl&quot;, &quot;wb&quot;) as f:
    pickle.dump(lr, f, protocol=2)


</code></pre>
<h4 id="3c-example-files-for-the-dataloader">3c. Example files for the dataloader</h4>
<p>Every Kipoi dataloader has to provide a set of example files so that Kipoi can perform its automated tests and users can have an idea what the dataloader files have to look like. Again we will store the files in the temporary folder:</p>
<pre><code class="language-python"># select first 20 rows of the iris dataset
X = pd.DataFrame(iris[&quot;data&quot;][:20], columns=iris[&quot;feature_names&quot;])
y = pd.DataFrame({&quot;class&quot;: iris[&quot;target&quot;][:20]})
# store the model input features and targets as csv files with column names:
X.to_csv(&quot;tmp/example_features.csv&quot;, index=False)
y.to_csv(&quot;tmp/example_targets.csv&quot;, index=False)
</code></pre>
<h3 id="4-write-the-modelyaml">4 Write the model.yaml</h3>
<p>Now it is time to write the model.yaml in the model directory. Since we are in the testing stage we will be using local file paths in the <code>args</code> field - those will be replaced by zenodo links once everything is ready for publication.</p>
<pre><code class="language-python">model_yaml = &quot;&quot;&quot;
defined_as: kipoi.model.KerasModel  # use `kipoi.model.KerasModel`
args:  # arguments of `kipoi.model.KerasModel`
    arch: tmp/model.json
    weights: tmp/weights.h5
default_dataloader: . # path to the dataloader directory. Here it's defined in the same directory
info: # General information about the model
    authors: 
        - name: Your Name
          github: your_github_username
          email: your_email@host.org
    doc: Model predicting the Iris species
    cite_as: https://doi.org:/... # preferably a doi url to the paper
    trained_on: Iris species dataset (http://archive.ics.uci.edu/ml/datasets/Iris) # short dataset description
    license: MIT # Software License - defaults to MIT
dependencies:
    conda: # install via conda
      - python=3.9
      - h5py=3.6
      - pip=21.2.4
      - keras=2.8
      - tensorflow=2.8
    pip:   # install via pip
      - protobuf==3.20
schema:  # Model schema
    inputs:
        features:
            shape: (4,)  # array shape of a single sample (omitting the batch dimension)
            doc: &quot;Features in cm: sepal length, sepal width, petal length, petal width.&quot;
    targets:
        shape: (3,)
        doc: &quot;One-hot encoded array of classes: setosa, versicolor, virginica.&quot;
&quot;&quot;&quot;
with open(&quot;model.yaml&quot;, &quot;w&quot;) as ofh:
    ofh.write(model_yaml)
</code></pre>
<h3 id="5-and-6-write-the-dataloaderyaml-and-dataloaderpy">5 and 6 Write the dataloader.yaml and dataloader.py</h3>
<p><em><strong>PLEASE REMEMBER:</strong></em>
Before writing a dataloader yourself please check whether the same functionality can be achieved using a ready-made 
dataloader in <a href="https://github.com/kipoi/kipoiseq">kipoiseq</a> and use those as explained in the Kipoi docs.</p>
<p>Now it is time to write the <code>dataloader.yaml</code>. Since we defined the <code>default_dataloader</code> field in <code>model.yaml</code> as <code>.</code> Kipoi will expect that our <code>dataloader.yaml</code> file lies in the same directory. Since we are in the testing stage we will be using local file paths in the <code>args</code> field - those will be replaced by zenodo links once everything is ready for publication.</p>
<pre><code class="language-python">dataloader_yaml = &quot;&quot;&quot;
type: Dataset
defined_as: dataloader.MyDataset
args:
    features_file:
        # descr: &gt; allows multi-line fields
        doc: &gt;
          Csv file of the Iris Plants Database from
          http://archive.ics.uci.edu/ml/datasets/Iris features.
        type: str
        example: tmp/example_features.csv  # example files
    x_transformer:
        default: tmp/x_transformer.pkl
        #default:
        #      url: https://github.com/kipoi/kipoi/raw/57734d716b8dedaffe460855e7cfe8f37ec2d48d/example/models/sklearn_iris/dataloader_files/x_transformer.pkl
        #      md5: bc1bf3c61c418b2d07506a7d0521a893
    y_transformer:
        default: tmp/y_transformer.pkl
    targets_file:
        doc: &gt;
          Csv file of the Iris Plants Database targets.
          Not required for making the prediction.
        type: str
        example: tmp/example_targets.csv
        optional: True  # if not present, the `targets` field will not be present in the dataloader output

info:
    authors: 
        - name: Your Name
          github: your_github_account
          email: your_email@host.org
    version: 0.1
    doc: Model predicting the Iris species
dependencies:
    conda:
      - python=3.9
      - pandas=1.4
      - numpy=1.22
    pip:
      - sklearn==0.0
output_schema:
    inputs:
        features:
            shape: (4,)
            doc: &quot;Features in cm: sepal length, sepal width, petal length, petal width.&quot;
    targets:
        shape: (3, )
        doc: &quot;One-hot encoded array of classes: setosa, versicolor, virginica.&quot;
    metadata:  # field providing additional information to the samples (not directly required by the model)
        example_row_number:
            doc: Just an example metadata column
&quot;&quot;&quot;
with open(&quot;dataloader.yaml&quot;, &quot;w&quot;) as ofh:
    ofh.write(dataloader_yaml)
</code></pre>
<p>Since we have referred to the dataloader as <code>dataloader.MyDataset</code> we expect a <code>dataloader.py</code> file in the same directory as <code>dataloader.yaml</code> which has to contain the dataloader class, which is here <code>MyDataset</code>.</p>
<p>Notice that external static files are arguments to the <code>__init__</code> function! Their path was defined in the <code>dataloader.yaml</code>.</p>
<pre><code class="language-python">import pickle
from kipoi.data import Dataset
import pandas as pd
import numpy as np

def read_pickle(f):
    with open(f, &quot;rb&quot;) as f:
        return pickle.load(f)

class MyDataset(Dataset):

    def __init__(self, features_file, targets_file=None, x_transformer=None, y_transformer=None):
        self.features_file = features_file
        self.targets_file = targets_file

        self.y_transformer = read_pickle(y_transformer)
        self.x_transformer = read_pickle(x_transformer)

        self.features = pd.read_csv(features_file)
        if targets_file is not None:
            self.targets = pd.read_csv(targets_file)
            assert len(self.targets) == len(self.features)

    def __len__(self):
        return len(self.features)

    def __getitem__(self, idx):
        x_features = np.ravel(self.x_transformer.transform(self.features.iloc[idx].values[np.newaxis]))
        if self.targets_file is None:
            y_class = {}
        else:
            y_class = np.ravel(self.y_transformer.transform(self.targets.iloc[idx].values[np.newaxis]))
        return {
            &quot;inputs&quot;: {
                &quot;features&quot;: x_features
            },
            &quot;targets&quot;: y_class,
            &quot;metadata&quot;: {
                &quot;example_row_number&quot;: idx
            }
        }
</code></pre>
<p>In order to elucidate what the Dataloader class does I will make a few function calls that are usually performed by the Kipoi API in order to generate model input:</p>
<pre><code class="language-python"># instantiate the dataloader
ds = MyDataset(&quot;tmp/example_features.csv&quot;, &quot;tmp/example_targets.csv&quot;, &quot;tmp/x_transformer.pkl&quot;, 
               &quot;tmp/y_transformer.pkl&quot;)
</code></pre>
<pre><code class="language-python"># call __getitem__
ds[5]
</code></pre>
<pre><code>{'inputs': {'features': array([-0.53717756,  1.95766909, -1.17067529, -1.05003079])},
 'targets': array([1, 0, 0]),
 'metadata': {'example_row_number': 5}}
</code></pre>
<pre><code class="language-python">it = ds.batch_iter(batch_size=3, shuffle=False, num_workers=2)
next(it)
</code></pre>
<pre><code>{'inputs': {'features': array([[-0.90068117,  1.03205722, -1.3412724 , -1.31297673],
         [-1.14301691, -0.1249576 , -1.3412724 , -1.31297673],
         [-1.38535265,  0.33784833, -1.39813811, -1.31297673]])},
 'targets': array([[1, 0, 0],
        [1, 0, 0],
        [1, 0, 0]]),
 'metadata': {'example_row_number': array([0, 1, 2])}}
</code></pre>
<p>I will now store the code from above in a file so that we can test it:</p>
<pre><code class="language-python">dataloader_py = &quot;&quot;&quot;
import pickle
from kipoi.data import Dataset
import pandas as pd
import numpy as np

def read_pickle(f):
    with open(f, &quot;rb&quot;) as f:
        return pickle.load(f)

class MyDataset(Dataset):

    def __init__(self, features_file, targets_file=None, x_transformer=None, y_transformer=None):
        self.features_file = features_file
        self.targets_file = targets_file

        self.y_transformer = read_pickle(y_transformer)
        self.x_transformer = read_pickle(x_transformer)

        self.features = pd.read_csv(features_file)
        if targets_file is not None:
            self.targets = pd.read_csv(targets_file)
            assert len(self.targets) == len(self.features)

    def __len__(self):
        return len(self.features)

    def __getitem__(self, idx):
        x_features = np.ravel(self.x_transformer.transform(self.features.iloc[idx].values[np.newaxis]))
        if self.targets_file is None:
            y_class = {}
        else:
            y_class = np.ravel(self.y_transformer.transform(self.targets.iloc[idx].values[np.newaxis]))
        return {
            &quot;inputs&quot;: {
                &quot;features&quot;: x_features
            },
            &quot;targets&quot;: y_class,
            &quot;metadata&quot;: {
                &quot;example_row_number&quot;: idx
            }
        }
&quot;&quot;&quot;
with open(&quot;dataloader.py&quot;, &quot;w&quot;) as ofh:
    ofh.write(dataloader_py)
</code></pre>
<h3 id="7-test-the-model">7 Test the model</h3>
<p>Now it is time to test the model.</p>
<pre><code class="language-python">!kipoi test .
</code></pre>
<pre><code>[33mWARNING[0m [44m[kipoi.specs][0m doc empty for one of the dataloader `args` fields[0m
[33mWARNING[0m [44m[kipoi.specs][0m doc empty for one of the dataloader `args` fields[0m
[32mINFO[0m [44m[kipoi.data][0m successfully loaded the dataloader from /nfs/research1/stegle/users/rkreuzhu/opt/model-zoo/notebooks/contribution_sample_model/dataloader.MyDataset[0m
Using TensorFlow backend.
2018-10-11 17:41:58.586759: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
[32mINFO[0m [44m[kipoi.model][0m successfully loaded model architecture from &lt;_io.TextIOWrapper name='tmp/model.json' mode='r' encoding='UTF-8'&gt;[0m
[32mINFO[0m [44m[kipoi.model][0m successfully loaded model weights from tmp/weights.h5[0m
[32mINFO[0m [44m[kipoi.pipeline][0m dataloader.output_schema is compatible with model.schema[0m
[32mINFO[0m [44m[kipoi.pipeline][0m Initialized data generator. Running batches...[0m
[32mINFO[0m [44m[kipoi.pipeline][0m Returned data schema correct[0m
100%|█████████████████████████████████████████████| 1/1 [00:00&lt;00:00, 28.88it/s]
[32mINFO[0m [44m[kipoi.pipeline][0m predict_example done![0m
[32mINFO[0m [44m[kipoi.cli.main][0m Successfully ran test_predict[0m
</code></pre>
<h3 id="8-publish-data-on-zenodo-or-figshare">8. Publish data on zenodo or figshare</h3>
<p>Now that the model works It is time to upload the data files onto zenodo or figshare. To do so follow the instructions on the website. It might be necessary to remove file suffixes in order to be able to load the respective files.</p>
<h3 id="9-update-modelyaml-and-dataloaderyaml">9 Update <code>model.yaml</code> and <code>dataloader.yaml</code></h3>
<p>Now the local file paths in <code>model.yaml</code> and <code>dataloader.yaml</code> have to be replaced by the zenodo / figshare URLs in the following way.</p>
<p>The entry:</p>
<pre><code class="language-yaml">args:
    ...
    x_transformer:
        default: tmp/x_transformer.pkl
</code></pre>
<p>would be replaced by:</p>
<pre><code class="language-yaml">args:
    ...
    x_transformer:
        default: 
            url: https://zenodo.org/path/to/example_files/x_transformer.pkl
            md5: 76a5sd76asd57
</code></pre>
<p>So every local path has to be replaced by the <code>url</code> and <code>md5</code> combination. Where <code>md5</code> is the md5 sum of the file. If you cannot find the the md5 sum on the zenodo / figshare website you can for example run <code>curl https://zenodo.org/.../x_transformer.pkl | md5sum</code> to calculate the md5 sum.</p>
<p>Now after replacing all the files, test the setup again by running <code>kipoi test .</code> and then delete the <code>tmp</code> folder. Now the only file(s) remaining in the folder should be <code>model.yaml</code> (and in this case also: <code>dataloader.py</code>  <code>dataloader.yaml</code>). </p>
<h3 id="9-test-again">9 Test again</h3>
<p>Now that you have deleted the temporary files, rerun the test to make sure everything works fine.</p>
<h3 id="10-commit-and-push">10 Commit and push</h3>
<p>Now commit the <code>model.yaml</code> and if needed (like in this example) also the <code>dataloader.py</code> and <code>datalaoder.yaml</code> files by running: <code>git add model.yaml</code>.</p>
<p>Now you can push back to your fork (<code>git push</code>) and submit a pull request with <code>kipoi/models</code> to request adding your model to the Kipoi models.</p>
<h2 id="accessing-local-models-through-kipoi">Accessing local models through kipoi</h2>
<p>In Kipoi it is not necessary to publish your model. You can leverage the full functionality of Kipoi also for local models. All you have to do is specify <code>--source dir</code> when using the CLI or setting <code>source="dir"</code> in the python API. The model name is then the local path to the model folder.</p>
<pre><code class="language-python">import kipoi
</code></pre>
<pre><code class="language-python">m = kipoi.get_model(&quot;.&quot;, source=&quot;dir&quot;)  # See also python-sdk.ipynb
</code></pre>
<pre><code class="language-python">m.pipeline.predict({&quot;features_file&quot;: &quot;tmp/example_features.csv&quot;, &quot;targets_file&quot;: &quot;tmp/example_targets.csv&quot; })[:5]
</code></pre>
<pre><code>0it [00:00, ?it/s][A
1it [00:00, 19.03it/s][A




array([[ 3.2324865 , -0.29753828,  0.62135816],
       [ 2.8549244 ,  0.4957999 ,  0.6873083 ],
       [ 3.2744825 ,  0.40906954,  0.99161   ],
       [ 3.1413555 ,  0.58123374,  1.0272367 ],
       [ 3.416262  , -0.34901416,  0.76257455]], dtype=float32)
</code></pre>
<pre><code class="language-python">m.info
</code></pre>
<pre><code>ModelInfo(authors=[Author(name='Your Name', github='your_github_username', email='your_email@host.org')], doc='Model predicting the Iris species', name=None, version='0.1', license='MIT', tags=[], contributors=[], cite_as='https://doi.org:/...', trained_on='Iris species dataset (http://archive.ics.uci.edu/ml/datasets/Iris)', training_procedure=None)
</code></pre>
<pre><code class="language-python">m.default_dataloader
</code></pre>
<pre><code>dataloader.MyDataset
</code></pre>
<pre><code class="language-python">m.model
</code></pre>
<pre><code>&lt;keras.engine.training.Model at 0x2ab5a3eff668&gt;
</code></pre>
<pre><code class="language-python">m.predict_on_batch
</code></pre>
<pre><code>&lt;bound method KerasModel.predict_on_batch of &lt;kipoi.model.KerasModel object at 0x2ab5a2d75160&gt;&gt;
</code></pre>
<h2 id="best-practices">Best practices</h2>
<ul>
<li>Like all other types of virtual environment, conda environments are sensitive to changes in the ever changing world of python dependencies. It is recommended that you pin the versions of the packages listed under dependencies to that used in your local setup. If you already have a conda environment, simply do the following - <br>
    <code>conda env export --no-build &gt; env.yml</code><br>
    <code>cat env.yml | grep keras</code> </li>
<li>Your submitted models will be tested in our circleci infrastructure. The specifications are -<ul>
<li>OS: <a href="https://circleci.com/developer/machine/image/ubuntu-2004">ubuntu-2004:current</a></li>
<li>conda: latest version</li>
</ul>
</li>
<li>Try installing keras, tensorflow, h5py, numpy, pandas etc. from conda as opposed to pip. These packages depend on system libraries so installing them from pip is likely to lead to unintended inconsistencies.</li>
<li>If you are using a specific conda channel for a particular dependency, you can specify them as channel::package=version such as bioconda::pysam=0.16</li>
<li>During nightly tests, a conda environment is created for each model group from scratch. If there is a test template present in <code>model.yaml</code> generated 
predictions are compared against predictions stored in a file. In general, kipoi maintainers will generate a test file and update <code>model.yaml</code> after your submission. However, if you wish you can do this as well. However, this is optional. The steps are as follows - <br><ul>
<li><code>kipoi test &lt;model-name&gt; --source=dir  -o &lt;model-name&gt;.predictions.h5</code> <br></li>
<li>Upload <code>&lt;model-name&gt;.predictions.h5</code>  on zenodo or a file hosting service of choice and get an url and checksum <br></li>
<li>Add the following snippet to <code>model.yaml</code>. By default desired precision is 7 decimal places. Feel free to adjust this as shown below. 
<code>test:
  expect:
    url: &lt;Insert url&gt;
    md5: &lt;Insert md5 checksum&gt;
  precision_decimal: 5</code>    </li>
</ul>
</li>
<li>In some cases, you may submit a model group that contains multiple models with similar configuration. If you feel it is okay to just test a subset of them during kipoi repository's nightly tests - add a file in the top level called test_subset.txt and specify the name of the model like <a href="https://github.com/kipoi/models/blob/master/DeepBind/test_subset.txt">here</a>. In this case, the above test snippet needs to be modified like <a href="https://github.com/kipoi/models/blob/ca962e3881ba4e969a125144afab35ba4db442d5/DeepBind/model-template.yaml#L60-L65">so</a>. However, this is optional.</li>
</ul>
<h2 id="recap">Recap</h2>
<p>Congrats! You made it through the tutorial! Feel free to use this model for your model template. Alternatively, you can use <code>kipoi init</code> to setup a model directory. Make sure you have read the <a href="http://kipoi.org/docs/contributing/01_Getting_started/">getting started guide</a> for contributing models.</p>
              
            </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../python-api/" class="btn btn-neutral float-right" title="Python API">Next <span class="icon icon-circle-arrow-right"></span></a>
      
      
        <a href="../../contributing/06_dumping_models_programatically/" class="btn btn-neutral" title="Multiple very similar models"><span class="icon icon-circle-arrow-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
    
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
      
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
        <span>
          <a href="http://github.com/kipoi/kipoi/" class="fa fa-github" style="color: #fcfcfc"> GitHub</a>
        </span>
    
    
      <span><a href="../../contributing/06_dumping_models_programatically/" style="color: #fcfcfc">&laquo; Previous</a></span>
    
    
      <span><a href="../python-api/" style="color: #fcfcfc">Next &raquo;</a></span>
    
  </span>
</div>
    <script>var base_url = '../..';</script>
    <script src="../../js/theme_extra.js" defer></script>
    <script src="../../js/theme.js" defer></script>
      <script src="../../search/main.js" defer></script>
    <script defer>
        window.onload = function () {
            SphinxRtdTheme.Navigation.enable(true);
        };
    </script>

</body>
</html>
