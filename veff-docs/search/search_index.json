{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"kipoi_veff Variant effect prediction plugin for Kipoi. The variant effect prediction plug-in bring VCF annotation for DNA-sequence based models to models that are integrated into Kipoi . Additionally it offers visualisation tools to estimate the effect of possible genetic variants in a given area (mutation maps). Installation To install the variant effect prediction plug-in use the following command: pip install kipoi_veff In order to use the variant effect prediction plug-in with Kipoi the --vep argument has to be added when setting up the model environment with kipoi create env <model_name> --vep . Alternatively, you can use conda to install kipoi_veff: conda install -c bioconda kipoi_veff Usage example Main function of this package is score_variants accessible from the command line or python. It annotates the vcf file using model predictions for the reference and alternative alleles. CLI $ kipoi veff score_variants -h usage: kipoi veff score_variants [-h] [--source {kipoi,dir,github-permalink} [{kipoi,dir,github-permalink} ...]] [--dataloader DATALOADER [DATALOADER ...]] [--dataloader_source DATALOADER_SOURCE [DATALOADER_SOURCE ...]] [--dataloader_args DATALOADER_ARGS [DATALOADER_ARGS ...]] [-i INPUT_VCF] [-o OUTPUT_VCF] [--batch_size BATCH_SIZE] [-n NUM_WORKERS] [-r RESTRICTION_BED] [-e EXTRA_OUTPUT] [-s SCORES [SCORES ...]] [-k SCORE_KWARGS [SCORE_KWARGS ...]] [-l SEQ_LENGTH [SEQ_LENGTH ...]] [--std_var_id] [--model_outputs MODEL_OUTPUTS [MODEL_OUTPUTS ...]] [--model_outputs_i MODEL_OUTPUTS_I [MODEL_OUTPUTS_I ...]] model [model ...] Predict effect of SNVs using ISM. positional arguments: model Model name. optional arguments: -h, --help show this help message and exit --source {kipoi,dir,github-permalink} [{kipoi,dir,github-permalink} ...] Model source to use. Specified in ~/.kipoi/config.yaml under model_sources. 'dir' is an additional source referring to the local folder. --dataloader DATALOADER [DATALOADER ...] Dataloader name. If not specified, the model's defaultDataLoader will be used --dataloader_source DATALOADER_SOURCE [DATALOADER_SOURCE ...] Dataloader source --dataloader_args DATALOADER_ARGS [DATALOADER_ARGS ...] Dataloader arguments either as a json string:'{\"arg1\": 1} or as a file path to a json file -i INPUT_VCF, --input_vcf INPUT_VCF Input VCF. -o OUTPUT_VCF, --output_vcf OUTPUT_VCF Output annotated VCF file path. --batch_size BATCH_SIZE Batch size to use in prediction -n NUM_WORKERS, --num_workers NUM_WORKERS Number of parallel workers for loading the dataset -r RESTRICTION_BED, --restriction_bed RESTRICTION_BED Regions for prediction can only be subsets of this bed file -e EXTRA_OUTPUT, --extra_output EXTRA_OUTPUT Additional output file. File format is inferred from the file path ending. Available file formats are: tsv,hdf5,h5 -s SCORES [SCORES ...], --scores SCORES [SCORES ...] Scoring method to be used. Only scoring methods selected in the model yaml file areavailable except for `diff` which is always available. Select scoring function by the`name` tag defined in the model yaml file. -k SCORE_KWARGS [SCORE_KWARGS ...], --score_kwargs SCORE_KWARGS [SCORE_KWARGS ...] JSON definition of the kwargs for the scoring functions selected in --scoring. The definiton can either be in JSON in the command line or the path of a .json file. The individual JSONs are expected to be supplied in the same order as the labels defined in --scoring. If the defaults or no arguments should be used define '{}' for that respective scoring method. -l SEQ_LENGTH [SEQ_LENGTH ...], --seq_length SEQ_LENGTH [SEQ_LENGTH ...] Optional parameter: Model input sequence length - necessary if the model does not have a pre-defined input sequence length. --std_var_id If set then variant IDs in the annotated VCF will be replaced with a standardised, unique ID. --model_outputs MODEL_OUTPUTS [MODEL_OUTPUTS ...] Optional parameter: Only return predictions for the selected model outputs. Namingaccording to the definition in model.yaml > schema > targets > column_labels --model_outputs_i MODEL_OUTPUTS_I [MODEL_OUTPUTS_I ...] Optional parameter: Only return predictions for the selected model outputs. Give integerindices of the selected model output(s). Python from kipoi_veff import score_variants # Signature score_variants(model, dl_args, input_vcf, output_vcf, scores=[\"logit_ref\", \"logit_alt\", \"ref\", \"alt\", \"logit\", \"diff\"], score_kwargs=None, num_workers=0, batch_size=32, source='kipoi', seq_length=None, std_var_id=False, restriction_bed=None, return_predictions=False, model_outputs = None) Method arguments: - model: model string or a model class instance - dl_args: dataloader arguments as a dictionary - input_vcf: input vcf file path - output_vcf: output vcf file path - scores: list of score names to compute. See kipoi_veff.scores - score_kwargs: optional, list of kwargs that corresponds to the entries in score. For details see - num_workers: number of paralell workers to use for dataloading - batch_size: batch_size for dataloading - source: model source name - std_var_id: If true then variant IDs in the annotated VCF will be replaced with a standardised, unique ID. - seq_length: If model accepts variable input sequence length then this value has to be set! - restriction_bed: If dataloader can be run with regions generated from the VCF then only variants that overlap - regions defined in restriction_bed will be tested. - return_predictions: return generated predictions also as pandas dataframe. - model_outputs: If set then either a boolean filter or a named filter for model outputs that are reported. Development setup If you want to help develop the Kipoi variant effect prediction plug-in, you are more than welcome to join. You should then install and test kipoi-veff as follows: git clone https://github.com/kipoi/kipoi-veff.git cd kipoi-veff pip install -e '.[develop]' py.test -n 8 # Run tests using 8 workers Release History 0.1.0 First release to PyPI","title":"Home"},{"location":"#kipoi_veff","text":"Variant effect prediction plugin for Kipoi. The variant effect prediction plug-in bring VCF annotation for DNA-sequence based models to models that are integrated into Kipoi . Additionally it offers visualisation tools to estimate the effect of possible genetic variants in a given area (mutation maps).","title":"kipoi_veff"},{"location":"#installation","text":"To install the variant effect prediction plug-in use the following command: pip install kipoi_veff In order to use the variant effect prediction plug-in with Kipoi the --vep argument has to be added when setting up the model environment with kipoi create env <model_name> --vep . Alternatively, you can use conda to install kipoi_veff: conda install -c bioconda kipoi_veff","title":"Installation"},{"location":"#usage-example","text":"Main function of this package is score_variants accessible from the command line or python. It annotates the vcf file using model predictions for the reference and alternative alleles.","title":"Usage example"},{"location":"#cli","text":"$ kipoi veff score_variants -h usage: kipoi veff score_variants [-h] [--source {kipoi,dir,github-permalink} [{kipoi,dir,github-permalink} ...]] [--dataloader DATALOADER [DATALOADER ...]] [--dataloader_source DATALOADER_SOURCE [DATALOADER_SOURCE ...]] [--dataloader_args DATALOADER_ARGS [DATALOADER_ARGS ...]] [-i INPUT_VCF] [-o OUTPUT_VCF] [--batch_size BATCH_SIZE] [-n NUM_WORKERS] [-r RESTRICTION_BED] [-e EXTRA_OUTPUT] [-s SCORES [SCORES ...]] [-k SCORE_KWARGS [SCORE_KWARGS ...]] [-l SEQ_LENGTH [SEQ_LENGTH ...]] [--std_var_id] [--model_outputs MODEL_OUTPUTS [MODEL_OUTPUTS ...]] [--model_outputs_i MODEL_OUTPUTS_I [MODEL_OUTPUTS_I ...]] model [model ...] Predict effect of SNVs using ISM. positional arguments: model Model name. optional arguments: -h, --help show this help message and exit --source {kipoi,dir,github-permalink} [{kipoi,dir,github-permalink} ...] Model source to use. Specified in ~/.kipoi/config.yaml under model_sources. 'dir' is an additional source referring to the local folder. --dataloader DATALOADER [DATALOADER ...] Dataloader name. If not specified, the model's defaultDataLoader will be used --dataloader_source DATALOADER_SOURCE [DATALOADER_SOURCE ...] Dataloader source --dataloader_args DATALOADER_ARGS [DATALOADER_ARGS ...] Dataloader arguments either as a json string:'{\"arg1\": 1} or as a file path to a json file -i INPUT_VCF, --input_vcf INPUT_VCF Input VCF. -o OUTPUT_VCF, --output_vcf OUTPUT_VCF Output annotated VCF file path. --batch_size BATCH_SIZE Batch size to use in prediction -n NUM_WORKERS, --num_workers NUM_WORKERS Number of parallel workers for loading the dataset -r RESTRICTION_BED, --restriction_bed RESTRICTION_BED Regions for prediction can only be subsets of this bed file -e EXTRA_OUTPUT, --extra_output EXTRA_OUTPUT Additional output file. File format is inferred from the file path ending. Available file formats are: tsv,hdf5,h5 -s SCORES [SCORES ...], --scores SCORES [SCORES ...] Scoring method to be used. Only scoring methods selected in the model yaml file areavailable except for `diff` which is always available. Select scoring function by the`name` tag defined in the model yaml file. -k SCORE_KWARGS [SCORE_KWARGS ...], --score_kwargs SCORE_KWARGS [SCORE_KWARGS ...] JSON definition of the kwargs for the scoring functions selected in --scoring. The definiton can either be in JSON in the command line or the path of a .json file. The individual JSONs are expected to be supplied in the same order as the labels defined in --scoring. If the defaults or no arguments should be used define '{}' for that respective scoring method. -l SEQ_LENGTH [SEQ_LENGTH ...], --seq_length SEQ_LENGTH [SEQ_LENGTH ...] Optional parameter: Model input sequence length - necessary if the model does not have a pre-defined input sequence length. --std_var_id If set then variant IDs in the annotated VCF will be replaced with a standardised, unique ID. --model_outputs MODEL_OUTPUTS [MODEL_OUTPUTS ...] Optional parameter: Only return predictions for the selected model outputs. Namingaccording to the definition in model.yaml > schema > targets > column_labels --model_outputs_i MODEL_OUTPUTS_I [MODEL_OUTPUTS_I ...] Optional parameter: Only return predictions for the selected model outputs. Give integerindices of the selected model output(s).","title":"CLI"},{"location":"#python","text":"from kipoi_veff import score_variants # Signature score_variants(model, dl_args, input_vcf, output_vcf, scores=[\"logit_ref\", \"logit_alt\", \"ref\", \"alt\", \"logit\", \"diff\"], score_kwargs=None, num_workers=0, batch_size=32, source='kipoi', seq_length=None, std_var_id=False, restriction_bed=None, return_predictions=False, model_outputs = None) Method arguments: - model: model string or a model class instance - dl_args: dataloader arguments as a dictionary - input_vcf: input vcf file path - output_vcf: output vcf file path - scores: list of score names to compute. See kipoi_veff.scores - score_kwargs: optional, list of kwargs that corresponds to the entries in score. For details see - num_workers: number of paralell workers to use for dataloading - batch_size: batch_size for dataloading - source: model source name - std_var_id: If true then variant IDs in the annotated VCF will be replaced with a standardised, unique ID. - seq_length: If model accepts variable input sequence length then this value has to be set! - restriction_bed: If dataloader can be run with regions generated from the VCF then only variants that overlap - regions defined in restriction_bed will be tested. - return_predictions: return generated predictions also as pandas dataframe. - model_outputs: If set then either a boolean filter or a named filter for model outputs that are reported.","title":"Python"},{"location":"#development-setup","text":"If you want to help develop the Kipoi variant effect prediction plug-in, you are more than welcome to join. You should then install and test kipoi-veff as follows: git clone https://github.com/kipoi/kipoi-veff.git cd kipoi-veff pip install -e '.[develop]' py.test -n 8 # Run tests using 8 workers","title":"Development setup"},{"location":"#release-history","text":"0.1.0 First release to PyPI","title":"Release History"},{"location":"mutation_map/","text":"Mutation maps Mutation maps are related to variant effect prediction discussed above. Mutation maps are the application of SNV variant effect prediction on every position of the input sequence with all three alternative alleles. Therefore mutation maps can only be generated for models that support variant effect prediction. Mutation maps can be used to give an overview over the effect scores in a selected region. This region may be centered on a variant of interest or any other region in the genome for which the model can produce a prediction. It is therefore complementary to the variant effect prediction functionality and is intended for use with less variants / regions of interest as the variant effect prediction itself. Typically a mutation map should be calculated for only a handful of regions or query variants (that each tag a region), because for every region many effect predictions have to calculated resulting in calculation time and memory requirements: For a single query variant / query region N = model_sequence_length * 3 * model_output_tasks * effect_scoring_functions effect predictions have to be performed. The workflow is desinged in two steps: In a first step the aforementioned calculation is performed and results are stored in an hdf5 file with standardised format. These files can then be imported into the visualisation part of mutation maps. Both steps are available in python, R as well as the command line. Calculating mutation maps Python / R API The core element of mutation maps is the MutationMap class that is instantiated with a Kipoi model object, a dataloader object and the dataloader arguments: import kipoi from kipoi.postprocessing.variant_effects import MutationMap model = kipoi.get_model(<model_name>) dataloader = model.default_dataloader dataloader_arguments = {...} mm = MutationMap(model, dataloader, dataloader_arguments) MutationMap instances have the following methods to calculate mutation maps for the given query regions / variants: query_region , query_bed , query_vcf . All those functions return an instance of MutationMapPlotter, which can be stored as a hdf5 file or directly be used for generating mutation map plots. query_region The query_region command can be used to generate a mutation map for a selected genomic region: mmp = mm.query_region(\"chr22\", 25346, 25357) The query region has to be transformed to match model input sequence length as well as it has to lie in a genomic region for which the model can produce prediction. All this is taken care of automatically just like in the score_variants function of kipoi.postprocessing.variant_effects . For more details please see below . query_bed The query_bed command can be used to generate mutation maps for genomic regions defined in the bed file: mmp = mm.query_region(\"path/to/my/file.bed\") The query regions have to be transformed to match model input sequence length as well as they hasveto lie in a genomic region for which the model can produce prediction. All this is taken care of automatically just like in the score_variants function of kipoi.postprocessing.variant_effects . For more details please see below . query_vcf The query_vcf command can be used to generate mutation maps based on variants defined in the vcf file: mmp = mm.query_vcf(\"path/to/my/file.vcf\") The regions for query variants are generated analogously to the score_variants function of kipoi.postprocessing.variant_effects . For more details please see below . MutationMapPlotter Instances of the MutationMapPlotter class are generated by the query_* methods of the MutationMap class. They contain all the effect predictions plus some additional meta data necessary to produce mutation map plots. Those objects can be stored in hdf5 files. For plotting the plot_mutmap function can be used. The required arguments select the input sequence by a numerical index ( input_entry ), the name of the DNA sequence model input ( model_seq_input ), the name of the scoring function for which the results should be displayed ( scoring_key ) and finally the model output task ( model_output ). A combination of those four values directly link to one set of mutation map predictions. input_entry input_entry is a numerical index indicating which set of input data should be used. This relates back to how query regions are turned into model input data, see below . Since this link depends model sequence length as well as whether the model can only predict for a restricted subset of he genome, the meaning of an index value may vary from model to model. For a combination of models with highly different model input specifications it is therefore advisable to only query a single variant or region in order to avoid confusion. model_seq_input Many models will only have a single model input key, so this parameter might seem superfluous, but in general a model can have multiple DNA sequence inputs which are all being tested for variant effects. scoring_key The scoring key is one of the labels passed to the query_* function in the scores argument. model_output model_output is a model output task label. Additional to the required arguments the plots can be generated for a subset of the model input sequence using the limit_region_genomic . The plot can be generated with reverse-complementation of the sequence by using rc_plot . There are additional features available for the python/R API which are described in the method definition, some of which are also used in the mutation_map.ipynb . The CLI In the CLI mutation maps can be calculated for bed files or for VCF files. Both file formats are accepted by the --regions_file argument of the CLI command: kipoi postproc create_mutation_map <my_model_name> --dataloader_args '{...}' --regions_file path/to/my/file.vcf --output path/to/the/results/file.hdf5 Plotting Plotting in the command line works analogously as using the python API: kipoi postproc plot_mutation_map --input_file path/to/the/results/file.hdf5 --input_entry 0 --model_seq_input seq --scoring_key diff --model_output my_model_task --output path/to/the/plot/file.png The meaning of the parameters is identical to the ones in the python API mentioned above. The plotting functionality in the CLI is limited to zooming into genomic region and reverse-complementation of sequences. For examaples please take a look at the mutation_map.ipynb . Transformation of queries to model input This section gives the necessary information to understand how the tested region is derived from a query file. In order to perform a query on a model the query input must be transformed into genomic regions compatible with the model. Similar to variant effect prediction using the score_variants the automatically chosen region generation method will be chosen based on whether a dataloader offers a bed file input for postprocessing. dataloader.yaml > postprocessing > variant_effects > bed_input . By setting this value the mutation map method will automatically generate a temporary bed input file requesting model input for genomic regions. The path of this temporary bed file is then passed on to the dataloader by resetting the respective argument in the datalaoder_arguments . For some models it is not possible to freely define the genomic region for which model input data should be generated - in that case the dataloader.yaml does not have the dataloader.yaml > postprocessing > variant_effects > bed_input set. In those cases the datalaoder is executed without modifying the dataloader_arguments . The metadata generated alongside the model input is then used to identify model input that overlaps a query region / query variant. For cases when genomic regions can be defined freely for a model, the input samples will always have to generated matching the model input sequence length. This means that for query variants a region of the length of the model input will be centered on the query variant position. For query regions (e.g.: bed input file) every region is overlapped with windows of length of the model input. The first of those regions will start at the same position as the selected query region. Regions of the length of the model input sequence length will then be generated consecutively in order to cover the full region defined by the respective query region - see this schematic: In the top bit of this schematic on can see the case in which the dataloader accepts a bed file as an input to generate model input data. This also requires the correct setup of the dataloader.yaml in postprocessing > variant_effects > bed_input as described in more detail (here)[../postprocessing/variant_effect_prediction]. When the dataloader doesn't support bed input files for region defintion then all the regions generated by the dataloader will be overlapped with the query regions and any overlapping data generated from the dataloader will be used for mutation maps. The same as for bed query files holds true for VCF query files. As mentioned above all of those model input sequences are the subjected to variant effect prediction for every base and ever possible allele. The integer numbers displayed in the green or orange boxes are te order in which model input data is processed by the mutation map calculation algorithm. The numbers represent the index by which the predictions can then be accessed for plotting ( input_entry in plot_mutmap method of MutationMapPlotter or --input_entry CLI argument).","title":"Mutation maps"},{"location":"mutation_map/#mutation-maps","text":"Mutation maps are related to variant effect prediction discussed above. Mutation maps are the application of SNV variant effect prediction on every position of the input sequence with all three alternative alleles. Therefore mutation maps can only be generated for models that support variant effect prediction. Mutation maps can be used to give an overview over the effect scores in a selected region. This region may be centered on a variant of interest or any other region in the genome for which the model can produce a prediction. It is therefore complementary to the variant effect prediction functionality and is intended for use with less variants / regions of interest as the variant effect prediction itself. Typically a mutation map should be calculated for only a handful of regions or query variants (that each tag a region), because for every region many effect predictions have to calculated resulting in calculation time and memory requirements: For a single query variant / query region N = model_sequence_length * 3 * model_output_tasks * effect_scoring_functions effect predictions have to be performed. The workflow is desinged in two steps: In a first step the aforementioned calculation is performed and results are stored in an hdf5 file with standardised format. These files can then be imported into the visualisation part of mutation maps. Both steps are available in python, R as well as the command line.","title":"Mutation maps"},{"location":"mutation_map/#calculating-mutation-maps","text":"","title":"Calculating mutation maps"},{"location":"mutation_map/#python-r-api","text":"The core element of mutation maps is the MutationMap class that is instantiated with a Kipoi model object, a dataloader object and the dataloader arguments: import kipoi from kipoi.postprocessing.variant_effects import MutationMap model = kipoi.get_model(<model_name>) dataloader = model.default_dataloader dataloader_arguments = {...} mm = MutationMap(model, dataloader, dataloader_arguments) MutationMap instances have the following methods to calculate mutation maps for the given query regions / variants: query_region , query_bed , query_vcf . All those functions return an instance of MutationMapPlotter, which can be stored as a hdf5 file or directly be used for generating mutation map plots.","title":"Python / R API"},{"location":"mutation_map/#query_region","text":"The query_region command can be used to generate a mutation map for a selected genomic region: mmp = mm.query_region(\"chr22\", 25346, 25357) The query region has to be transformed to match model input sequence length as well as it has to lie in a genomic region for which the model can produce prediction. All this is taken care of automatically just like in the score_variants function of kipoi.postprocessing.variant_effects . For more details please see below .","title":"query_region"},{"location":"mutation_map/#query_bed","text":"The query_bed command can be used to generate mutation maps for genomic regions defined in the bed file: mmp = mm.query_region(\"path/to/my/file.bed\") The query regions have to be transformed to match model input sequence length as well as they hasveto lie in a genomic region for which the model can produce prediction. All this is taken care of automatically just like in the score_variants function of kipoi.postprocessing.variant_effects . For more details please see below .","title":"query_bed"},{"location":"mutation_map/#query_vcf","text":"The query_vcf command can be used to generate mutation maps based on variants defined in the vcf file: mmp = mm.query_vcf(\"path/to/my/file.vcf\") The regions for query variants are generated analogously to the score_variants function of kipoi.postprocessing.variant_effects . For more details please see below .","title":"query_vcf"},{"location":"mutation_map/#mutationmapplotter","text":"Instances of the MutationMapPlotter class are generated by the query_* methods of the MutationMap class. They contain all the effect predictions plus some additional meta data necessary to produce mutation map plots. Those objects can be stored in hdf5 files. For plotting the plot_mutmap function can be used. The required arguments select the input sequence by a numerical index ( input_entry ), the name of the DNA sequence model input ( model_seq_input ), the name of the scoring function for which the results should be displayed ( scoring_key ) and finally the model output task ( model_output ). A combination of those four values directly link to one set of mutation map predictions.","title":"MutationMapPlotter"},{"location":"mutation_map/#input_entry","text":"input_entry is a numerical index indicating which set of input data should be used. This relates back to how query regions are turned into model input data, see below . Since this link depends model sequence length as well as whether the model can only predict for a restricted subset of he genome, the meaning of an index value may vary from model to model. For a combination of models with highly different model input specifications it is therefore advisable to only query a single variant or region in order to avoid confusion.","title":"input_entry"},{"location":"mutation_map/#model_seq_input","text":"Many models will only have a single model input key, so this parameter might seem superfluous, but in general a model can have multiple DNA sequence inputs which are all being tested for variant effects.","title":"model_seq_input"},{"location":"mutation_map/#scoring_key","text":"The scoring key is one of the labels passed to the query_* function in the scores argument.","title":"scoring_key"},{"location":"mutation_map/#model_output","text":"model_output is a model output task label. Additional to the required arguments the plots can be generated for a subset of the model input sequence using the limit_region_genomic . The plot can be generated with reverse-complementation of the sequence by using rc_plot . There are additional features available for the python/R API which are described in the method definition, some of which are also used in the mutation_map.ipynb .","title":"model_output"},{"location":"mutation_map/#the-cli","text":"In the CLI mutation maps can be calculated for bed files or for VCF files. Both file formats are accepted by the --regions_file argument of the CLI command: kipoi postproc create_mutation_map <my_model_name> --dataloader_args '{...}' --regions_file path/to/my/file.vcf --output path/to/the/results/file.hdf5","title":"The CLI"},{"location":"mutation_map/#plotting","text":"Plotting in the command line works analogously as using the python API: kipoi postproc plot_mutation_map --input_file path/to/the/results/file.hdf5 --input_entry 0 --model_seq_input seq --scoring_key diff --model_output my_model_task --output path/to/the/plot/file.png The meaning of the parameters is identical to the ones in the python API mentioned above. The plotting functionality in the CLI is limited to zooming into genomic region and reverse-complementation of sequences. For examaples please take a look at the mutation_map.ipynb .","title":"Plotting"},{"location":"mutation_map/#transformation-of-queries-to-model-input","text":"This section gives the necessary information to understand how the tested region is derived from a query file. In order to perform a query on a model the query input must be transformed into genomic regions compatible with the model. Similar to variant effect prediction using the score_variants the automatically chosen region generation method will be chosen based on whether a dataloader offers a bed file input for postprocessing. dataloader.yaml > postprocessing > variant_effects > bed_input . By setting this value the mutation map method will automatically generate a temporary bed input file requesting model input for genomic regions. The path of this temporary bed file is then passed on to the dataloader by resetting the respective argument in the datalaoder_arguments . For some models it is not possible to freely define the genomic region for which model input data should be generated - in that case the dataloader.yaml does not have the dataloader.yaml > postprocessing > variant_effects > bed_input set. In those cases the datalaoder is executed without modifying the dataloader_arguments . The metadata generated alongside the model input is then used to identify model input that overlaps a query region / query variant. For cases when genomic regions can be defined freely for a model, the input samples will always have to generated matching the model input sequence length. This means that for query variants a region of the length of the model input will be centered on the query variant position. For query regions (e.g.: bed input file) every region is overlapped with windows of length of the model input. The first of those regions will start at the same position as the selected query region. Regions of the length of the model input sequence length will then be generated consecutively in order to cover the full region defined by the respective query region - see this schematic: In the top bit of this schematic on can see the case in which the dataloader accepts a bed file as an input to generate model input data. This also requires the correct setup of the dataloader.yaml in postprocessing > variant_effects > bed_input as described in more detail (here)[../postprocessing/variant_effect_prediction]. When the dataloader doesn't support bed input files for region defintion then all the regions generated by the dataloader will be overlapped with the query regions and any overlapping data generated from the dataloader will be used for mutation maps. The same as for bed query files holds true for VCF query files. As mentioned above all of those model input sequences are the subjected to variant effect prediction for every base and ever possible allele. The integer numbers displayed in the green or orange boxes are te order in which model input data is processed by the mutation map calculation algorithm. The numbers represent the index by which the predictions can then be accessed for plotting ( input_entry in plot_mutmap method of MutationMapPlotter or --input_entry CLI argument).","title":"Transformation of queries to model input"},{"location":"overview/","text":"Variant effect prediction Variant effect prediction offers a simple way predict effects of SNVs using any model that uses DNA sequence as an input. Many different scoring methods can be chosen but the principle relies on in-silico mutagenesis (see below). The default input is a VCF and the default output again is a VCF annotated with predictions of variant effects. How it works This sketch highlights the overall functionality of variant effect prediction. More details are given in the chapters below. Dataloader output and a VCF are overlapped and the input DNA sequence is mutated as defined in the VCF. The reference and the alternative set of model inputs is predicted using the model and the differences are evaluated using a scoring function. The results are then stored in an annotated VCF. In-silico mutagenesis The principle relies on generating model predictions twice, once with DNA sequence that contains the reference and once with the alternative allele of a variant. Those predictions can then be compared in different ways to generate an effect prediction. Scoring methods Scoring methods that come with Kipoi are Diff which simply calculates the difference between the two predictions, Logit which calculates the difference of logit(prediction) of the two predictions and a few more. Those scoring methods can also be user-defined in which case they can be submitted with the model. Not all scoring functions are compatible with all model possible model outputs - for example the logit transformation can only be performed on values [0,1]. Model and dataloader requirements The model has to produce predictions at least partly based on DNA sequence and the DNA sequence either has to be as a string (e.g. acgtACGT ) or in a 1-hot encoded way in which A = [1,0,0,0] , C = [0,1,0,0] , G= [0,0,1,0] , T= [0,0,0,1] . Please note that any letter/base that is not in acgtACGT will be regarded and treated as N (in one-hot: [0,0,0,0] )! Requirements for the dataloader are that apart from producing the model input it also has to output information which region of the genome this generated sequence corresponds. On a side note: This region is only used to calculate an overlap with the query VCF, hence as long the dataloader output refers to the same sequence assembly as the VCF file variant scoring will return the desired results. Setting up the model.yaml In order to indicate that a model is compatible with Kipoi postprocessing the definition of postprocessing in the model.yaml file is necessary. The postprocessing section can then mention multiple different ways to interpret a model. Here we will discuss variant effect prediction, a sample section of the model.yaml can look like this: postprocessing: variant_effects: seq_input: - seq use_rc: seq_only This defines that the current model is capable to be used for variant effect prediction ( variant_effects ) and it defines that seq is the name of the model input that contains DNA sequence, which can be mutated and used for effect prediction. seq_input is a mandatory field and variant effect prediction can only be executed if there is at least one model input defined in seq_input . For some models it is necessary that also reverse-complements of DNA sequences are tested / predicted. To indicate that this is the case for the current model add the optional flag use_rc: seq_only . Using seq_only will reverse-complement only the model inputs that are defined in seq_input . Any other model input will remain untouched and exactly the same input will be fed to the model input as for the \"forward\" version of the model input. As mentioned above the DNA sequence input may either be a string or 1-hot encoded. To indicate which format is used the special_type flag is used. The model input may then look like this: schema: inputs: seq: shape: (101, 4) special_type: DNASeq doc: One-hot encoded RNA sequence Here a one-hot encoded sequence ( DNASeq ) is expected to be the model input. Note that the model input label (here: seq ) was used before in the postprocessing section and the same label is expected to be exist in the dataloader output. The special_type flag for using string input sequences is: DNAStringSeq . So the following snippet of a model.yaml file schema: inputs: seq: shape: () special_type: DNAStringSeq doc: RNA sequence as a string indicates that a single sample of seq is np.array(string) where string is a python string. If special_type is not defined for a model input, but it is used in seq_input in the postprocessing section, then by default Kipoi expects one-hot encoded DNA sequences. Setting up the dataloader.yaml Similar to the model.yaml also dataloader.yaml has to have a postprocessing section defined to indicate that it is compatible with variant effect prediction. As a bare minimum the following has to be defined: postprocessing: variant_effects: And equally important every DNA sequence input of a model (here seq ) has to have an associated metadata tag, which could like follows: output_schema: inputs: seq: shape: (101, 4) special_type: DNASeq doc: One-hot encoded RNA sequence associated_metadata: ranges some_other_input: shape: (1, 10) doc: Some description metadata: ranges: type: GenomicRanges doc: Ranges describing inputs.seq Here the associated_metadata flag in the input field seq is set to ranges , which means that for every sample in the model_input['inputs']['seq'] one entry in model_input['metadata']['ranges'] is expected with its type either being GenomicRanges or a dictionary of numpy arrays with the keys chr , start , end , id . The information in the metadata object gives variant effect prediction the possibilty to find the relative position of a variant within a given input sequence. Hence the associated_metadata is mandatory for every entry in seq_input in the model.yaml file. Please note that the coordinates in the metadata are expected to be 0-based, hence comply with .bed file format! The following sketch gives an overview how the different tags play together and how they are used with variant effect prediction. Use-cases This section describes a set of functions which cover most of the common queries for variant effect. All of the functions described below require that the model.yaml and dataloader.yaml files are set up in the way defined above. In literature in-silico mutagenesis-based variant effect predcition is performed in a variant centric way: Starting from a VCF for every variant a sequence centered on said variant is generated. That sequence is then mutated by modifying the central base and setting it to what is defined as reference or alternative allele, generating two sets of sequences. For both the set with the reference allele in the center and the alternative allele in the center the model prediction is run and model outputs are compared. Not all models can predict on aribrary DNA sequences from any region of the genome. Splicing models may for example only be trained on regions surrounding a splice site, hence the variant-centered approach from before will not work. Therefore two more options to run variant effect predicion are offered: restricted variant centered effect prediction and overlap-based effect prediction. Variant effect prediction will try to use variant-centered approaches whenever the bed_input flag is defined in dataloader.yaml (see below). Otherwise the overlap-based effect prediction is used. This is because the variant centered approach is generally faster and for every variant in the VCF one single prediction can be made (assuming the position of variant is in a valid genomic region). For all the methods described below it is essential that genomic coordinates in the VCF and the coordinates used by the dataloader are for the same genome / assembly /etc. Variant centered effect prediction In order to use variant centered effect prediction the dataloader must accept an input bed file based on which it will produce model input. Furthermore the dataloader is required to return the name values (fourth column) of the input bed file in the id field of model_input['metadata']['ranges'] . Additionally the order of samples has to be identical with the order of regions in the input bed file, but regions may be skipped. In order for the variant effect prediction to know which input argument of the dataloader is accepts a bed file three additional lines in dataloader.yaml are necessary, e.g: postprocessing: variant_effects: bed_input: - intervals_file This section indicates that the dataloader function has an argument intervals_file which accepts a bed file path as input which may be used. Restricted-variant centered effect prediction Requirements for the dataloader and dataloader.yaml here are identical to the variant centered effect prediction. The only difference is that this function is designed for models that can't predict on arbitrary regions of the genome, but only in certain regions of the genome. If those regions can be defined in a bed file (further on called 'restriction-bed' file) then this approach can be used. Variant effect prediction will then intersect the VCF with the restriction-bed and generate another bed file that is then passed on to the dataloader. Regions in the restriction-bed file may be larger than the input sequence lenght, in that case the generated seuqence will be centered on the variant position as much as possible - restricted by what is defined in the restrictions-bed file. Overlap-based effect prediction If the dataloader does not support bed input files then variant effect predictions can be run by the overlap of a VCF with the regions defined in the metdata output of the dataloader. If multiple variants overlap with a region then the effect will be predicted inpendently for those variants. If multiple (e.g.: two) model input samples overlap with one variant then the output will contain as many predictions as there were independent overlaps of metadata ranges and variants (e.g.: two). Scoring functions After mutating the model input DNA sequences predictions are created using the models and those predictions then have to compared by scoring methods. Not all scoring methods are compatible with all models depending on the output data range of the model (see below). The compatibility of a scoring function with a given model can be indicated by setting scoring_functions in model.yaml: postprocessing: variant_effects seq_input: - seq scoring_functions: - name: diff type: diff - type: logit default: true The scoring function is identified by the type field in scoring_functions which is the only mandatory field. Allowed values for the type field are: diff , logit , deepsea_effect and custom . Setting default:true for a scoring function indicates that that respective scoring function is executed by variant effect prediction if none is selected by the used on execution time. If multiple scoring functions have set default:true then all of those will be run by default. If default:true is not set for any scoring function defined in scoring_functions then all entries in scoring_functions will be run by default. Scoring functions can be assigned a different name with the name flag by which they are then selected using the command line interface. In general it is not advisable to rename the scoring functions that come with Kipoi. Diff The simplest scoring method is to calculate the difference between predictions for the reference and the alternative allele: prediction(alt) - prediction(ref) . This scoring method is available for all models no matter if it is defined in scoring_functions or not. Logit Calculates the difference of logit-transformed values of the predictions: logit(prediction(alt)) - logit(prediction(ref)) . This scoring method only makes sense if the model output can be interpreted as probabilities. In a wider sense, it will only produce valid values if the predictions are in the range [0,1]. LogitAlt Returns the logits transformed predictions for the sequences carrying the alternative allele: logit(prediction(alt)) . This scoring method only makes sense if the model output can be interpreted as probabilities. In a wider sense, it will only produce valid values if the predictions are in the range [0,1]. LogitRef Returns the logits transformed predictions for the sequences carrying the reference allele: logit(prediction(ref)) . This scoring method only makes sense if the model output can be interpreted as probabilities. In a wider sense, it will only produce valid values if the predictions are in the range [0,1]. Deepsea_effect Calculates the variant scores as defined in the publication of the DeepSEA model (Troyanskaya et al., 2015) by using the absolute value of the logit difference and diff values multiplied together: abs(Logit * Diff) with Logit and Diff defined as above. Custom Custom scoring methods can be defined and shipped with the models. In that case the model.yaml will look similar to this: postprocessing: variant_effects: seq_input: - seq scoring_functions: - name: my_scores type: custom defined_as: postproc.py::myfun args: first_arg: doc: Description of the first argument default: 1 Notice that the selection of type: custom requires that defined_as is set. The value postproc.py::myfun indicates that the callable python object myfun is stored in a file called postproc.py . When executing variant effect prediction in the command line the scoring function can be chosen by it's name - which in this case is: my_scores . All scoring functions are subclasses of Rc_merging_pred_analysis this means that also a custom scoring function must inherit from it. Output The output of variant effect prediction is by default stored in a VCF that is derived from the input VCF. The output VCF only contains variants for which a effect prediction could be generated (e.g. if no model input sample overlapped a variant no prediction could be made for it). The predictions themselves are stored in the INFO field of the VCF, with the ID starting with KPVEP and containing the name of the model. Additional to the predictions themselves a also a region ID will be stored in a second INFO field. The region IDs are the values stored in model_input['metadata']['ranges']['id'] given to a sequence sample generated by the dataloader. This way it is possible to trace back which sequence was mutated by which variant in order to produce a certain effect prediction Since multiple seqeunces generated by the dataloader may overlap one variant - especially when using the overlap-based effect prediction - it is possible that the generated VCF output will contain a variant multiple times, but the different predictions will be destinguishable by their region ID. If variant effect prediction is run programmatically in python then the results are returned as a dictionary of pandas DataFrames. More complex models More complex models may have more than only one DNA sequence input, it may even be that models have DNA sequence inputs taken from different regions of the genome within one sample in a batch. See this sketch for an illustration of the scenario: The dataloader has three sequence outputs which are linked to two metadata ranges. for both ranges objects the beginning of the ranges is displayed. In order to overlap the metadata ranges with variants the input batch is processed one sample at a time. The samples in a batch are displayed in green rectangular boxes: For every sample all the ranges are assembled and overlapped with variants in the VCF. Then the effect is predicted for every single variant in the VCF that overlaps at least one of the region defined in that sample. This means that for the first sample in the batch two variants are investigated: rs1 and rs2. rs1 can only affect seq1a and seq1b, hence those two sequences are mutated, seq2 is not. rs2 overlaps with both ranges in the first sample and hence two sequences are mutated with rs2 to predict its effect. This means that the first sample will be evaluated twice using variants rs1 and rs2, and the second sample only once using rs3.","title":"Overview"},{"location":"overview/#variant-effect-prediction","text":"Variant effect prediction offers a simple way predict effects of SNVs using any model that uses DNA sequence as an input. Many different scoring methods can be chosen but the principle relies on in-silico mutagenesis (see below). The default input is a VCF and the default output again is a VCF annotated with predictions of variant effects.","title":"Variant effect prediction"},{"location":"overview/#how-it-works","text":"This sketch highlights the overall functionality of variant effect prediction. More details are given in the chapters below. Dataloader output and a VCF are overlapped and the input DNA sequence is mutated as defined in the VCF. The reference and the alternative set of model inputs is predicted using the model and the differences are evaluated using a scoring function. The results are then stored in an annotated VCF.","title":"How it works"},{"location":"overview/#in-silico-mutagenesis","text":"The principle relies on generating model predictions twice, once with DNA sequence that contains the reference and once with the alternative allele of a variant. Those predictions can then be compared in different ways to generate an effect prediction.","title":"In-silico mutagenesis"},{"location":"overview/#scoring-methods","text":"Scoring methods that come with Kipoi are Diff which simply calculates the difference between the two predictions, Logit which calculates the difference of logit(prediction) of the two predictions and a few more. Those scoring methods can also be user-defined in which case they can be submitted with the model. Not all scoring functions are compatible with all model possible model outputs - for example the logit transformation can only be performed on values [0,1].","title":"Scoring methods"},{"location":"overview/#model-and-dataloader-requirements","text":"The model has to produce predictions at least partly based on DNA sequence and the DNA sequence either has to be as a string (e.g. acgtACGT ) or in a 1-hot encoded way in which A = [1,0,0,0] , C = [0,1,0,0] , G= [0,0,1,0] , T= [0,0,0,1] . Please note that any letter/base that is not in acgtACGT will be regarded and treated as N (in one-hot: [0,0,0,0] )! Requirements for the dataloader are that apart from producing the model input it also has to output information which region of the genome this generated sequence corresponds. On a side note: This region is only used to calculate an overlap with the query VCF, hence as long the dataloader output refers to the same sequence assembly as the VCF file variant scoring will return the desired results.","title":"Model and dataloader requirements"},{"location":"overview/#setting-up-the-modelyaml","text":"In order to indicate that a model is compatible with Kipoi postprocessing the definition of postprocessing in the model.yaml file is necessary. The postprocessing section can then mention multiple different ways to interpret a model. Here we will discuss variant effect prediction, a sample section of the model.yaml can look like this: postprocessing: variant_effects: seq_input: - seq use_rc: seq_only This defines that the current model is capable to be used for variant effect prediction ( variant_effects ) and it defines that seq is the name of the model input that contains DNA sequence, which can be mutated and used for effect prediction. seq_input is a mandatory field and variant effect prediction can only be executed if there is at least one model input defined in seq_input . For some models it is necessary that also reverse-complements of DNA sequences are tested / predicted. To indicate that this is the case for the current model add the optional flag use_rc: seq_only . Using seq_only will reverse-complement only the model inputs that are defined in seq_input . Any other model input will remain untouched and exactly the same input will be fed to the model input as for the \"forward\" version of the model input. As mentioned above the DNA sequence input may either be a string or 1-hot encoded. To indicate which format is used the special_type flag is used. The model input may then look like this: schema: inputs: seq: shape: (101, 4) special_type: DNASeq doc: One-hot encoded RNA sequence Here a one-hot encoded sequence ( DNASeq ) is expected to be the model input. Note that the model input label (here: seq ) was used before in the postprocessing section and the same label is expected to be exist in the dataloader output. The special_type flag for using string input sequences is: DNAStringSeq . So the following snippet of a model.yaml file schema: inputs: seq: shape: () special_type: DNAStringSeq doc: RNA sequence as a string indicates that a single sample of seq is np.array(string) where string is a python string. If special_type is not defined for a model input, but it is used in seq_input in the postprocessing section, then by default Kipoi expects one-hot encoded DNA sequences.","title":"Setting up the model.yaml"},{"location":"overview/#setting-up-the-dataloaderyaml","text":"Similar to the model.yaml also dataloader.yaml has to have a postprocessing section defined to indicate that it is compatible with variant effect prediction. As a bare minimum the following has to be defined: postprocessing: variant_effects: And equally important every DNA sequence input of a model (here seq ) has to have an associated metadata tag, which could like follows: output_schema: inputs: seq: shape: (101, 4) special_type: DNASeq doc: One-hot encoded RNA sequence associated_metadata: ranges some_other_input: shape: (1, 10) doc: Some description metadata: ranges: type: GenomicRanges doc: Ranges describing inputs.seq Here the associated_metadata flag in the input field seq is set to ranges , which means that for every sample in the model_input['inputs']['seq'] one entry in model_input['metadata']['ranges'] is expected with its type either being GenomicRanges or a dictionary of numpy arrays with the keys chr , start , end , id . The information in the metadata object gives variant effect prediction the possibilty to find the relative position of a variant within a given input sequence. Hence the associated_metadata is mandatory for every entry in seq_input in the model.yaml file. Please note that the coordinates in the metadata are expected to be 0-based, hence comply with .bed file format! The following sketch gives an overview how the different tags play together and how they are used with variant effect prediction.","title":"Setting up the dataloader.yaml"},{"location":"overview/#use-cases","text":"This section describes a set of functions which cover most of the common queries for variant effect. All of the functions described below require that the model.yaml and dataloader.yaml files are set up in the way defined above. In literature in-silico mutagenesis-based variant effect predcition is performed in a variant centric way: Starting from a VCF for every variant a sequence centered on said variant is generated. That sequence is then mutated by modifying the central base and setting it to what is defined as reference or alternative allele, generating two sets of sequences. For both the set with the reference allele in the center and the alternative allele in the center the model prediction is run and model outputs are compared. Not all models can predict on aribrary DNA sequences from any region of the genome. Splicing models may for example only be trained on regions surrounding a splice site, hence the variant-centered approach from before will not work. Therefore two more options to run variant effect predicion are offered: restricted variant centered effect prediction and overlap-based effect prediction. Variant effect prediction will try to use variant-centered approaches whenever the bed_input flag is defined in dataloader.yaml (see below). Otherwise the overlap-based effect prediction is used. This is because the variant centered approach is generally faster and for every variant in the VCF one single prediction can be made (assuming the position of variant is in a valid genomic region). For all the methods described below it is essential that genomic coordinates in the VCF and the coordinates used by the dataloader are for the same genome / assembly /etc.","title":"Use-cases"},{"location":"overview/#variant-centered-effect-prediction","text":"In order to use variant centered effect prediction the dataloader must accept an input bed file based on which it will produce model input. Furthermore the dataloader is required to return the name values (fourth column) of the input bed file in the id field of model_input['metadata']['ranges'] . Additionally the order of samples has to be identical with the order of regions in the input bed file, but regions may be skipped. In order for the variant effect prediction to know which input argument of the dataloader is accepts a bed file three additional lines in dataloader.yaml are necessary, e.g: postprocessing: variant_effects: bed_input: - intervals_file This section indicates that the dataloader function has an argument intervals_file which accepts a bed file path as input which may be used.","title":"Variant centered effect prediction"},{"location":"overview/#restricted-variant-centered-effect-prediction","text":"Requirements for the dataloader and dataloader.yaml here are identical to the variant centered effect prediction. The only difference is that this function is designed for models that can't predict on arbitrary regions of the genome, but only in certain regions of the genome. If those regions can be defined in a bed file (further on called 'restriction-bed' file) then this approach can be used. Variant effect prediction will then intersect the VCF with the restriction-bed and generate another bed file that is then passed on to the dataloader. Regions in the restriction-bed file may be larger than the input sequence lenght, in that case the generated seuqence will be centered on the variant position as much as possible - restricted by what is defined in the restrictions-bed file.","title":"Restricted-variant centered effect prediction"},{"location":"overview/#overlap-based-effect-prediction","text":"If the dataloader does not support bed input files then variant effect predictions can be run by the overlap of a VCF with the regions defined in the metdata output of the dataloader. If multiple variants overlap with a region then the effect will be predicted inpendently for those variants. If multiple (e.g.: two) model input samples overlap with one variant then the output will contain as many predictions as there were independent overlaps of metadata ranges and variants (e.g.: two).","title":"Overlap-based effect prediction"},{"location":"overview/#scoring-functions","text":"After mutating the model input DNA sequences predictions are created using the models and those predictions then have to compared by scoring methods. Not all scoring methods are compatible with all models depending on the output data range of the model (see below). The compatibility of a scoring function with a given model can be indicated by setting scoring_functions in model.yaml: postprocessing: variant_effects seq_input: - seq scoring_functions: - name: diff type: diff - type: logit default: true The scoring function is identified by the type field in scoring_functions which is the only mandatory field. Allowed values for the type field are: diff , logit , deepsea_effect and custom . Setting default:true for a scoring function indicates that that respective scoring function is executed by variant effect prediction if none is selected by the used on execution time. If multiple scoring functions have set default:true then all of those will be run by default. If default:true is not set for any scoring function defined in scoring_functions then all entries in scoring_functions will be run by default. Scoring functions can be assigned a different name with the name flag by which they are then selected using the command line interface. In general it is not advisable to rename the scoring functions that come with Kipoi.","title":"Scoring functions"},{"location":"overview/#diff","text":"The simplest scoring method is to calculate the difference between predictions for the reference and the alternative allele: prediction(alt) - prediction(ref) . This scoring method is available for all models no matter if it is defined in scoring_functions or not.","title":"Diff"},{"location":"overview/#logit","text":"Calculates the difference of logit-transformed values of the predictions: logit(prediction(alt)) - logit(prediction(ref)) . This scoring method only makes sense if the model output can be interpreted as probabilities. In a wider sense, it will only produce valid values if the predictions are in the range [0,1].","title":"Logit"},{"location":"overview/#logitalt","text":"Returns the logits transformed predictions for the sequences carrying the alternative allele: logit(prediction(alt)) . This scoring method only makes sense if the model output can be interpreted as probabilities. In a wider sense, it will only produce valid values if the predictions are in the range [0,1].","title":"LogitAlt"},{"location":"overview/#logitref","text":"Returns the logits transformed predictions for the sequences carrying the reference allele: logit(prediction(ref)) . This scoring method only makes sense if the model output can be interpreted as probabilities. In a wider sense, it will only produce valid values if the predictions are in the range [0,1].","title":"LogitRef"},{"location":"overview/#deepsea_effect","text":"Calculates the variant scores as defined in the publication of the DeepSEA model (Troyanskaya et al., 2015) by using the absolute value of the logit difference and diff values multiplied together: abs(Logit * Diff) with Logit and Diff defined as above.","title":"Deepsea_effect"},{"location":"overview/#custom","text":"Custom scoring methods can be defined and shipped with the models. In that case the model.yaml will look similar to this: postprocessing: variant_effects: seq_input: - seq scoring_functions: - name: my_scores type: custom defined_as: postproc.py::myfun args: first_arg: doc: Description of the first argument default: 1 Notice that the selection of type: custom requires that defined_as is set. The value postproc.py::myfun indicates that the callable python object myfun is stored in a file called postproc.py . When executing variant effect prediction in the command line the scoring function can be chosen by it's name - which in this case is: my_scores . All scoring functions are subclasses of Rc_merging_pred_analysis this means that also a custom scoring function must inherit from it.","title":"Custom"},{"location":"overview/#output","text":"The output of variant effect prediction is by default stored in a VCF that is derived from the input VCF. The output VCF only contains variants for which a effect prediction could be generated (e.g. if no model input sample overlapped a variant no prediction could be made for it). The predictions themselves are stored in the INFO field of the VCF, with the ID starting with KPVEP and containing the name of the model. Additional to the predictions themselves a also a region ID will be stored in a second INFO field. The region IDs are the values stored in model_input['metadata']['ranges']['id'] given to a sequence sample generated by the dataloader. This way it is possible to trace back which sequence was mutated by which variant in order to produce a certain effect prediction Since multiple seqeunces generated by the dataloader may overlap one variant - especially when using the overlap-based effect prediction - it is possible that the generated VCF output will contain a variant multiple times, but the different predictions will be destinguishable by their region ID. If variant effect prediction is run programmatically in python then the results are returned as a dictionary of pandas DataFrames.","title":"Output"},{"location":"overview/#more-complex-models","text":"More complex models may have more than only one DNA sequence input, it may even be that models have DNA sequence inputs taken from different regions of the genome within one sample in a batch. See this sketch for an illustration of the scenario: The dataloader has three sequence outputs which are linked to two metadata ranges. for both ranges objects the beginning of the ranges is displayed. In order to overlap the metadata ranges with variants the input batch is processed one sample at a time. The samples in a batch are displayed in green rectangular boxes: For every sample all the ranges are assembled and overlapped with variants in the VCF. Then the effect is predicted for every single variant in the VCF that overlaps at least one of the region defined in that sample. This means that for the first sample in the batch two variants are investigated: rs1 and rs2. rs1 can only affect seq1a and seq1b, hence those two sequences are mutated, seq2 is not. rs2 overlaps with both ranges in the first sample and hence two sequences are mutated with rs2 to predict its effect. This means that the first sample will be evaluated twice using variants rs1 and rs2, and the second sample only once using rs3.","title":"More complex models"},{"location":"using/","text":"Kipoi offers a set of postprocessing tools that enable to calculate variant effects, create mutation maps, inspect activation of hidden model layers and to calculate the gradient of layer activation with respect to a given input. Variant effect prediction and mutation map generation is available for all models where the variant_effects parameter in the model.yaml (and dataloader.yaml) is set (see here)[http://kipoi.org/docs/postprocessing/variant_effect_prediction]. Inspection of the activation of hidden model layers and calculation of gradients is available for all deep learning models: Currently supported are Keras, PyTorch and Tensorflow models. For a detailed description and examples of how to use tose features please take a look at: Variant effect prediction Mutation maps","title":"Functions"},{"location":"variant_effect_pred/","text":"Using variant effect prediction This chapter describes how to run variant prediction using a model in the zoo either using the python functionality or using the command line. A prerequesite is that the model is compatible with variant effect prediction (see: Variant effect prediction prerequesites for the model.yaml and dataloader.yaml) Variant effect prediction in python Using variant effect prediction within python allows more flexibility in the finegrain details compared to using the command line interface. The core function of variant effect prediction is score_variants , which on the one hand requires a model with its dataloader as well as a valid VCF. The easiest way to run variant effect prediction is the following: from kipoi.postprocessing.variant_effects import score_variants dataloader_arguments = {...} score_variants(model = \"my_model_name\", dl_args = dataloader_arguments, input_vcf = \"path/to/my_vcf.vcf\", output_vcf = \"path/to/my_annotated_vcf.vcf\",) Where model is a kipoi model - replace my_model_name by a valid model name. dataloader_arguments contains all the kwargs that are necessary to run the dataloader. The coordinates in the input_vcf have to match the genome / assembly etc. of the raw input files used by the dataloader. The output of score_variants is an annotated VCF - output_vcf . For more details please look at the detailed function description of score_variants . For details on the different scoring methods please take a look at the detailed explanation of variant effect prediction or the API defintion. The above code will run the dataloader based with dataloader_arguments and try to overlap the input VCF with the sequences generated by the dataloader. If a model dataloader accepts bed files input to control the generated regions, then a temporary bed file with variant-centered regions will be generated. If the dataloader does not offer a bed file input then the inputs generated by the dataloader will automatically be overlapped with the positions in the VCF and only the overlapping regions / variants are tested. For more control over the region generation please use kipoi.postprocessing.variant_effects.predict_snvs function's vcf_to_region argument with SnvCenteredRg , SnvPosRestrictedRg , or None . In the following section features of both functions score_variants and predict_snvs will be explained - please keep in mind that score_variants is a wrapper function around predict_snvs to cover most frequent use cases and reduce complexity of the user's code. Test region generation based on VCFs: Variant-centered effect prediction In the above example the regions were defined by the dataloader arguments, but if the dataloader supports bed file input (see dataloader.yaml definition for variant effect prediction) then the SnvCenteredRg class can generate a temporary bed file using a VCF and information on the required input sequence length from the model.yaml which is extracted by the ModelInfoExtractor instance model_info : from kipoi.postprocessing.variant_effects import SnvCenteredRg vcf_to_region = SnvCenteredRg(model_info) The resulting vcf_to_region object can then be used as the vcf_to_region argument when calling predict_snvs . Restricted variant-centered effect prediction This funcionality is similar to variant-centered effect prediction - the only difference is that this function is designed for models that can't predict on arbitrary regions of the genome, but only in certain regions of the genome. If those regions can be defined in a bed file (further on called 'restriction-bed' file) then this approach can be used. Variant effect prediction will then intersect the VCF with the restriction-bed and generate another bed file that is then passed on to the dataloader. Regions in the restriction-bed file may be larger than the input sequence lenght, in that case the generated seuqence will be centered on the variant position as much as possible - restricted by what is defined in the restrictions-bed file. The SnvPosRestrictedRg class can generate a temporary bed file using a VCF, the restrictions-bed file ( restricted_regions_fpath in the example below) and information on the required input sequence length from the model.yaml which is extracted by the ModelInfoExtractor instance model_info : from kipoi.postprocessing.variant_effects import SnvPosRestrictedRg import pybedtools as pb pbd = pb.BedTool(restricted_regions_fpath) vcf_to_region = SnvPosRestrictedRg(model_info, pbd) The resulting vcf_to_region object can then be used as the vcf_to_region argument when calling predict_snvs . Scoring functions Scoring functions perform calculations on the model predictions for the reference and alternative sequences. Default scoring functions are: Logit , LogitAlt , LogitRef , Diff , DeepSEA_effect . These functions are described in more detail in the variant effect prediction pages. These and custom scoring functions can be used in the score_variants function by setting the scores as a list of strings, for example: [\"logit\", \"diff\"] . This list can contain strings of the implemented scoring functions ( \"diff\" , \"ref\" , \"alt\" , \"logit\" , \"logit_ref\" , \"logit_alt\" , \"deepsea_effect\" ) or callables that are inherited from RCScore . Fine-tuning scoring functions The default scoring functions ( Logit , LogitAlt , LogitRef , Diff , DeepSEA_effect ) offer different options on how the forward and the reverse complement sequences are merged together. They have an rc_merging argument which can be \"min\" , \"max\" , \"mean\" , \"median\" or \"absmax\" . So when using the score_variants function the maximum between forward and reverse complement sequences for the alt-ref prediction differences should be returned, then the scores_kargs argument would be: [{\"rc_merging\": \"max\"}] and scores would be [\"diff\"] . The default rc_merging value is \"mean\" . Saving mutated sequence sets to a file A specialised feature of the predict_snvs function that is only available when using the python functions is to save the mutated sequence sets in a file. This can be useful for quality control or if a non-deeplearning model outside the model zoo should be run using the same data. For those cases instances of the SyncHdf5SeqWriter can be used. If they are passed to predict_snvs as the argument generated_seq_writer then the respective sequences are written to a file. Keep in mind that when defining a generated_seq_writer then no actual effect prediction is performed, but only the reference/alternative sequence sets are generated and saved. Return predictions By default effect predicions are not kept in memory, but only written to the output VCF to ensure a low memory profile. By setting the parameter return_predictions = True in predict_snvs or in score_variants the effect predictions are accumulated in memory and the results are returned as a dictionary of DataFrames, where the keys are the labels of the used scoring functions and the DataFrames have the shape (number effect predictions, number of output tasks of the model). Using the command line interface Similar to kipoi predict variant effect prediction can be run by executing: kipoi postproc score_variants my_model_name \\ --dataloader_args '{...}' \\ --vcf_path path/to/my_vcf.vcf \\ --out_vcf_fpath path/to/my_annotated_vcf.vcf Exceptions are that if the dataloader of the model allows the definition of a bed input file, then the respective field in the --dataloader_args JSON will be replaced by a bed file that consists in regions that are centered on the variant position. That is, if in the dataloader.yaml file of the respective model the bed_input flag is set then the respective argument in the --dataloader_args will be overwritten. When using variant effect prediction from the command line and using --source dir , keep in mind that whatever the path is that you put where my_model_name stands in the above command is treated as your model name. Since the annotated VCF INFO tags contain the model name as an identifier, executing kipoi postproc score_variants ./ --source dir ... will result in an annotated VCF with the model name \".\", which is most probably not desired. For those cases kipoi postproc score_variants ... should be executed in at least one directory level higher than the one where the model.yaml file lies. Then the command will look similar to this kipoi postproc score_variants ./my_model --source dir ... and the annotated VCF INFO tags will contain './my_model'. Scoring functions Scoring functions perform calculations on the model predictions for the reference and alternative sequences. Default scoring functions are: logit , logit_alt , logit_ref , diff , deepsea_effect . These functions are described in more detail in the variant effect prediction pages. Given a model is compatible with said scoring functions one or more of those can be selected by using the --scoring argument, e.g.: --scoring diff logit . The model.yaml file defines which scoring functions are available for a model, with the exception that the diff scoring function is available for all models. In the model.yaml also additional custom scoring functions can be defined, for details on please see the variant effect prediction pages. The labels by which the different scoring functions are made available can also be defined in the model.yaml file using the name tag. Fine-tuning scoring functions Scoring functions may have or may even require arguments at instantiation. Those arguments can be passed as JSON dictionaries to scoring functions by using the --scoring_kwargs argument. If --scoring_kwargs is used then for every label set in --scoring there must be a --scoring_kwargs JSON in the exact same order. If the degault values should be used or no arguments are required then an empty dictionary ( {} ) can be used. For example: --scoring diff my_scr --scoring_kwargs '{}' '{my_arg:2}' will use diff with the default parameters and will instantiate my_scr(my_arg=2) . The default scoring functions ( logit , logit_alt , logit_ref , diff , deepsea_effect ) offer different options on how the forward and the reverse complement sequences are merged together. They have an rc_merging argument which can be \"min\" , \"max\" , \"mean\" , \"median\" or \"absmax\" . So if the maximum between forward and reverse complement sequences for the alt-ref prediction differences should be returned, then the command would be: --scoring diff --scoring_kwargs '{rc_merging:\"max\"}' . By default rc_merging is set to \"mean\" . Putting scoring functions into context with DeepSEA The DeepSEA model was one of the first publications to define variant effect prediction scores for deep learning models. Some of the effect scores of the kipoi-veff package are inspired by those. Here we wan to give an explanation how the original DeepSEA scores relate to the ones in kipoi-veff : The effect score or log2 fold change on the DeepSEA website is the same as using the logit function of kipoi-veff on DeepSEA/variantEffects and dividing all values by the constant: np.log(2) . The e-value of DeepSEA cannot be readily provided as it relies on a set of effect prediction of randomly selected variants. The file size is restrively big and hence was not added to the Kipoi model. The DeepSEA website uses a score to compare the tested variant against the set of random variants (See Q&A 2. ), this score is available in kipoi-veff as deepsea_effect . If you want to calculate the evalue locally then use deepsea_effect with the DeepSEA/variantEffects and compare your result to the set of predictions of 1M variants provided with the DeepSEA model.","title":"Variant effect prediction"},{"location":"variant_effect_pred/#using-variant-effect-prediction","text":"This chapter describes how to run variant prediction using a model in the zoo either using the python functionality or using the command line. A prerequesite is that the model is compatible with variant effect prediction (see: Variant effect prediction prerequesites for the model.yaml and dataloader.yaml)","title":"Using variant effect prediction"},{"location":"variant_effect_pred/#variant-effect-prediction-in-python","text":"Using variant effect prediction within python allows more flexibility in the finegrain details compared to using the command line interface. The core function of variant effect prediction is score_variants , which on the one hand requires a model with its dataloader as well as a valid VCF. The easiest way to run variant effect prediction is the following: from kipoi.postprocessing.variant_effects import score_variants dataloader_arguments = {...} score_variants(model = \"my_model_name\", dl_args = dataloader_arguments, input_vcf = \"path/to/my_vcf.vcf\", output_vcf = \"path/to/my_annotated_vcf.vcf\",) Where model is a kipoi model - replace my_model_name by a valid model name. dataloader_arguments contains all the kwargs that are necessary to run the dataloader. The coordinates in the input_vcf have to match the genome / assembly etc. of the raw input files used by the dataloader. The output of score_variants is an annotated VCF - output_vcf . For more details please look at the detailed function description of score_variants . For details on the different scoring methods please take a look at the detailed explanation of variant effect prediction or the API defintion. The above code will run the dataloader based with dataloader_arguments and try to overlap the input VCF with the sequences generated by the dataloader. If a model dataloader accepts bed files input to control the generated regions, then a temporary bed file with variant-centered regions will be generated. If the dataloader does not offer a bed file input then the inputs generated by the dataloader will automatically be overlapped with the positions in the VCF and only the overlapping regions / variants are tested. For more control over the region generation please use kipoi.postprocessing.variant_effects.predict_snvs function's vcf_to_region argument with SnvCenteredRg , SnvPosRestrictedRg , or None . In the following section features of both functions score_variants and predict_snvs will be explained - please keep in mind that score_variants is a wrapper function around predict_snvs to cover most frequent use cases and reduce complexity of the user's code.","title":"Variant effect prediction in python"},{"location":"variant_effect_pred/#test-region-generation-based-on-vcfs","text":"","title":"Test region generation based on VCFs:"},{"location":"variant_effect_pred/#variant-centered-effect-prediction","text":"In the above example the regions were defined by the dataloader arguments, but if the dataloader supports bed file input (see dataloader.yaml definition for variant effect prediction) then the SnvCenteredRg class can generate a temporary bed file using a VCF and information on the required input sequence length from the model.yaml which is extracted by the ModelInfoExtractor instance model_info : from kipoi.postprocessing.variant_effects import SnvCenteredRg vcf_to_region = SnvCenteredRg(model_info) The resulting vcf_to_region object can then be used as the vcf_to_region argument when calling predict_snvs .","title":"Variant-centered effect prediction"},{"location":"variant_effect_pred/#restricted-variant-centered-effect-prediction","text":"This funcionality is similar to variant-centered effect prediction - the only difference is that this function is designed for models that can't predict on arbitrary regions of the genome, but only in certain regions of the genome. If those regions can be defined in a bed file (further on called 'restriction-bed' file) then this approach can be used. Variant effect prediction will then intersect the VCF with the restriction-bed and generate another bed file that is then passed on to the dataloader. Regions in the restriction-bed file may be larger than the input sequence lenght, in that case the generated seuqence will be centered on the variant position as much as possible - restricted by what is defined in the restrictions-bed file. The SnvPosRestrictedRg class can generate a temporary bed file using a VCF, the restrictions-bed file ( restricted_regions_fpath in the example below) and information on the required input sequence length from the model.yaml which is extracted by the ModelInfoExtractor instance model_info : from kipoi.postprocessing.variant_effects import SnvPosRestrictedRg import pybedtools as pb pbd = pb.BedTool(restricted_regions_fpath) vcf_to_region = SnvPosRestrictedRg(model_info, pbd) The resulting vcf_to_region object can then be used as the vcf_to_region argument when calling predict_snvs .","title":"Restricted variant-centered effect prediction"},{"location":"variant_effect_pred/#scoring-functions","text":"Scoring functions perform calculations on the model predictions for the reference and alternative sequences. Default scoring functions are: Logit , LogitAlt , LogitRef , Diff , DeepSEA_effect . These functions are described in more detail in the variant effect prediction pages. These and custom scoring functions can be used in the score_variants function by setting the scores as a list of strings, for example: [\"logit\", \"diff\"] . This list can contain strings of the implemented scoring functions ( \"diff\" , \"ref\" , \"alt\" , \"logit\" , \"logit_ref\" , \"logit_alt\" , \"deepsea_effect\" ) or callables that are inherited from RCScore .","title":"Scoring functions"},{"location":"variant_effect_pred/#fine-tuning-scoring-functions","text":"The default scoring functions ( Logit , LogitAlt , LogitRef , Diff , DeepSEA_effect ) offer different options on how the forward and the reverse complement sequences are merged together. They have an rc_merging argument which can be \"min\" , \"max\" , \"mean\" , \"median\" or \"absmax\" . So when using the score_variants function the maximum between forward and reverse complement sequences for the alt-ref prediction differences should be returned, then the scores_kargs argument would be: [{\"rc_merging\": \"max\"}] and scores would be [\"diff\"] . The default rc_merging value is \"mean\" .","title":"Fine-tuning scoring functions"},{"location":"variant_effect_pred/#saving-mutated-sequence-sets-to-a-file","text":"A specialised feature of the predict_snvs function that is only available when using the python functions is to save the mutated sequence sets in a file. This can be useful for quality control or if a non-deeplearning model outside the model zoo should be run using the same data. For those cases instances of the SyncHdf5SeqWriter can be used. If they are passed to predict_snvs as the argument generated_seq_writer then the respective sequences are written to a file. Keep in mind that when defining a generated_seq_writer then no actual effect prediction is performed, but only the reference/alternative sequence sets are generated and saved.","title":"Saving mutated sequence sets to a file"},{"location":"variant_effect_pred/#return-predictions","text":"By default effect predicions are not kept in memory, but only written to the output VCF to ensure a low memory profile. By setting the parameter return_predictions = True in predict_snvs or in score_variants the effect predictions are accumulated in memory and the results are returned as a dictionary of DataFrames, where the keys are the labels of the used scoring functions and the DataFrames have the shape (number effect predictions, number of output tasks of the model).","title":"Return predictions"},{"location":"variant_effect_pred/#using-the-command-line-interface","text":"Similar to kipoi predict variant effect prediction can be run by executing: kipoi postproc score_variants my_model_name \\ --dataloader_args '{...}' \\ --vcf_path path/to/my_vcf.vcf \\ --out_vcf_fpath path/to/my_annotated_vcf.vcf Exceptions are that if the dataloader of the model allows the definition of a bed input file, then the respective field in the --dataloader_args JSON will be replaced by a bed file that consists in regions that are centered on the variant position. That is, if in the dataloader.yaml file of the respective model the bed_input flag is set then the respective argument in the --dataloader_args will be overwritten. When using variant effect prediction from the command line and using --source dir , keep in mind that whatever the path is that you put where my_model_name stands in the above command is treated as your model name. Since the annotated VCF INFO tags contain the model name as an identifier, executing kipoi postproc score_variants ./ --source dir ... will result in an annotated VCF with the model name \".\", which is most probably not desired. For those cases kipoi postproc score_variants ... should be executed in at least one directory level higher than the one where the model.yaml file lies. Then the command will look similar to this kipoi postproc score_variants ./my_model --source dir ... and the annotated VCF INFO tags will contain './my_model'.","title":"Using the command line interface"},{"location":"variant_effect_pred/#scoring-functions_1","text":"Scoring functions perform calculations on the model predictions for the reference and alternative sequences. Default scoring functions are: logit , logit_alt , logit_ref , diff , deepsea_effect . These functions are described in more detail in the variant effect prediction pages. Given a model is compatible with said scoring functions one or more of those can be selected by using the --scoring argument, e.g.: --scoring diff logit . The model.yaml file defines which scoring functions are available for a model, with the exception that the diff scoring function is available for all models. In the model.yaml also additional custom scoring functions can be defined, for details on please see the variant effect prediction pages. The labels by which the different scoring functions are made available can also be defined in the model.yaml file using the name tag.","title":"Scoring functions"},{"location":"variant_effect_pred/#fine-tuning-scoring-functions_1","text":"Scoring functions may have or may even require arguments at instantiation. Those arguments can be passed as JSON dictionaries to scoring functions by using the --scoring_kwargs argument. If --scoring_kwargs is used then for every label set in --scoring there must be a --scoring_kwargs JSON in the exact same order. If the degault values should be used or no arguments are required then an empty dictionary ( {} ) can be used. For example: --scoring diff my_scr --scoring_kwargs '{}' '{my_arg:2}' will use diff with the default parameters and will instantiate my_scr(my_arg=2) . The default scoring functions ( logit , logit_alt , logit_ref , diff , deepsea_effect ) offer different options on how the forward and the reverse complement sequences are merged together. They have an rc_merging argument which can be \"min\" , \"max\" , \"mean\" , \"median\" or \"absmax\" . So if the maximum between forward and reverse complement sequences for the alt-ref prediction differences should be returned, then the command would be: --scoring diff --scoring_kwargs '{rc_merging:\"max\"}' . By default rc_merging is set to \"mean\" .","title":"Fine-tuning scoring functions"},{"location":"variant_effect_pred/#putting-scoring-functions-into-context-with-deepsea","text":"The DeepSEA model was one of the first publications to define variant effect prediction scores for deep learning models. Some of the effect scores of the kipoi-veff package are inspired by those. Here we wan to give an explanation how the original DeepSEA scores relate to the ones in kipoi-veff : The effect score or log2 fold change on the DeepSEA website is the same as using the logit function of kipoi-veff on DeepSEA/variantEffects and dividing all values by the constant: np.log(2) . The e-value of DeepSEA cannot be readily provided as it relies on a set of effect prediction of randomly selected variants. The file size is restrively big and hence was not added to the Kipoi model. The DeepSEA website uses a score to compare the tested variant against the set of random variants (See Q&A 2. ), this score is available in kipoi-veff as deepsea_effect . If you want to calculate the evalue locally then use deepsea_effect with the DeepSEA/variantEffects and compare your result to the set of predictions of 1M variants provided with the DeepSEA model.","title":"Putting scoring functions into context with DeepSEA"},{"location":"api/KipoiVCFParser/","text":"KipoiVCFParser KipoiVCFParser(self, vcf_file) Iteratively parse a vcf file into a dictionary. This class was designed to work well with VCFs annotated by kipoi-veff . It performs automated shortening of column names. Arguments vcf_file : .vcf file path (can be also .vcf.gz, .bcf, .bcf.gz) Notes Iterator returns a nested dictionary with the schema: - variant: - id - chr - pos - ref - alt - other: - f1 - f2 - kipoi: - model: - type: - feature1... - feature2...","title":"KipoiVCFParser"},{"location":"api/MutationMap/","text":"MutationMap MutationMap(self, model, dataloader, dataloader_args=None, use_dataloader_example_data=False) Generate mutation map Prediction of effects of every base at every position of datalaoder input sequences. The regions for which the effect scores will be calculated are primarily defined by the dataloader input. Arguments model : A kipoi model handle generated by e.g.: kipoi.get_model() dataloader : Dataloader factory generated by e.g.: kipoi.get_dataloader_factory() dataloader_args : arguments passed on to the dataloader for sequence generation, arguments mentioned in dataloader.yaml > postprocessing > variant_effects > bed_input will be overwritten by the methods here. use_dataloader_example_data : Fill out the missing dataloader arguments with the example values given in the dataloader.yaml. query_region MutationMap.query_region(self, chrom, start, end, seq_length=None, scores=['logit_ref', 'logit_alt', 'ref', 'alt', 'logit', 'diff'], score_kwargs=None, **kwargs) Generate mutation map Prediction of effects of every base at every position of datalaoder input sequences. The regions for which the effect scores will be calculated are primarily defined by the dataloader input. If the dataloader accepts bed file inputs then this file will be overwritten with regions defined here of length seq_length or the model input sequence length. If that is not available all datalaoder-generated regions that overlap the region defined here will be investigated. Effect scores are returned as MutationMapPlotter object which can be saved to an hdf5 file and used for plotting. It is important to mention that the order of the scored sequences is the order in which the dataloader has produced data input - intersected with the region defined here. Arguments chrom : Chrosome of region of interest. Assembly is defined by the dataload arguments. start : Start of region of interest. Assembly is defined by the dataload arguments. end : End of region of interest. Assembly is defined by the dataload arguments. seq_length : Optional argument of model sequence length to use if model accepts variable input sequence length. scores : list of score names to compute. See kipoi_veff.scores score_kwargs : optional, list of kwargs that corresponds to the entries in score. Returns MutationMapPlotter : object containing variant scores. query_bed MutationMap.query_bed(self, bed_fpath, seq_length=None, scores=['logit_ref', 'logit_alt', 'ref', 'alt', 'logit', 'diff'], score_kwargs=None, **kwargs) Generate mutation map Prediction of effects of every base at every position of datalaoder input sequences. The regions for which the effect scores will be calculated are primarily defined by the dataloader input. If the dataloader accepts bed file inputs then this file will be overwritten with regions defined in bed_fpath of length seq_length or the model input sequence length. If that is not available all datalaoder-generated regions that overlap the region defined here will be investigated. Effect scores are returned as MutationMapPlotter object which can be saved to an hdf5 file and used for plotting. It is important to mention that the order of the scored sequences is the order in which the dataloader has produced data input - intersected with bed_fpath . Arguments bed_fpath : Only genomic regions overlapping regions in this bed file will be evaluated. If the dataloader accepts bed file input then the dataloader bed input file will be overwritten with regions based this ( bed_fpath ) bed file. Assembly is defined by the dataload arguments. seq_length : Optional argument of model sequence length to use if model accepts variable input sequence length. scores : list of score names to compute. See kipoi_veff.scores score_kwargs : optional, list of kwargs that corresponds to the entries in score. Returns MutationMapPlotter : object containing variant scores. query_vcf MutationMap.query_vcf(self, vcf_fpath, seq_length=None, scores=['logit_ref', 'logit_alt', 'ref', 'alt', 'logit', 'diff'], score_kwargs=None, var_centered_regions=True, **kwargs) Generate mutation map Prediction of effects of every base at every position of datalaoder input sequences. The regions for which the effect scores will be calculated are primarily defined by the dataloader input. If the dataloader accepts bed file inputs then this file will be overwritten with regions generaten from the SNVs in vcf_fpath in a variant-centered fashion. Sequence length is defined by seq_length or the model input sequence length. If the datalaoder does not have a bed file input all datalaoder-generated regions that overlap SNVs here will be investigated. Effect scores are returned as MutationMapPlotter object which can be saved to an hdf5 file and used for plotting. It is important to mention that the order of the scored sequences is the order in which the dataloader has produced data input - intersected with vcf_fpath . Arguments vcf_fpath : Only genomic regions overlapping the variants in this VCF will be evaluated. Variants defined here will be highlighted in mutation map plots. Only SNVs will be used. If vcf_to_region is defined and the dataloader accepts bed file input then the dataloader bed input file will be overwritten with regions based on variant positions of this VCF. seq_length : Optional argument of model sequence length to use if model accepts variable input sequence length. var_centered_regions : Generate variant-centered regions if the model accepts that. If a custom vcf_to_region should be used then this can be set explicitly in the kwargs. scores : list of score names to compute. See kipoi_veff.scores score_kwargs : optional, list of kwargs that corresponds to the entries in score. Returns MutationMapPlotter : object containing variant scores.","title":"MutationMap"},{"location":"api/MutationMapPlotter/","text":"MutationMapPlotter MutationMapPlotter(self, mutation_map=None, fname=None) Generate a mutation map plot Arguments mutation_map : mutation map object fname : alternatively, specify path to the mutation map save_to_file MutationMapPlotter.save_to_file(self, fname) Save object to an hdf5 file Arguments fname : file path plot_mutmap MutationMapPlotter.plot_mutmap(self, input_entry, model_seq_input, scoring_key, model_output, ax=None, show_letter_scale=False, cmap=None, limit_region=None, limit_region_genomic=None, annotation_vcf=None, annotation_variants=None, ignore_stored_var_annotation=False, rc_plot=False, minimum_letter_height=None, cbar=True, var_box_color='black', show_var_id=True, grad_inp_style_lh=False) Generate a mutation map plot Arguments input_entry : index of the region generated by the dataloader. (Integer) model_seq_input : Model input sequence key as defined in model.yaml. e.g. seq scoring_key : Key given for the scoring method. E.g.: diff model_output : Model output name for which the mutation map should be plotted ax : matplotlib axis object show_letter_scale : Display letter scale for seqlogo cmap : Colourmap for the heatmap limit_region : Limit the plotted region: Tuple of (x_start, x_end) where both x_* are integer in [0,sequence_length) limit_region_genomic : Like limit_region but a tuple of genomic positions. Values outside the queried regions are ignored. Region definition has to 0-based! annotation_vcf : VCF used for additional variant annotation in the plot. Only SNVs will be used. annotation_variants : dictionary with key: chr , pos , id , ref , alt and values are lists of strings, except for pos which is a list of integers of 1-based variant positions. ignore_stored_var_annotation : Ignore annotations that have been stored with the mutation map on generation. rc_plot : Reverse-complement plotting minimum_letter_height : Require a minimum height of the reference base. proportion of maximum letter height. e.g. 0.2","title":"MutationMapPlotter"},{"location":"api/predict_snvs/","text":"predict_snvs predict_snvs(model, dataloader, vcf_fpath, batch_size, num_workers=0, dataloader_args=None, vcf_to_region=None, vcf_id_generator_fn=<function default_vcf_id_gen at 0x7fc1bbad38c8>, evaluation_function=<function analyse_model_preds at 0x7fc1bb96e1e0>, evaluation_function_kwargs={'diff_types': {'logit': <kipoi_veff.scores.Logit object at 0x7fc1bb969588>}}, sync_pred_writer=None, use_dataloader_example_data=False, return_predictions=False, generated_seq_writer=None) Predict the effect of SNVs Prediction of effects of SNV based on a VCF. If desired the VCF can be stored with the predicted values as annotation. For a detailed description of the requirements in the yaml files please take a look at the core kipoi documentation on how to write a dataloader.yaml file or at the documentation of kipoi-veff in the section: overview/#model-and-dataloader-requirements . The evaluation_function is evaluated after the model predictions for reference and alternative allele were performed. By default the analyse_model_preds function is used, which executes the functions defined in its argument diff_types on the reference and alternative prediction of every sample. When using the default analyse_model_preds , then evaluation_function_kwargs has to be set to {'diff_types': <dict>} , where dict is a dictionary of scoring functions (subclasses of kipoi_veff.scores.Score ) and the keys will be used to annotate the VCF (and dataframe) returned by predict_snvs . Arguments model : A kipoi model handle generated by e.g.: kipoi.get_model() dataloader : Dataloader factory generated by e.g.: kipoi.get_dataloader_factory() vcf_fpath : Path of the VCF defining the positions that shall be assessed. Only SNVs will be tested. batch_size : Prediction batch size used for calling the data loader. Each batch will be generated in 4 mutated states yielding a system RAM consumption of >= 4x batch size. num_workers : Number of parallel workers for loading the dataset. dataloader_args : arguments passed on to the dataloader for sequence generation, arguments mentioned in dataloader.yaml > postprocessing > variant_effects > bed_input will be overwritten by the methods here. vcf_to_region : Callable that generates a region compatible with dataloader/model from a cyvcf2 record vcf_id_generator_fn : Callable that generates a unique ID from a cyvcf2 record evaluation_function : effect evaluation function. Default is analyse_model_preds , which will get arguments defined in evaluation_function_kwargs evaluation_function_kwargs : kwargs passed on to evaluation_function . sync_pred_writer : Single writer or list of writer objects like instances of VcfWriter . This object will be called after effect prediction of a batch is done. use_dataloader_example_data : Fill out the missing dataloader arguments with the example values given in the dataloader.yaml. return_predictions : Return all variant effect predictions as a dictionary. Setting this to False will help maintain a low memory profile and is faster as it avoids concatenating batches after prediction. generated_seq_writer : Single writer or list of writer objects like instances of SyncHdf5SeqWriter . This object will be called after the DNA sequence sets have been generated. If this parameter is not None, no prediction will be performed and only DNA sequence will be written!! This is relevant if you want to use the predict_snvs to generate appropriate input DNA sequences for your model. Returns dict : containing a pandas DataFrame containing the calculated values for each model output (target) column VCF SNV line. If return_predictions == False , returns None.","title":"predict_snvs"},{"location":"api/score_variants/","text":"score_variants score_variants(model, dl_args, input_vcf, output_vcf=None, output_writers=None, scores=['logit_ref', 'logit_alt', 'ref', 'alt', 'logit', 'diff'], score_kwargs=None, num_workers=0, batch_size=32, source='kipoi', seq_length=None, std_var_id=False, restriction_bed=None, return_predictions=False, model_outputs=None) Score variants: annotate the vcf file using model predictions for the reference and alternative alleles The functional elements that generate a score from a set of predictions for reference and alternative allele are defined in the scores argument. This function is the python version of the command-line call score_variants and is a convenience version of the predict_snvs function: Prediction of effects of SNV based on a VCF. If desired the VCF can be stored with the predicted values as annotation. For a detailed description of the requirements in the yaml files please take a look at the core kipoi documentation on how to write a dataloader.yaml file or at the documentation of kipoi-veff in the section: overview/#model-and-dataloader-requirements . Arguments model : model string or a model class instance dl_args : dataloader arguments as a dictionary input_vcf : input vcf file path output_vcf : output vcf file path output_writers : output writers a list of used output writers scores : list of score names to compute. See kipoi_veff.scores score_kwargs : optional, list of kwargs that corresponds to the entries in score. num_workers : number of paralell workers to use for dataloading batch_size : batch_size for dataloading source : model source name std_var_id : If true then variant IDs in the annotated VCF will be replaced with a standardised, unique ID. seq_length : If model accepts variable input sequence length then this value has to be set! restriction_bed : If dataloader can be run with regions generated from the VCF then only variants that overlap regions defined in restriction_bed will be tested. return_predictions : return generated predictions also as pandas dataframe. model_outputs : If set then either a boolean filter or a named filter for model outputs that are reported. Returns dict : containing a pandas DataFrame containing the calculated values for each model output (target) column VCF SNV line. If return_predictions == False , returns None.","title":"score_variants"},{"location":"api/scores/","text":"kipoi_veff.scores Ref Ref(self, rc_merging='mean') Returns the predictions for the reference allele. If the predictions were executed taking the reverse-complement of the sequence into account then the returned value is averaged by the function defined in rc_merging . Allowed values for rc_merging are: \"min\", \"max\", \"mean\", \"median\", \"absmax\" or any callable that accepts/expects two arguments: my_func(fwd_pred, rc_pred) . Reverse-complement-averaging, where applicable, is performed after score calculation. Alt Alt(self, rc_merging='mean') Returns the predictions for the alternative allele. If the predictions were executed taking the reverse-complement of the sequence into account then the returned value is averaged by the function defined in rc_merging . Allowed values for rc_merging are: \"min\", \"max\", \"mean\", \"median\", \"absmax\" or any callable that accepts/expects two arguments: my_func(fwd_pred, rc_pred) . Reverse-complement-averaging, where applicable, is performed after score calculation. Diff Diff(self, rc_merging='mean') Returns the difference between predictions for the reference and alternative sequences prediction difference: diff = p_alt - p_ref If the predictions were executed taking the reverse-complement of the sequence into account then the returned value is averaged by the function defined in rc_merging . Allowed values for rc_merging are: \"min\", \"max\", \"mean\", \"median\", \"absmax\" or any callable that accepts/expects two arguments: my_func(fwd_pred, rc_pred) . Reverse-complement-averaging, where applicable, is performed after score calculation. LogitRef LogitRef(self, rc_merging='mean') Returns the predictions for the reference allele on the logit scale: np.log(p_alt / (1 - p_alt )) . If the predictions were executed taking the reverse-complement of the sequence into account then the returned value is averaged by the function defined in rc_merging . Allowed values for rc_merging are: \"min\", \"max\", \"mean\", \"median\", \"absmax\" or any callable that accepts/expects two arguments: my_func(fwd_pred, rc_pred) . Reverse-complement-averaging, where applicable, is performed after score calculation. LogitAlt LogitAlt(self, rc_merging='mean') Returns the predictions for the alternative allele on the logit scale: np.log(p_alt / (1 - p_alt )) If the predictions were executed taking the reverse-complement of the sequence into account then the returned value is averaged by the function defined in rc_merging . Allowed values for rc_merging are: \"min\", \"max\", \"mean\", \"median\", \"absmax\" or any callable that accepts/expects two arguments: my_func(fwd_pred, rc_pred) . Reverse-complement-averaging, where applicable, is performed after score calculation. Logit Logit(self, rc_merging='mean') Returns the difference between predictions for the reference and alternative sequences on the logit scale: logit_diff = log(p_alt / (1 - p_alt )) - log(p_ref / (1 - p_ref )) If the predictions were executed taking the reverse-complement of the sequence into account then the returned value is averaged by the function defined in rc_merging . Allowed values for rc_merging are: \"min\", \"max\", \"mean\", \"median\", \"absmax\" or any callable that accepts/expects two arguments: my_func(fwd_pred, rc_pred) . Reverse-complement-averaging, where applicable, is performed after score calculation. DeepSEA_effect DeepSEA_effect(self, rc_merging='mean') Returns the score used by DeepSEA in order to calculate the e-value: abs(logit_diff) * abs(diff) If the predictions were executed taking the reverse-complement of the sequence into account then the returned value is averaged by the function defined in rc_merging . Allowed values for rc_merging are: \"min\", \"max\", \"mean\", \"median\", \"absmax\" or any callable that accepts/expects two arguments: my_func(fwd_pred, rc_pred) . Reverse-complement-averaging, where applicable, is performed after score calculation.","title":"Available scores"},{"location":"tutorials/mutation_map/","text":"Generated from notebooks/mutation_map.ipynb Generate a mutation map This inotebook shall give an simple introduction in how to produce mutation maps for all models that are enabled for variant effect prediction. Let's use the DeepSEA/variantEffects model. Variant selection In this example we will first run the variant effect prediction code that is described in detail in the variant_effect_prediction_simple.ipynb . We will use these effect scores to select variants with the strongest effects to then visualise one of those variants in a mutation map. # First let's select and setup the model: import kipoi model_name = \"DeepSEA/variantEffects\" #kipoi.pipeline.install_model_requirements(model_name) # The input vcf path vcf_path = \"example_data/clinvar_donor_acceptor_chr22.vcf\" # The output vcf path, based on the input file name out_vcf_fpath = vcf_path[:-4] + \"%s.vcf\"%model_name.replace(\"/\", \"_\") # The datalaoder keyword arguments dataloader_arguments = {\"fasta_file\": \"example_data/hg19_chr22.fa\"} # Now actually run the effect prediction using the logit difference: import kipoi_veff.snv_predict as sp sp.score_variants(model = model_name, dl_args = dataloader_arguments, scores = [\"logit\"], input_vcf = vcf_path, output_vcf = out_vcf_fpath) 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 14/14 [00:34<00:00, 2.43s/it] Just like in the variant_effect_prediction_simple.ipynb we will now load the results from the generated VCF into a dataframe for easy data access: from kipoi_veff.parsers import KipoiVCFParser vcf_reader = KipoiVCFParser(\"example_data/clinvar_donor_acceptor_chr22DeepSEA_variantEffects.vcf\") import pandas as pd entries = [el for el in vcf_reader] entries_df = pd.DataFrame(entries) entries_df.index = entries_df[\"variant_id\"] Now we can select a subset of variants that score with the strongest score across the most model output tasks: # select the 5 variants with the most universal strongest predicted effect in chr22 logit_cols = entries_df.columns.str.contains(\"LOGIT\") top5_vars = entries_df.loc[:,logit_cols].abs().idxmax().value_counts().head() top5_vars 12342 305 16376 194 8374 127 22158 65 9970 54 dtype: int64 Now make a subset dataframe: top5_df = entries_df.loc[entries_df[\"variant_id\"].isin(top5_vars.index)] top5_df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } variant_id variant_chr variant_pos variant_ref variant_alt KV_DeepSEA/variantEffects_LOGIT_8988T_DNase_None_0 KV_DeepSEA/variantEffects_LOGIT_AoSMC_DNase_None_1 KV_DeepSEA/variantEffects_LOGIT_Chorion_DNase_None_2 KV_DeepSEA/variantEffects_LOGIT_CLL_DNase_None_3 KV_DeepSEA/variantEffects_LOGIT_Fibrobl_DNase_None_4 ... KV_DeepSEA/variantEffects_LOGIT_Osteoblasts_H2AZ_None_910 KV_DeepSEA/variantEffects_LOGIT_Osteoblasts_H3K27ac_None_911 KV_DeepSEA/variantEffects_LOGIT_Osteoblasts_H3K27me3_None_912 KV_DeepSEA/variantEffects_LOGIT_Osteoblasts_H3K36me3_None_913 KV_DeepSEA/variantEffects_LOGIT_Osteoblasts_H3K4me1_None_914 KV_DeepSEA/variantEffects_LOGIT_Osteoblasts_H3K4me2_None_915 KV_DeepSEA/variantEffects_LOGIT_Osteoblasts_H3K4me3_None_916 KV_DeepSEA/variantEffects_LOGIT_Osteoblasts_H3K79me2_None_917 KV_DeepSEA/variantEffects_LOGIT_Osteoblasts_H3K9me3_None_918 KV_DeepSEA/variantEffects_rID_unnamed_0_0 variant_id 16376 16376 chr22 29108009 G C -2.560048 -2.604959 -1.476766 -1.966083 -1.286860 ... 0.068821 0.474027 0.227797 0.258411 0.544803 0.144552 0.175402 0.575531 0.055439 chr22:29108009:G:['C'] 22158 22158 chr22 29121356 C G 0.148644 2.256156 0.885380 -0.016387 0.423442 ... 0.033477 0.043208 -0.120319 -0.324504 0.189594 0.147367 -0.087590 -0.388921 -0.023764 chr22:29121356:C:['G'] 9970 9970 chr22 36701970 G A 0.504692 1.658696 1.032887 -0.148108 0.914291 ... 0.321597 0.299887 0.003522 -0.060838 0.473003 0.342598 0.247115 -0.056063 -0.063615 chr22:36701970:G:['A'] 8374 8374 chr22 40750331 A G 0.571587 0.248589 0.201321 1.890934 0.111852 ... 0.421956 -0.020715 -0.156171 -0.151327 0.022475 0.192291 0.189058 -0.144645 -0.187582 chr22:40750331:A:['G'] 12342 12342 chr22 50964903 C G -1.935331 -2.190516 -1.468465 -1.936842 -1.670801 ... 0.236538 0.432350 0.886636 0.113601 0.007765 -0.198594 -0.245576 0.767322 -0.188115 chr22:50964903:C:['G'] 5 rows \u00d7 925 columns Based on that selection let's now generate an input VCF file that can then be used for mutation map calculation: query_vcf = \"example_data/clinvar_donor_acceptor_chr22_5vars.vcf\" variant_order = [] # now subset the VCF: with open(query_vcf, \"w\") as ofh: with open(vcf_path, \"r\") as ifh: for l in ifh: els = l.split(\" \") if l.startswith(\"#\"): ofh.write(l) elif els[2] in top5_vars.index.tolist(): variant_order.append(els[2]) ofh.write(l) ! cat $query_vcf ##fileformat=VCFv4.0 ##FILTER=<ID=PASS,Description=\"All filters passed\"> ##contig=<ID=chr1,length=249250621> ##contig=<ID=chr2,length=243199373> ##contig=<ID=chr3,length=198022430> ##contig=<ID=chr4,length=191154276> ##contig=<ID=chr5,length=180915260> ##contig=<ID=chr6,length=171115067> ##contig=<ID=chr7,length=159138663> ##contig=<ID=chr8,length=146364022> ##contig=<ID=chr9,length=141213431> ##contig=<ID=chr10,length=135534747> ##contig=<ID=chr11,length=135006516> ##contig=<ID=chr12,length=133851895> ##contig=<ID=chr13,length=115169878> ##contig=<ID=chr14,length=107349540> ##contig=<ID=chr15,length=102531392> ##contig=<ID=chr16,length=90354753> ##contig=<ID=chr17,length=81195210> ##contig=<ID=chr18,length=78077248> ##contig=<ID=chr19,length=59128983> ##contig=<ID=chr20,length=63025520> ##contig=<ID=chr21,length=48129895> ##contig=<ID=chr22,length=51304566> ##contig=<ID=chrX,length=155270560> ##contig=<ID=chrY,length=59373566> ##contig=<ID=chrMT,length=16569> #CHROM POS ID REF ALT QUAL FILTER INFO chr22 40750331 8374 A G . . . chr22 36701970 9970 G A . . . chr22 50964903 12342 C G . . . chr22 29108009 16376 G C . . . chr22 29121356 22158 C G . . . Now we also want the dataframe to have the same order as the VCF: top5_df = top5_df.loc[variant_order, :] top5_df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } variant_id variant_chr variant_pos variant_ref variant_alt KV_DeepSEA/variantEffects_LOGIT_8988T_DNase_None_0 KV_DeepSEA/variantEffects_LOGIT_AoSMC_DNase_None_1 KV_DeepSEA/variantEffects_LOGIT_Chorion_DNase_None_2 KV_DeepSEA/variantEffects_LOGIT_CLL_DNase_None_3 KV_DeepSEA/variantEffects_LOGIT_Fibrobl_DNase_None_4 ... KV_DeepSEA/variantEffects_LOGIT_Osteoblasts_H2AZ_None_910 KV_DeepSEA/variantEffects_LOGIT_Osteoblasts_H3K27ac_None_911 KV_DeepSEA/variantEffects_LOGIT_Osteoblasts_H3K27me3_None_912 KV_DeepSEA/variantEffects_LOGIT_Osteoblasts_H3K36me3_None_913 KV_DeepSEA/variantEffects_LOGIT_Osteoblasts_H3K4me1_None_914 KV_DeepSEA/variantEffects_LOGIT_Osteoblasts_H3K4me2_None_915 KV_DeepSEA/variantEffects_LOGIT_Osteoblasts_H3K4me3_None_916 KV_DeepSEA/variantEffects_LOGIT_Osteoblasts_H3K79me2_None_917 KV_DeepSEA/variantEffects_LOGIT_Osteoblasts_H3K9me3_None_918 KV_DeepSEA/variantEffects_rID_unnamed_0_0 variant_id 8374 8374 chr22 40750331 A G 0.571587 0.248589 0.201321 1.890934 0.111852 ... 0.421956 -0.020715 -0.156171 -0.151327 0.022475 0.192291 0.189058 -0.144645 -0.187582 chr22:40750331:A:['G'] 9970 9970 chr22 36701970 G A 0.504692 1.658696 1.032887 -0.148108 0.914291 ... 0.321597 0.299887 0.003522 -0.060838 0.473003 0.342598 0.247115 -0.056063 -0.063615 chr22:36701970:G:['A'] 12342 12342 chr22 50964903 C G -1.935331 -2.190516 -1.468465 -1.936842 -1.670801 ... 0.236538 0.432350 0.886636 0.113601 0.007765 -0.198594 -0.245576 0.767322 -0.188115 chr22:50964903:C:['G'] 16376 16376 chr22 29108009 G C -2.560048 -2.604959 -1.476766 -1.966083 -1.286860 ... 0.068821 0.474027 0.227797 0.258411 0.544803 0.144552 0.175402 0.575531 0.055439 chr22:29108009:G:['C'] 22158 22158 chr22 29121356 C G 0.148644 2.256156 0.885380 -0.016387 0.423442 ... 0.033477 0.043208 -0.120319 -0.324504 0.189594 0.147367 -0.087590 -0.388921 -0.023764 chr22:29121356:C:['G'] 5 rows \u00d7 925 columns Calculating the mutation map Now we are set to generate a mutation map based on a VCF containing variants of interest: import kipoi model_name = \"DeepSEA/variantEffects\" #kipoi.pipeline.install_model_requirements(model_name) from kipoi_veff import MutationMap Set up the mutation map object with the necessary information such as the model and dataloader objects as well as the dataloader arguments to actually perform the calculation model = kipoi.get_model(model_name) dataloader = model.default_dataloader dataloader_arguments = {\"fasta_file\": \"example_data/hg19_chr22.fa\"} mm = MutationMap(model, dataloader, dataloader_args = dataloader_arguments) Mutation maps can be generated based on a VCF file ( mm.query_vcf ), based on a bed file ( mm.query_bed ) or in the python API also based on a region ( mm.query_region ) that is passed by arguments. Here we will be using the mm.query_vcf method: mmp = mm.query_vcf(query_vcf, scores = [\"logit\"]) The object returned by mm.query_* methods are MutationMapPlotter objects that can either be stored in a hdf5 file or be used for plotting using their plot_mutmap method. The data in the MutationMapPlotter is stored hierarchically by: Line of the query input (file), which is an integer number. For bed files the index is for regions of length of the model input that overlapped the regions defined in the region definition bed file. The name of the model (DNA sequence) input with regard to which the effect predictions were calculated. The scoring function defined by the score argument The model output task for which the effect prediction was calculated Therefore also for plotting one must select the dataset that should be plotted. Here we will select the fourth variant in the VCF (id: 16376) and the model task which had the strongest absolute predicted effect in our initial variant selection. # Fourth variant in the VCF sel_line = 3 # Select the model output being affected the most by this variant: model_task = top5_df.loc[:,logit_cols].iloc[sel_line].abs().idxmax().split(\"_LOGIT_\")[1] model_task 'SK-N-SH_RA_CTCF_None_385' mmp.plot_mutmap(sel_line, \"seq\", \"logit\", model_task) <matplotlib.axes._subplots.AxesSubplot at 0x2b0856e433c8> As we can see we can't see much. Everything is a bit squished, but the variant is already annotated with the ID that was given in the VCF file: 16376. By default the full input sequence length is displayed, which is 1000bp for the DeepSEA model. In order to zoom in let's find the variant position and then zoom down to a 80bp window surrounding the variant: var_pos = top5_df[\"variant_pos\"].iloc[sel_line] var_pos 29108009 In order to zoom in one can use the limit_region_genomic argument which accepts a tuple of two values - start and end of the genomic region (0-based) which should be selected for plotting. mmp.plot_mutmap(sel_line, \"seq\", \"logit\", model_task, limit_region_genomic=(var_pos -40, var_pos+40)) <matplotlib.axes._subplots.AxesSubplot at 0x2b0857c1b198> Now since we are looking at CTCF track one might suspect that the variant lies in a CTCF binding motif, but it is somewhat not 100% clear. Let's see whether a motif on the reverse strand is actually affected: mmp.plot_mutmap(sel_line, \"seq\", \"logit\", model_task, limit_region_genomic=(var_pos -40, var_pos+40), rc_plot=True) <matplotlib.axes._subplots.AxesSubplot at 0x2b085741f400> Add additional annotation (dbSNP) Now that we know how to zoom and reverse-complement mutation maps let's also try and highlight further variants in the region. For that I have prepared a subset of variants of the dbSNP b151 GRCh37 All_20180423.vcf.gz in the proximity of the selected variant. We can use this VCF to highlight dbSNP variants in the region. Let's first get the variant information into the right format: import cyvcf2 vcf_obj = cyvcf2.VCF(\"example_data/dbsnp_chr22_29108009.vcf\") variants = {\"chr\":[], \"pos\":[], \"id\":[], \"ref\":[], \"alt\":[]} for rec in vcf_obj: # skip indels if rec.is_indel: continue variants[\"chr\"].append(rec.CHROM) variants[\"pos\"].append(rec.POS) variants[\"id\"].append(rec.ID) variants[\"ref\"].append(rec.REF) variants[\"alt\"].append(rec.ALT[0]) Now we can plug this dictionary into the plotting method and take a look at our annotated plot. mmp.plot_mutmap(sel_line, \"seq\", \"logit\", model_task, limit_region_genomic=(var_pos -40, var_pos+40), rc_plot=True, annotation_variants = variants) <matplotlib.axes._subplots.AxesSubplot at 0x2b08574d6e10> Arguably it's not the most beautiful plot as labels start overlapping, so let's remove them and let's also exclude out seed variant, in order to highlight the difference we might actually also want to change the colour of the variant boxes to red: mmp.plot_mutmap(sel_line, \"seq\", \"logit\", model_task, limit_region_genomic=(var_pos -40, var_pos+40), rc_plot=True, annotation_variants = variants, show_var_id=False, ignore_stored_var_annotation=True,var_box_color=\"red\", ) <matplotlib.axes._subplots.AxesSubplot at 0x2b086f892f28> The CLI Mutation maps can be calculated using the command line interface analogously to the way presented above for the python API. Let's therefore collect all the input and output file names: import json model_name = \"DeepSEA/variantEffects\" dataloader_arguments_str = \"'%s'\"%json.dumps({\"fasta_file\": \"example_data/hg19_chr22.fa\"}) query_vcf = \"example_data/clinvar_donor_acceptor_chr22_5vars.vcf\" output_file = \"example_data/clinvar_donor_acceptor_chr22_5vars_mutmap.hdf5\" Now we are ready to calculate the mutation map data: ! kipoi veff create_mutation_map $model_name --dataloader_args $dataloader_arguments_str \\ --scores logit --output $output_file --regions_file $query_vcf The output of that was a hdf5 file that can either be loaded by the python API or by the CLI command plot_mutation_map as presented here: plot_file = \"example_data/clinvar_donor_acceptor_chr22_5vars_mmPlot.png\" region_start, region_end = var_pos -40, var_pos+40 ! kipoi veff plot_mutation_map --input_file $output_file \\ --output $plot_file --input_entry 3 --model_seq_input seq \\ --scoring_key logit --model_output \"SK-N-SH_RA_CTCF_None_385\" \\ --limit_region_genomic $region_start $region_end \\ --rc_plot \u001b[33mWARNING\u001b[0m \u001b[44m[kipoi.__main__]\u001b[0m `kipoi postproc` has been deprecated. Please use kipoi <plugin> ...: # - plugin commands: veff Variant effect prediction interpret Model interpretation using feature importance scores like ISM, grad*input or DeepLIFT. \u001b[0m And this is the result: from IPython.display import Image Image(filename=plot_file)","title":"Mutation map"},{"location":"tutorials/mutation_map/#generate-a-mutation-map","text":"This inotebook shall give an simple introduction in how to produce mutation maps for all models that are enabled for variant effect prediction. Let's use the DeepSEA/variantEffects model.","title":"Generate a mutation map"},{"location":"tutorials/mutation_map/#variant-selection","text":"In this example we will first run the variant effect prediction code that is described in detail in the variant_effect_prediction_simple.ipynb . We will use these effect scores to select variants with the strongest effects to then visualise one of those variants in a mutation map. # First let's select and setup the model: import kipoi model_name = \"DeepSEA/variantEffects\" #kipoi.pipeline.install_model_requirements(model_name) # The input vcf path vcf_path = \"example_data/clinvar_donor_acceptor_chr22.vcf\" # The output vcf path, based on the input file name out_vcf_fpath = vcf_path[:-4] + \"%s.vcf\"%model_name.replace(\"/\", \"_\") # The datalaoder keyword arguments dataloader_arguments = {\"fasta_file\": \"example_data/hg19_chr22.fa\"} # Now actually run the effect prediction using the logit difference: import kipoi_veff.snv_predict as sp sp.score_variants(model = model_name, dl_args = dataloader_arguments, scores = [\"logit\"], input_vcf = vcf_path, output_vcf = out_vcf_fpath) 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 14/14 [00:34<00:00, 2.43s/it] Just like in the variant_effect_prediction_simple.ipynb we will now load the results from the generated VCF into a dataframe for easy data access: from kipoi_veff.parsers import KipoiVCFParser vcf_reader = KipoiVCFParser(\"example_data/clinvar_donor_acceptor_chr22DeepSEA_variantEffects.vcf\") import pandas as pd entries = [el for el in vcf_reader] entries_df = pd.DataFrame(entries) entries_df.index = entries_df[\"variant_id\"] Now we can select a subset of variants that score with the strongest score across the most model output tasks: # select the 5 variants with the most universal strongest predicted effect in chr22 logit_cols = entries_df.columns.str.contains(\"LOGIT\") top5_vars = entries_df.loc[:,logit_cols].abs().idxmax().value_counts().head() top5_vars 12342 305 16376 194 8374 127 22158 65 9970 54 dtype: int64 Now make a subset dataframe: top5_df = entries_df.loc[entries_df[\"variant_id\"].isin(top5_vars.index)] top5_df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } variant_id variant_chr variant_pos variant_ref variant_alt KV_DeepSEA/variantEffects_LOGIT_8988T_DNase_None_0 KV_DeepSEA/variantEffects_LOGIT_AoSMC_DNase_None_1 KV_DeepSEA/variantEffects_LOGIT_Chorion_DNase_None_2 KV_DeepSEA/variantEffects_LOGIT_CLL_DNase_None_3 KV_DeepSEA/variantEffects_LOGIT_Fibrobl_DNase_None_4 ... KV_DeepSEA/variantEffects_LOGIT_Osteoblasts_H2AZ_None_910 KV_DeepSEA/variantEffects_LOGIT_Osteoblasts_H3K27ac_None_911 KV_DeepSEA/variantEffects_LOGIT_Osteoblasts_H3K27me3_None_912 KV_DeepSEA/variantEffects_LOGIT_Osteoblasts_H3K36me3_None_913 KV_DeepSEA/variantEffects_LOGIT_Osteoblasts_H3K4me1_None_914 KV_DeepSEA/variantEffects_LOGIT_Osteoblasts_H3K4me2_None_915 KV_DeepSEA/variantEffects_LOGIT_Osteoblasts_H3K4me3_None_916 KV_DeepSEA/variantEffects_LOGIT_Osteoblasts_H3K79me2_None_917 KV_DeepSEA/variantEffects_LOGIT_Osteoblasts_H3K9me3_None_918 KV_DeepSEA/variantEffects_rID_unnamed_0_0 variant_id 16376 16376 chr22 29108009 G C -2.560048 -2.604959 -1.476766 -1.966083 -1.286860 ... 0.068821 0.474027 0.227797 0.258411 0.544803 0.144552 0.175402 0.575531 0.055439 chr22:29108009:G:['C'] 22158 22158 chr22 29121356 C G 0.148644 2.256156 0.885380 -0.016387 0.423442 ... 0.033477 0.043208 -0.120319 -0.324504 0.189594 0.147367 -0.087590 -0.388921 -0.023764 chr22:29121356:C:['G'] 9970 9970 chr22 36701970 G A 0.504692 1.658696 1.032887 -0.148108 0.914291 ... 0.321597 0.299887 0.003522 -0.060838 0.473003 0.342598 0.247115 -0.056063 -0.063615 chr22:36701970:G:['A'] 8374 8374 chr22 40750331 A G 0.571587 0.248589 0.201321 1.890934 0.111852 ... 0.421956 -0.020715 -0.156171 -0.151327 0.022475 0.192291 0.189058 -0.144645 -0.187582 chr22:40750331:A:['G'] 12342 12342 chr22 50964903 C G -1.935331 -2.190516 -1.468465 -1.936842 -1.670801 ... 0.236538 0.432350 0.886636 0.113601 0.007765 -0.198594 -0.245576 0.767322 -0.188115 chr22:50964903:C:['G'] 5 rows \u00d7 925 columns Based on that selection let's now generate an input VCF file that can then be used for mutation map calculation: query_vcf = \"example_data/clinvar_donor_acceptor_chr22_5vars.vcf\" variant_order = [] # now subset the VCF: with open(query_vcf, \"w\") as ofh: with open(vcf_path, \"r\") as ifh: for l in ifh: els = l.split(\" \") if l.startswith(\"#\"): ofh.write(l) elif els[2] in top5_vars.index.tolist(): variant_order.append(els[2]) ofh.write(l) ! cat $query_vcf ##fileformat=VCFv4.0 ##FILTER=<ID=PASS,Description=\"All filters passed\"> ##contig=<ID=chr1,length=249250621> ##contig=<ID=chr2,length=243199373> ##contig=<ID=chr3,length=198022430> ##contig=<ID=chr4,length=191154276> ##contig=<ID=chr5,length=180915260> ##contig=<ID=chr6,length=171115067> ##contig=<ID=chr7,length=159138663> ##contig=<ID=chr8,length=146364022> ##contig=<ID=chr9,length=141213431> ##contig=<ID=chr10,length=135534747> ##contig=<ID=chr11,length=135006516> ##contig=<ID=chr12,length=133851895> ##contig=<ID=chr13,length=115169878> ##contig=<ID=chr14,length=107349540> ##contig=<ID=chr15,length=102531392> ##contig=<ID=chr16,length=90354753> ##contig=<ID=chr17,length=81195210> ##contig=<ID=chr18,length=78077248> ##contig=<ID=chr19,length=59128983> ##contig=<ID=chr20,length=63025520> ##contig=<ID=chr21,length=48129895> ##contig=<ID=chr22,length=51304566> ##contig=<ID=chrX,length=155270560> ##contig=<ID=chrY,length=59373566> ##contig=<ID=chrMT,length=16569> #CHROM POS ID REF ALT QUAL FILTER INFO chr22 40750331 8374 A G . . . chr22 36701970 9970 G A . . . chr22 50964903 12342 C G . . . chr22 29108009 16376 G C . . . chr22 29121356 22158 C G . . . Now we also want the dataframe to have the same order as the VCF: top5_df = top5_df.loc[variant_order, :] top5_df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } variant_id variant_chr variant_pos variant_ref variant_alt KV_DeepSEA/variantEffects_LOGIT_8988T_DNase_None_0 KV_DeepSEA/variantEffects_LOGIT_AoSMC_DNase_None_1 KV_DeepSEA/variantEffects_LOGIT_Chorion_DNase_None_2 KV_DeepSEA/variantEffects_LOGIT_CLL_DNase_None_3 KV_DeepSEA/variantEffects_LOGIT_Fibrobl_DNase_None_4 ... KV_DeepSEA/variantEffects_LOGIT_Osteoblasts_H2AZ_None_910 KV_DeepSEA/variantEffects_LOGIT_Osteoblasts_H3K27ac_None_911 KV_DeepSEA/variantEffects_LOGIT_Osteoblasts_H3K27me3_None_912 KV_DeepSEA/variantEffects_LOGIT_Osteoblasts_H3K36me3_None_913 KV_DeepSEA/variantEffects_LOGIT_Osteoblasts_H3K4me1_None_914 KV_DeepSEA/variantEffects_LOGIT_Osteoblasts_H3K4me2_None_915 KV_DeepSEA/variantEffects_LOGIT_Osteoblasts_H3K4me3_None_916 KV_DeepSEA/variantEffects_LOGIT_Osteoblasts_H3K79me2_None_917 KV_DeepSEA/variantEffects_LOGIT_Osteoblasts_H3K9me3_None_918 KV_DeepSEA/variantEffects_rID_unnamed_0_0 variant_id 8374 8374 chr22 40750331 A G 0.571587 0.248589 0.201321 1.890934 0.111852 ... 0.421956 -0.020715 -0.156171 -0.151327 0.022475 0.192291 0.189058 -0.144645 -0.187582 chr22:40750331:A:['G'] 9970 9970 chr22 36701970 G A 0.504692 1.658696 1.032887 -0.148108 0.914291 ... 0.321597 0.299887 0.003522 -0.060838 0.473003 0.342598 0.247115 -0.056063 -0.063615 chr22:36701970:G:['A'] 12342 12342 chr22 50964903 C G -1.935331 -2.190516 -1.468465 -1.936842 -1.670801 ... 0.236538 0.432350 0.886636 0.113601 0.007765 -0.198594 -0.245576 0.767322 -0.188115 chr22:50964903:C:['G'] 16376 16376 chr22 29108009 G C -2.560048 -2.604959 -1.476766 -1.966083 -1.286860 ... 0.068821 0.474027 0.227797 0.258411 0.544803 0.144552 0.175402 0.575531 0.055439 chr22:29108009:G:['C'] 22158 22158 chr22 29121356 C G 0.148644 2.256156 0.885380 -0.016387 0.423442 ... 0.033477 0.043208 -0.120319 -0.324504 0.189594 0.147367 -0.087590 -0.388921 -0.023764 chr22:29121356:C:['G'] 5 rows \u00d7 925 columns","title":"Variant selection"},{"location":"tutorials/mutation_map/#calculating-the-mutation-map","text":"Now we are set to generate a mutation map based on a VCF containing variants of interest: import kipoi model_name = \"DeepSEA/variantEffects\" #kipoi.pipeline.install_model_requirements(model_name) from kipoi_veff import MutationMap Set up the mutation map object with the necessary information such as the model and dataloader objects as well as the dataloader arguments to actually perform the calculation model = kipoi.get_model(model_name) dataloader = model.default_dataloader dataloader_arguments = {\"fasta_file\": \"example_data/hg19_chr22.fa\"} mm = MutationMap(model, dataloader, dataloader_args = dataloader_arguments) Mutation maps can be generated based on a VCF file ( mm.query_vcf ), based on a bed file ( mm.query_bed ) or in the python API also based on a region ( mm.query_region ) that is passed by arguments. Here we will be using the mm.query_vcf method: mmp = mm.query_vcf(query_vcf, scores = [\"logit\"]) The object returned by mm.query_* methods are MutationMapPlotter objects that can either be stored in a hdf5 file or be used for plotting using their plot_mutmap method. The data in the MutationMapPlotter is stored hierarchically by: Line of the query input (file), which is an integer number. For bed files the index is for regions of length of the model input that overlapped the regions defined in the region definition bed file. The name of the model (DNA sequence) input with regard to which the effect predictions were calculated. The scoring function defined by the score argument The model output task for which the effect prediction was calculated Therefore also for plotting one must select the dataset that should be plotted. Here we will select the fourth variant in the VCF (id: 16376) and the model task which had the strongest absolute predicted effect in our initial variant selection. # Fourth variant in the VCF sel_line = 3 # Select the model output being affected the most by this variant: model_task = top5_df.loc[:,logit_cols].iloc[sel_line].abs().idxmax().split(\"_LOGIT_\")[1] model_task 'SK-N-SH_RA_CTCF_None_385' mmp.plot_mutmap(sel_line, \"seq\", \"logit\", model_task) <matplotlib.axes._subplots.AxesSubplot at 0x2b0856e433c8> As we can see we can't see much. Everything is a bit squished, but the variant is already annotated with the ID that was given in the VCF file: 16376. By default the full input sequence length is displayed, which is 1000bp for the DeepSEA model. In order to zoom in let's find the variant position and then zoom down to a 80bp window surrounding the variant: var_pos = top5_df[\"variant_pos\"].iloc[sel_line] var_pos 29108009 In order to zoom in one can use the limit_region_genomic argument which accepts a tuple of two values - start and end of the genomic region (0-based) which should be selected for plotting. mmp.plot_mutmap(sel_line, \"seq\", \"logit\", model_task, limit_region_genomic=(var_pos -40, var_pos+40)) <matplotlib.axes._subplots.AxesSubplot at 0x2b0857c1b198> Now since we are looking at CTCF track one might suspect that the variant lies in a CTCF binding motif, but it is somewhat not 100% clear. Let's see whether a motif on the reverse strand is actually affected: mmp.plot_mutmap(sel_line, \"seq\", \"logit\", model_task, limit_region_genomic=(var_pos -40, var_pos+40), rc_plot=True) <matplotlib.axes._subplots.AxesSubplot at 0x2b085741f400>","title":"Calculating the mutation map"},{"location":"tutorials/mutation_map/#add-additional-annotation-dbsnp","text":"Now that we know how to zoom and reverse-complement mutation maps let's also try and highlight further variants in the region. For that I have prepared a subset of variants of the dbSNP b151 GRCh37 All_20180423.vcf.gz in the proximity of the selected variant. We can use this VCF to highlight dbSNP variants in the region. Let's first get the variant information into the right format: import cyvcf2 vcf_obj = cyvcf2.VCF(\"example_data/dbsnp_chr22_29108009.vcf\") variants = {\"chr\":[], \"pos\":[], \"id\":[], \"ref\":[], \"alt\":[]} for rec in vcf_obj: # skip indels if rec.is_indel: continue variants[\"chr\"].append(rec.CHROM) variants[\"pos\"].append(rec.POS) variants[\"id\"].append(rec.ID) variants[\"ref\"].append(rec.REF) variants[\"alt\"].append(rec.ALT[0]) Now we can plug this dictionary into the plotting method and take a look at our annotated plot. mmp.plot_mutmap(sel_line, \"seq\", \"logit\", model_task, limit_region_genomic=(var_pos -40, var_pos+40), rc_plot=True, annotation_variants = variants) <matplotlib.axes._subplots.AxesSubplot at 0x2b08574d6e10> Arguably it's not the most beautiful plot as labels start overlapping, so let's remove them and let's also exclude out seed variant, in order to highlight the difference we might actually also want to change the colour of the variant boxes to red: mmp.plot_mutmap(sel_line, \"seq\", \"logit\", model_task, limit_region_genomic=(var_pos -40, var_pos+40), rc_plot=True, annotation_variants = variants, show_var_id=False, ignore_stored_var_annotation=True,var_box_color=\"red\", ) <matplotlib.axes._subplots.AxesSubplot at 0x2b086f892f28>","title":"Add additional annotation (dbSNP)"},{"location":"tutorials/mutation_map/#the-cli","text":"Mutation maps can be calculated using the command line interface analogously to the way presented above for the python API. Let's therefore collect all the input and output file names: import json model_name = \"DeepSEA/variantEffects\" dataloader_arguments_str = \"'%s'\"%json.dumps({\"fasta_file\": \"example_data/hg19_chr22.fa\"}) query_vcf = \"example_data/clinvar_donor_acceptor_chr22_5vars.vcf\" output_file = \"example_data/clinvar_donor_acceptor_chr22_5vars_mutmap.hdf5\" Now we are ready to calculate the mutation map data: ! kipoi veff create_mutation_map $model_name --dataloader_args $dataloader_arguments_str \\ --scores logit --output $output_file --regions_file $query_vcf The output of that was a hdf5 file that can either be loaded by the python API or by the CLI command plot_mutation_map as presented here: plot_file = \"example_data/clinvar_donor_acceptor_chr22_5vars_mmPlot.png\" region_start, region_end = var_pos -40, var_pos+40 ! kipoi veff plot_mutation_map --input_file $output_file \\ --output $plot_file --input_entry 3 --model_seq_input seq \\ --scoring_key logit --model_output \"SK-N-SH_RA_CTCF_None_385\" \\ --limit_region_genomic $region_start $region_end \\ --rc_plot \u001b[33mWARNING\u001b[0m \u001b[44m[kipoi.__main__]\u001b[0m `kipoi postproc` has been deprecated. Please use kipoi <plugin> ...: # - plugin commands: veff Variant effect prediction interpret Model interpretation using feature importance scores like ISM, grad*input or DeepLIFT. \u001b[0m And this is the result: from IPython.display import Image Image(filename=plot_file)","title":"The CLI"},{"location":"tutorials/variant_effect_prediction/","text":"Generated from notebooks/variant_effect_prediction.ipynb Variant effect prediction Variant effect prediction offers a simple way to predict effects of SNVs using any model that uses DNA sequence as an input. Many different scoring methods can be chosen, but the principle relies on in-silico mutagenesis. The default input is a VCF and the default output again is a VCF annotated with predictions of variant effects. For details please take a look at the documentation in Postprocessing/Variant effect prediction. This iPython notebook goes through the basic programmatic steps that are needed to preform variant effect prediction. First a variant-centered approach will be taken and secondly overlap-based variant effect prediction will be presented. For details in how this is done programmatically, please refer to the documentation. Variant centered effect prediction Models that accept input .bed files can make use of variant-centered effect prediction. This procedure starts out from the query VCF and generates genomic regions of the length of the model input, centered on the individual variant in the VCF.The model dataloader is then used to produce the model input samples for those regions, which are then mutated according to the alleles in the VCF: First an instance of SnvCenteredRg generates a temporary bed file with regions matching the input sequence length defined in the model.yaml input schema. Then the model dataloader is used to preduce the model input in batches. These chunks of data are then modified by the effect prediction algorithm, the model batch prediction function is triggered for all mutated sequence sets and finally the scoring method is applied. The selected scoring methods compare model predicitons for sequences carrying the reference or alternative allele. Those scoring methods can be Diff for simple subtraction of prediction, Logit for substraction of logit-transformed model predictions, or DeepSEA_effect which is a combination of Diff and Logit , which was published in the Troyanskaya et al. (2015) publication. This ipython notebook assumes that it is executed in an environment in which all dependencies for the following models are installed: DeepSEA/vaariantEffects , HAL , labranchor , MaxEntScan , and rbp are installed, as well as the --vep flag has to be used during installing the dependencies. Now let's start out by loading the DeepSEA model and dataloader factory: import kipoi model_name = \"DeepSEA/variantEffects\" # get the model model = kipoi.get_model(model_name) # get the dataloader factory Dataloader = kipoi.get_dataloader_factory(model_name) Next we will have to define the variants we want to look at, let's look at a sample VCF in chromosome 22: !head -n 40 example_data/clinvar_donor_acceptor_chr22.vcf ##fileformat=VCFv4.0 ##FILTER=<ID=PASS,Description=\"All filters passed\"> ##contig=<ID=chr1,length=249250621> ##contig=<ID=chr2,length=243199373> ##contig=<ID=chr3,length=198022430> ##contig=<ID=chr4,length=191154276> ##contig=<ID=chr5,length=180915260> ##contig=<ID=chr6,length=171115067> ##contig=<ID=chr7,length=159138663> ##contig=<ID=chr8,length=146364022> ##contig=<ID=chr9,length=141213431> ##contig=<ID=chr10,length=135534747> ##contig=<ID=chr11,length=135006516> ##contig=<ID=chr12,length=133851895> ##contig=<ID=chr13,length=115169878> ##contig=<ID=chr14,length=107349540> ##contig=<ID=chr15,length=102531392> ##contig=<ID=chr16,length=90354753> ##contig=<ID=chr17,length=81195210> ##contig=<ID=chr18,length=78077248> ##contig=<ID=chr19,length=59128983> ##contig=<ID=chr20,length=63025520> ##contig=<ID=chr21,length=48129895> ##contig=<ID=chr22,length=51304566> ##contig=<ID=chrX,length=155270560> ##contig=<ID=chrY,length=59373566> ##contig=<ID=chrMT,length=16569> #CHROM POS ID REF ALT QUAL FILTER INFO chr22 41320486 4 G T . . . chr22 31009031 9 T G . . . chr22 43024150 15 C G . . . chr22 43027392 16 A G . . . chr22 37469571 122 C T . . . chr22 37465112 123 C G . . . chr22 37494466 124 G T . . . chr22 18561373 177 G T . . . chr22 51065593 241 C T . . . chr22 51064006 242 C T . . . chr22 51065269 243 G A . . . chr22 30032866 260 G T . . . Now we will define path variable for vcf input and output paths and instantiate a VcfWriter, which will write out the annotated VCF: import kipoi_veff from kipoi_veff import VcfWriter # The input vcf path vcf_path = \"example_data/clinvar_donor_acceptor_chr22.vcf\" # The output vcf path, based on the input file name out_vcf_fpath = vcf_path[:-4] + \"%s.vcf\"%model_name.replace(\"/\", \"_\") # The writer object that will output the annotated VCF writer = VcfWriter(model, vcf_path, out_vcf_fpath) Then we need to instantiate an object that can generate variant-centered regions ( SnvCenteredRg objects). This class needs information on the model input sequence length which is extracted automatically within ModelInfoExtractor objects: # Information extraction from dataloader and model model_info = kipoi_veff.ModelInfoExtractor(model, Dataloader) # vcf_to_region will generate a variant-centered regions when presented a VCF record. vcf_to_region = kipoi_veff.SnvCenteredRg(model_info) Now we can define the required dataloader arguments, omitting the intervals_file as this will be replaced by the automatically generated bed file: dataloader_arguments = {\"fasta_file\": \"example_data/hg19_chr22.fa\"} This is the moment to run the variant effect prediction: import kipoi_veff.snv_predict as sp from kipoi_veff.scores import Diff, DeepSEA_effect sp.predict_snvs(model, Dataloader, vcf_path, batch_size = 32, dataloader_args=dataloader_arguments, vcf_to_region=vcf_to_region, evaluation_function_kwargs={'diff_types': {'diff': Diff(\"mean\"), 'deepsea_effect': DeepSEA_effect(\"mean\")}}, sync_pred_writer=writer) 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 14/14 [00:34<00:00, 2.46s/it] In the example above we have used the variant scoring method Diff and DeepSEA_effect from kipoi_veff plug-in. As mentioned above variant scoring methods calculate the difference between predictions for reference and alternative, but there is another dimension to this: Models that have the use_rc: true flag set in their model.yaml file (DeepSEA/variantEffects does) will not only be queried with the reference and alternative carrying input sequences, but also with the reverse complement of the the sequences. In order to know of to combine predictions for forward and reverse sequences there is a initialisation flag (here set to: \"mean\" ) for the variant scoring methods. \"mean\" in this case means that after calculating the effect (e.g.: Difference) the average over the difference between the prediction for the forward and for the reverse sequence should be returned. Setting \"mean\" complies with what was used in the Troyanskaya et al. publication. Now let's look at the output: # Let's print out the first 40 lines of the annotated VCF (up to 80 characters per line maximum) with open(\"example_data/clinvar_donor_acceptor_chr22DeepSEA_variantEffects.vcf\") as ifh: for i,l in enumerate(ifh): long_line = \"\" if len(l)>80: long_line = \"...\" print(l[:80].rstrip() +long_line) if i >=40: break ##fileformat=VCFv4.0 ##INFO=<ID=KV:kipoi:DeepSEA/variantEffects:DIFF,Number=.,Type=String,Description... ##INFO=<ID=KV:kipoi:DeepSEA/variantEffects:DEEPSEA_EFFECT,Number=.,Type=String,D... ##INFO=<ID=KV:kipoi:DeepSEA/variantEffects:rID,Number=.,Type=String,Description=... ##FILTER=<ID=PASS,Description=\"All filters passed\"> ##contig=<ID=chr1,length=249250621> ##contig=<ID=chr2,length=243199373> ##contig=<ID=chr3,length=198022430> ##contig=<ID=chr4,length=191154276> ##contig=<ID=chr5,length=180915260> ##contig=<ID=chr6,length=171115067> ##contig=<ID=chr7,length=159138663> ##contig=<ID=chr8,length=146364022> ##contig=<ID=chr9,length=141213431> ##contig=<ID=chr10,length=135534747> ##contig=<ID=chr11,length=135006516> ##contig=<ID=chr12,length=133851895> ##contig=<ID=chr13,length=115169878> ##contig=<ID=chr14,length=107349540> ##contig=<ID=chr15,length=102531392> ##contig=<ID=chr16,length=90354753> ##contig=<ID=chr17,length=81195210> ##contig=<ID=chr18,length=78077248> ##contig=<ID=chr19,length=59128983> ##contig=<ID=chr20,length=63025520> ##contig=<ID=chr21,length=48129895> ##contig=<ID=chr22,length=51304566> ##contig=<ID=chrX,length=155270560> ##contig=<ID=chrY,length=59373566> ##contig=<ID=chrMT,length=16569> #CHROM POS ID REF ALT QUAL FILTER INFO chr22 41320486 4 G T . . KV:kipoi:DeepSEA/variantEffects:DIFF=-0.00285008|-0.000... chr22 31009031 9 T G . . KV:kipoi:DeepSEA/variantEffects:DIFF=-0.02733281|-0.008... chr22 43024150 15 C G . . KV:kipoi:DeepSEA/variantEffects:DIFF=0.01077350|0.0007... chr22 43027392 16 A G . . KV:kipoi:DeepSEA/variantEffects:DIFF=-0.12174654|-0.24... chr22 37469571 122 C T . . KV:kipoi:DeepSEA/variantEffects:DIFF=-0.00654625|0.00... chr22 37465112 123 C G . . KV:kipoi:DeepSEA/variantEffects:DIFF=0.00574893|0.003... chr22 37494466 124 G T . . KV:kipoi:DeepSEA/variantEffects:DIFF=0.01308702|0.001... chr22 18561373 177 G T . . KV:kipoi:DeepSEA/variantEffects:DIFF=-0.00669485|0.00... chr22 51065593 241 C T . . KV:kipoi:DeepSEA/variantEffects:DIFF=0.00409312|0.001... chr22 51064006 242 C T . . KV:kipoi:DeepSEA/variantEffects:DIFF=0.00095593|0.000... This shows that variants have been annotated with variant effect scores. For every different scoring method a different INFO tag was created and the score of every model output is concantenated with the | separator symbol. A legend is given in the header section of the VCF. The name tag indicates with model was used, wich version of it and it displays the scoring function label ( DIFF ) which is derived from the scoring function label defined in the evaluation_function_kwargs dictionary ( 'diff' ). The most comprehensive representation of effect preditions is in the annotated VCF. Kipoi offers a VCF parser class that enables simple parsing of annotated VCFs: from kipoi_veff.parsers import KipoiVCFParser vcf_reader = KipoiVCFParser(\"example_data/clinvar_donor_acceptor_chr22DeepSEA_variantEffects.vcf\") #We can have a look at the different labels which were created in the VCF print(list(vcf_reader.kipoi_parsed_colnames.values())) [('kipoi', 'DeepSEA/variantEffects', 'DIFF'), ('kipoi', 'DeepSEA/variantEffects', 'DEEPSEA_EFFECT'), ('kipoi', 'DeepSEA/variantEffects', 'rID')] We can see that two scores have been saved - 'DEEPSEA_EFFECT' and 'DIFF' . Additionally there is 'rID' which is the region ID - that is the ID given by the dataloader for a genomic region which was overlapped with the variant to get the prediction that is listed in the effect score columns mentioned before. Let's take a look at the VCF entries: import pandas as pd entries = [el for el in vcf_reader] print(pd.DataFrame(entries).head().iloc[:,:7]) variant_id variant_chr variant_pos variant_ref variant_alt \\ 0 4 chr22 41320486 G T 1 9 chr22 31009031 T G 2 15 chr22 43024150 C G 3 16 chr22 43027392 A G 4 122 chr22 37469571 C T KV_DeepSEA/variantEffects_DIFF_8988T_DNase_None_0 \\ 0 -0.002850 1 -0.027333 2 0.010774 3 -0.121747 4 -0.006546 KV_DeepSEA/variantEffects_DIFF_AoSMC_DNase_None_1 0 -0.000094 1 -0.008740 2 0.000702 3 -0.247321 4 0.000784 Another way to access effect predicitons programmatically is to keep all the results in memory and receive them as a dictionary of pandas dataframes: effects = sp.predict_snvs(model, Dataloader, vcf_path, batch_size = 32, dataloader_args=dataloader_arguments, vcf_to_region=vcf_to_region, evaluation_function_kwargs={'diff_types': {'diff': Diff(\"mean\"), 'deepsea_effect': DeepSEA_effect(\"mean\")}}, return_predictions=True) 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 14/14 [00:33<00:00, 2.41s/it] For every key in the evaluation_function_kwargs dictionary there is a key in effects and (the equivalent of an additional INFO tag in the VCF). Now let's take a look at the results: for k in effects: print(k) print(effects[k].head().iloc[:,:4]) print(\"-\"*80) diff 8988T_DNase_None AoSMC_DNase_None \\ chr22:41320486:G:['T'] -0.002850 -0.000094 chr22:31009031:T:['G'] -0.027333 -0.008740 chr22:43024150:C:['G'] 0.010773 0.000702 chr22:43027392:A:['G'] -0.121747 -0.247321 chr22:37469571:C:['T'] -0.006546 0.000784 Chorion_DNase_None CLL_DNase_None chr22:41320486:G:['T'] -0.001533 -0.000353 chr22:31009031:T:['G'] -0.003499 -0.008143 chr22:43024150:C:['G'] 0.004689 -0.000609 chr22:43027392:A:['G'] -0.167689 -0.010695 chr22:37469571:C:['T'] -0.000383 -0.000924 -------------------------------------------------------------------------------- deepsea_effect 8988T_DNase_None AoSMC_DNase_None \\ chr22:41320486:G:['T'] 0.000377 9.663903e-07 chr22:31009031:T:['G'] 0.004129 3.683221e-03 chr22:43024150:C:['G'] 0.001582 1.824510e-04 chr22:43027392:A:['G'] 0.068382 2.689577e-01 chr22:37469571:C:['T'] 0.001174 4.173280e-04 Chorion_DNase_None CLL_DNase_None chr22:41320486:G:['T'] 0.000162 0.000040 chr22:31009031:T:['G'] 0.000201 0.002139 chr22:43024150:C:['G'] 0.000322 0.000033 chr22:43027392:A:['G'] 0.133855 0.000773 chr22:37469571:C:['T'] 0.000008 0.000079 -------------------------------------------------------------------------------- We see that for diff and deepsea_effect there is a dataframe with variant identifiers as rows and model output labels as columns. The DeepSEA model predicts 919 tasks simultaneously hence there are 919 columns in the dataframe. Overlap based prediction Models that cannot predict on every region of the genome might not accept a .bed file as dataloader input. An example of such a model is a splicing model. Those models only work in certain regions of the genome. Here variant effect prediction can be executed based on overlaps between the regions generated by the dataloader and the variants defined in the VCF: The procedure is similar to the variant centered effect prediction explained above, but in this case no temporary bed file is generated and the effect prediction is based on all the regions generated by the dataloader which overlap any variant in the VCF. If a region is overlapped by two variants the effect of the two variants is predicted independently. Here the VCF has to be tabixed so that a regional lookup can be performed efficiently, this can be done by using the ensure_tabixed function, the rest remains the same as before: import kipoi from kipoi_veff import VcfWriter from kipoi_veff import ensure_tabixed_vcf # Use a splicing model model_name = \"HAL\" # get the model model = kipoi.get_model(model_name) # get the dataloader factory Dataloader = kipoi.get_dataloader_factory(model_name) # The input vcf path vcf_path = \"example_data/clinvar_donor_acceptor_chr22.vcf\" # Make sure that the vcf is bgzipped and tabixed, if not then generate the compressed vcf in the same place vcf_path_tbx = ensure_tabixed_vcf(vcf_path) # The output vcf path, based on the input file name out_vcf_fpath = vcf_path[:-4] + \"%s.vcf\"%model_name.replace(\"/\", \"_\") # The writer object that will output the annotated VCF writer = VcfWriter(model, vcf_path, out_vcf_fpath) This time we don't need an object that generates regions, hence we can directly define the dataloader arguments and run the prediction: from kipoi_veff import predict_snvs from kipoi_veff.scores import Diff dataloader_arguments = {\"gtf_file\":\"example_data/Homo_sapiens.GRCh37.75.filtered_chr22.gtf\", \"fasta_file\": \"example_data/hg19_chr22.fa\"} effects = predict_snvs(model, Dataloader, vcf_path_tbx, batch_size = 32, dataloader_args=dataloader_arguments, evaluation_function_kwargs={'diff_types': {'diff': Diff(\"mean\")}}, sync_pred_writer=writer, return_predictions=True) 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 709/709 [00:04<00:00, 150.84it/s] Let's have a look at the VCF: # A slightly convoluted way of printing out the first 40 lines and up to 80 characters per line maximum with open(\"example_data/clinvar_donor_acceptor_chr22HAL.vcf\") as ifh: for i,l in enumerate(ifh): long_line = \"\" if len(l)>80: long_line = \"...\" print(l[:80].rstrip() +long_line) if i >=40: break ##fileformat=VCFv4.0 ##INFO=<ID=KV:kipoi:HAL:DIFF,Number=.,Type=String,Description=\"DIFF SNV effect p... ##INFO=<ID=KV:kipoi:HAL:rID,Number=.,Type=String,Description=\"Range or region id... ##FILTER=<ID=PASS,Description=\"All filters passed\"> ##contig=<ID=chr1,length=249250621> ##contig=<ID=chr2,length=243199373> ##contig=<ID=chr3,length=198022430> ##contig=<ID=chr4,length=191154276> ##contig=<ID=chr5,length=180915260> ##contig=<ID=chr6,length=171115067> ##contig=<ID=chr7,length=159138663> ##contig=<ID=chr8,length=146364022> ##contig=<ID=chr9,length=141213431> ##contig=<ID=chr10,length=135534747> ##contig=<ID=chr11,length=135006516> ##contig=<ID=chr12,length=133851895> ##contig=<ID=chr13,length=115169878> ##contig=<ID=chr14,length=107349540> ##contig=<ID=chr15,length=102531392> ##contig=<ID=chr16,length=90354753> ##contig=<ID=chr17,length=81195210> ##contig=<ID=chr18,length=78077248> ##contig=<ID=chr19,length=59128983> ##contig=<ID=chr20,length=63025520> ##contig=<ID=chr21,length=48129895> ##contig=<ID=chr22,length=51304566> ##contig=<ID=chrX,length=155270560> ##contig=<ID=chrY,length=59373566> ##contig=<ID=chrMT,length=16569> #CHROM POS ID REF ALT QUAL FILTER INFO chr22 17684454 4461 G A . . KV:kipoi:HAL:DIFF=0.10586491;KV:kipoi:HAL:rID=290 chr22 17669232 7178 T C . . KV:kipoi:HAL:DIFF=0.00000000;KV:kipoi:HAL:rID=293 chr22 17669232 7178 T C . . KV:kipoi:HAL:DIFF=0.00000000;KV:kipoi:HAL:rID=299 chr22 17684454 4461 G A . . KV:kipoi:HAL:DIFF=0.10586491;KV:kipoi:HAL:rID=304 chr22 17669232 7178 T C . . KV:kipoi:HAL:DIFF=0.00000000;KV:kipoi:HAL:rID=307 chr22 17684454 4461 G A . . KV:kipoi:HAL:DIFF=0.10586491;KV:kipoi:HAL:rID=313 chr22 17669232 7178 T C . . KV:kipoi:HAL:DIFF=0.00000000;KV:kipoi:HAL:rID=316 chr22 17684454 4461 G A . . KV:kipoi:HAL:DIFF=0.10586491;KV:kipoi:HAL:rID=322 chr22 17669232 7178 T C . . KV:kipoi:HAL:DIFF=0.00000000;KV:kipoi:HAL:rID=325 chr22 17669232 7178 T C . . KV:kipoi:HAL:DIFF=0.00000000;KV:kipoi:HAL:rID=328 chr22 18561370 7302 C T . . KV:kipoi:HAL:DIFF=-1.33794269;KV:kipoi:HAL:rID=824 And the prediction output this time is less helpful because it's the ids that the dataloader created which are displayed as index. In general it is advisable to use the output VCF for more detailed information on which variant was overlapped with which region fo produce a prediction. for k in effects: print(k) print(effects[k].head()) print(\"-\"*80) diff 0 290 0.105865 293 0.000000 299 0.000000 304 0.105865 307 0.000000 -------------------------------------------------------------------------------- Command-line based effect prediction The above command can also conveniently be executed using the command line: import json import os model_name = \"DeepSEA/variantEffects\" dl_args = json.dumps({\"fasta_file\": \"example_data/hg19_chr22.fa\"}) out_vcf_fpath = vcf_path[:-4] + \"%s.vcf\"%model_name.replace(\"/\", \"_\") scorings = \"diff deepsea_effect\" command = (\"kipoi veff score_variants {model} \" \"--dataloader_args='{dl_args}' \" \"-i {input_vcf} \" \"-o {output_vcf} \" \"-s {scorings}\").format(model=model_name, dl_args=dl_args, input_vcf=vcf_path, output_vcf=out_vcf_fpath, scorings=scorings) # Print out the command: print(command) kipoi veff score_variants DeepSEA/variantEffects --dataloader_args='{\"fasta_file\": \"example_data/hg19_chr22.fa\"}' -i example_data/clinvar_donor_acceptor_chr22.vcf -o example_data/clinvar_donor_acceptor_chr22DeepSEA_variantEffects.vcf -s diff deepsea_effect ! $command \u001b[32mINFO\u001b[0m \u001b[44m[kipoi.sources]\u001b[0m Update /nfs/research1/stegle/users/rkreuzhu/.kipoi/models/\u001b[0m Already up-to-date. \u001b[32mINFO\u001b[0m \u001b[44m[kipoi.sources]\u001b[0m git-lfs pull -I DeepSEA/variantEffects/**\u001b[0m \u001b[32mINFO\u001b[0m \u001b[44m[kipoi.sources]\u001b[0m git-lfs pull -I DeepSEA/template/**\u001b[0m \u001b[32mINFO\u001b[0m \u001b[44m[kipoi.sources]\u001b[0m git-lfs pull -I DeepSEA/template/model_files/**\u001b[0m \u001b[32mINFO\u001b[0m \u001b[44m[kipoi.sources]\u001b[0m git-lfs pull -I DeepSEA/template/example_files/**\u001b[0m \u001b[32mINFO\u001b[0m \u001b[44m[kipoi.sources]\u001b[0m model DeepSEA/variantEffects loaded\u001b[0m \u001b[32mINFO\u001b[0m \u001b[44m[kipoi.sources]\u001b[0m git-lfs pull -I DeepSEA/variantEffects/./**\u001b[0m \u001b[32mINFO\u001b[0m \u001b[44m[kipoi.sources]\u001b[0m git-lfs pull -I DeepSEA/template/**\u001b[0m \u001b[32mINFO\u001b[0m \u001b[44m[kipoi.sources]\u001b[0m git-lfs pull -I DeepSEA/template/model_files/**\u001b[0m \u001b[32mINFO\u001b[0m \u001b[44m[kipoi.sources]\u001b[0m git-lfs pull -I DeepSEA/template/example_files/**\u001b[0m \u001b[32mINFO\u001b[0m \u001b[44m[kipoi.sources]\u001b[0m dataloader DeepSEA/variantEffects/. loaded\u001b[0m \u001b[32mINFO\u001b[0m \u001b[44m[kipoi.data]\u001b[0m successfully loaded the dataloader from /nfs/research1/stegle/users/rkreuzhu/.kipoi/models/DeepSEA/variantEffects/dataloader.py::SeqDataset\u001b[0m \u001b[32mINFO\u001b[0m \u001b[44m[kipoi.pipeline]\u001b[0m dataloader.output_schema is compatible with model.schema\u001b[0m 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 14/14 [00:35<00:00, 2.53s/it] Batch prediction Since the syntax basically doesn't change for different kinds of models a simple for-loop can be written to do what we just did on many models: import kipoi # Run effect predicton models_df = kipoi.list_models() models_substr = [\"HAL\", \"MaxEntScan\", \"labranchor\", \"rbp\"] models_df_subsets = {ms: models_df.loc[models_df[\"model\"].str.contains(ms)] for ms in models_substr} /nfs/research1/stegle/users/rkreuzhu/opt/model-zoo/kipoi/config.py:110: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version of pandas will change to not sort by default. To accept the future behavior, pass 'sort=False'. To retain the current behavior and silence the warning, pass 'sort=True'. return pd.concat(pd_list)[pd_list[0].columns] # Run variant effect prediction using a basic Diff import kipoi from kipoi_veff import ensure_tabixed_vcf import kipoi_veff.snv_predict as sp from kipoi_veff import VcfWriter from kipoi_veff.scores import Diff splicing_dl_args = {\"gtf_file\":\"example_data/Homo_sapiens.GRCh37.75.filtered_chr22.gtf\", \"fasta_file\": \"example_data/hg19_chr22.fa\"} dataloader_args_dict = {\"HAL\": splicing_dl_args, \"labranchor\": splicing_dl_args, \"MaxEntScan\":splicing_dl_args, \"rbp\": {\"fasta_file\": \"example_data/hg19_chr22.fa\", \"gtf_file\":\"example_data/Homo_sapiens.GRCh37.75_chr22.gtf\"} } for ms in models_substr: model_name = models_df_subsets[ms][\"model\"].iloc[0] #kipoi.pipeline.install_model_requirements(model_name) model = kipoi.get_model(model_name) vcf_path = \"example_data/clinvar_donor_acceptor_chr22.vcf\" vcf_path_tbx = ensure_tabixed_vcf(vcf_path) out_vcf_fpath = vcf_path[:-4] + \"%s.vcf\"%model_name.replace(\"/\", \"_\") writer = VcfWriter(model, vcf_path, out_vcf_fpath) print(model_name) Dataloader = kipoi.get_dataloader_factory(model_name) dataloader_arguments = dataloader_args_dict[ms] model_info = kipoi_veff.ModelInfoExtractor(model, Dataloader) vcf_to_region = None if ms == \"rbp\": vcf_to_region = kipoi_veff.SnvCenteredRg(model_info) sp.predict_snvs(model, Dataloader, vcf_path_tbx, batch_size = 32, dataloader_args=dataloader_arguments, vcf_to_region=vcf_to_region, evaluation_function_kwargs={'diff_types': {'diff': Diff(\"mean\")}}, sync_pred_writer=writer) writer.close() HAL 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 709/709 [00:04<00:00, 167.58it/s] MaxEntScan/3prime 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 709/709 [00:02<00:00, 329.18it/s] Using TensorFlow backend. WARNING:tensorflow:From /nfs/research1/stegle/users/rkreuzhu/conda-envs/kipoi_interpret/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1238: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version. Instructions for updating: keep_dims is deprecated, use keepdims instead WARNING:tensorflow:From /nfs/research1/stegle/users/rkreuzhu/conda-envs/kipoi_interpret/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1340: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version. Instructions for updating: keep_dims is deprecated, use keepdims instead /nfs/research1/stegle/users/rkreuzhu/conda-envs/kipoi_interpret/lib/python3.6/site-packages/keras/models.py:287: UserWarning: Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer. warnings.warn('Error in loading the saved optimizer ' labranchor 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 709/709 [00:05<00:00, 122.95it/s] 2018-07-25 11:37:28,705 [INFO] successfully loaded the dataloader from /nfs/research1/stegle/users/rkreuzhu/.kipoi/models/rbp_eclip/AARS/dataloader.py::SeqDistDataset WARNING:tensorflow:From /nfs/research1/stegle/users/rkreuzhu/conda-envs/kipoi_interpret/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1255: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version. Instructions for updating: keep_dims is deprecated, use keepdims instead 2018-07-25 11:37:28,851 [WARNING] From /nfs/research1/stegle/users/rkreuzhu/conda-envs/kipoi_interpret/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1255: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version. Instructions for updating: keep_dims is deprecated, use keepdims instead /nfs/research1/stegle/users/rkreuzhu/conda-envs/kipoi_interpret/lib/python3.6/site-packages/keras/models.py:287: UserWarning: Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer. warnings.warn('Error in loading the saved optimizer ' 2018-07-25 11:37:30,996 [INFO] successfully loaded the model from model_files/model.h5 2018-07-25 11:37:30,999 [INFO] dataloader.output_schema is compatible with model.schema 2018-07-25 11:37:31,157 [INFO] git-lfs pull -I rbp_eclip/AARS/** rbp_eclip/AARS 2018-07-25 11:37:32,071 [INFO] git-lfs pull -I rbp_eclip/template/** 2018-07-25 11:37:33,219 [INFO] dataloader rbp_eclip/AARS loaded 2018-07-25 11:37:33,252 [INFO] successfully loaded the dataloader from /nfs/research1/stegle/users/rkreuzhu/.kipoi/models/rbp_eclip/AARS/dataloader.py::SeqDistDataset 2018-07-25 11:37:34,411 [INFO] Extracted GTF attributes: ['gene_id', 'gene_name', 'gene_source', 'gene_biotype', 'transcript_id', 'transcript_name', 'transcript_source', 'exon_number', 'exon_id', 'tag', 'protein_id', 'ccds_id'] /nfs/research1/stegle/users/rkreuzhu/conda-envs/kipoi_interpret/lib/python3.6/site-packages/sklearn/base.py:311: UserWarning: Trying to unpickle estimator MinMaxScaler from version 0.18.1 when using version 0.19.1. This might lead to breaking code or invalid results. Use at your own risk. UserWarning) /nfs/research1/stegle/users/rkreuzhu/conda-envs/kipoi_interpret/lib/python3.6/site-packages/sklearn/base.py:311: UserWarning: Trying to unpickle estimator Imputer from version 0.18.1 when using version 0.19.1. This might lead to breaking code or invalid results. Use at your own risk. UserWarning) 0%| | 0/14 [00:00<?, ?it/s]INFO:2018-07-25 11:37:34,812:genomelake] Running landmark extractors.. 2018-07-25 11:37:34,812 [INFO] Running landmark extractors.. /nfs/research1/stegle/users/rkreuzhu/conda-envs/kipoi_interpret/lib/python3.6/site-packages/concise/utils/position.py:55: FutureWarning: from_items is deprecated. Please use DataFrame.from_dict(dict(items), ...) instead. DataFrame.from_dict(OrderedDict(items)) may be used to preserve the key order. (\"strand\", gtf.strand)]) /nfs/research1/stegle/users/rkreuzhu/conda-envs/kipoi_interpret/lib/python3.6/site-packages/concise/utils/position.py:62: FutureWarning: from_items is deprecated. Please use DataFrame.from_dict(dict(items), ...) instead. DataFrame.from_dict(OrderedDict(items)) may be used to preserve the key order. (\"strand\", gtf.strand)]) INFO:2018-07-25 11:37:34,975:genomelake] Done! 2018-07-25 11:37:34,975 [INFO] Done! 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 14/14 [00:03<00:00, 4.05it/s] let's validate that things have worked: ! wc -l example_data/clinvar_donor_acceptor_chr22*.vcf 450 example_data/clinvar_donor_acceptor_chr22DeepSEA_variantEffects.vcf 2035 example_data/clinvar_donor_acceptor_chr22HAL.vcf 794 example_data/clinvar_donor_acceptor_chr22labranchor.vcf 1176 example_data/clinvar_donor_acceptor_chr22MaxEntScan_3prime.vcf 449 example_data/clinvar_donor_acceptor_chr22rbp_eclip_AARS.vcf 447 example_data/clinvar_donor_acceptor_chr22.vcf 5351 total","title":"Advanced"},{"location":"tutorials/variant_effect_prediction/#variant-effect-prediction","text":"Variant effect prediction offers a simple way to predict effects of SNVs using any model that uses DNA sequence as an input. Many different scoring methods can be chosen, but the principle relies on in-silico mutagenesis. The default input is a VCF and the default output again is a VCF annotated with predictions of variant effects. For details please take a look at the documentation in Postprocessing/Variant effect prediction. This iPython notebook goes through the basic programmatic steps that are needed to preform variant effect prediction. First a variant-centered approach will be taken and secondly overlap-based variant effect prediction will be presented. For details in how this is done programmatically, please refer to the documentation.","title":"Variant effect prediction"},{"location":"tutorials/variant_effect_prediction/#variant-centered-effect-prediction","text":"Models that accept input .bed files can make use of variant-centered effect prediction. This procedure starts out from the query VCF and generates genomic regions of the length of the model input, centered on the individual variant in the VCF.The model dataloader is then used to produce the model input samples for those regions, which are then mutated according to the alleles in the VCF: First an instance of SnvCenteredRg generates a temporary bed file with regions matching the input sequence length defined in the model.yaml input schema. Then the model dataloader is used to preduce the model input in batches. These chunks of data are then modified by the effect prediction algorithm, the model batch prediction function is triggered for all mutated sequence sets and finally the scoring method is applied. The selected scoring methods compare model predicitons for sequences carrying the reference or alternative allele. Those scoring methods can be Diff for simple subtraction of prediction, Logit for substraction of logit-transformed model predictions, or DeepSEA_effect which is a combination of Diff and Logit , which was published in the Troyanskaya et al. (2015) publication. This ipython notebook assumes that it is executed in an environment in which all dependencies for the following models are installed: DeepSEA/vaariantEffects , HAL , labranchor , MaxEntScan , and rbp are installed, as well as the --vep flag has to be used during installing the dependencies. Now let's start out by loading the DeepSEA model and dataloader factory: import kipoi model_name = \"DeepSEA/variantEffects\" # get the model model = kipoi.get_model(model_name) # get the dataloader factory Dataloader = kipoi.get_dataloader_factory(model_name) Next we will have to define the variants we want to look at, let's look at a sample VCF in chromosome 22: !head -n 40 example_data/clinvar_donor_acceptor_chr22.vcf ##fileformat=VCFv4.0 ##FILTER=<ID=PASS,Description=\"All filters passed\"> ##contig=<ID=chr1,length=249250621> ##contig=<ID=chr2,length=243199373> ##contig=<ID=chr3,length=198022430> ##contig=<ID=chr4,length=191154276> ##contig=<ID=chr5,length=180915260> ##contig=<ID=chr6,length=171115067> ##contig=<ID=chr7,length=159138663> ##contig=<ID=chr8,length=146364022> ##contig=<ID=chr9,length=141213431> ##contig=<ID=chr10,length=135534747> ##contig=<ID=chr11,length=135006516> ##contig=<ID=chr12,length=133851895> ##contig=<ID=chr13,length=115169878> ##contig=<ID=chr14,length=107349540> ##contig=<ID=chr15,length=102531392> ##contig=<ID=chr16,length=90354753> ##contig=<ID=chr17,length=81195210> ##contig=<ID=chr18,length=78077248> ##contig=<ID=chr19,length=59128983> ##contig=<ID=chr20,length=63025520> ##contig=<ID=chr21,length=48129895> ##contig=<ID=chr22,length=51304566> ##contig=<ID=chrX,length=155270560> ##contig=<ID=chrY,length=59373566> ##contig=<ID=chrMT,length=16569> #CHROM POS ID REF ALT QUAL FILTER INFO chr22 41320486 4 G T . . . chr22 31009031 9 T G . . . chr22 43024150 15 C G . . . chr22 43027392 16 A G . . . chr22 37469571 122 C T . . . chr22 37465112 123 C G . . . chr22 37494466 124 G T . . . chr22 18561373 177 G T . . . chr22 51065593 241 C T . . . chr22 51064006 242 C T . . . chr22 51065269 243 G A . . . chr22 30032866 260 G T . . . Now we will define path variable for vcf input and output paths and instantiate a VcfWriter, which will write out the annotated VCF: import kipoi_veff from kipoi_veff import VcfWriter # The input vcf path vcf_path = \"example_data/clinvar_donor_acceptor_chr22.vcf\" # The output vcf path, based on the input file name out_vcf_fpath = vcf_path[:-4] + \"%s.vcf\"%model_name.replace(\"/\", \"_\") # The writer object that will output the annotated VCF writer = VcfWriter(model, vcf_path, out_vcf_fpath) Then we need to instantiate an object that can generate variant-centered regions ( SnvCenteredRg objects). This class needs information on the model input sequence length which is extracted automatically within ModelInfoExtractor objects: # Information extraction from dataloader and model model_info = kipoi_veff.ModelInfoExtractor(model, Dataloader) # vcf_to_region will generate a variant-centered regions when presented a VCF record. vcf_to_region = kipoi_veff.SnvCenteredRg(model_info) Now we can define the required dataloader arguments, omitting the intervals_file as this will be replaced by the automatically generated bed file: dataloader_arguments = {\"fasta_file\": \"example_data/hg19_chr22.fa\"} This is the moment to run the variant effect prediction: import kipoi_veff.snv_predict as sp from kipoi_veff.scores import Diff, DeepSEA_effect sp.predict_snvs(model, Dataloader, vcf_path, batch_size = 32, dataloader_args=dataloader_arguments, vcf_to_region=vcf_to_region, evaluation_function_kwargs={'diff_types': {'diff': Diff(\"mean\"), 'deepsea_effect': DeepSEA_effect(\"mean\")}}, sync_pred_writer=writer) 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 14/14 [00:34<00:00, 2.46s/it] In the example above we have used the variant scoring method Diff and DeepSEA_effect from kipoi_veff plug-in. As mentioned above variant scoring methods calculate the difference between predictions for reference and alternative, but there is another dimension to this: Models that have the use_rc: true flag set in their model.yaml file (DeepSEA/variantEffects does) will not only be queried with the reference and alternative carrying input sequences, but also with the reverse complement of the the sequences. In order to know of to combine predictions for forward and reverse sequences there is a initialisation flag (here set to: \"mean\" ) for the variant scoring methods. \"mean\" in this case means that after calculating the effect (e.g.: Difference) the average over the difference between the prediction for the forward and for the reverse sequence should be returned. Setting \"mean\" complies with what was used in the Troyanskaya et al. publication. Now let's look at the output: # Let's print out the first 40 lines of the annotated VCF (up to 80 characters per line maximum) with open(\"example_data/clinvar_donor_acceptor_chr22DeepSEA_variantEffects.vcf\") as ifh: for i,l in enumerate(ifh): long_line = \"\" if len(l)>80: long_line = \"...\" print(l[:80].rstrip() +long_line) if i >=40: break ##fileformat=VCFv4.0 ##INFO=<ID=KV:kipoi:DeepSEA/variantEffects:DIFF,Number=.,Type=String,Description... ##INFO=<ID=KV:kipoi:DeepSEA/variantEffects:DEEPSEA_EFFECT,Number=.,Type=String,D... ##INFO=<ID=KV:kipoi:DeepSEA/variantEffects:rID,Number=.,Type=String,Description=... ##FILTER=<ID=PASS,Description=\"All filters passed\"> ##contig=<ID=chr1,length=249250621> ##contig=<ID=chr2,length=243199373> ##contig=<ID=chr3,length=198022430> ##contig=<ID=chr4,length=191154276> ##contig=<ID=chr5,length=180915260> ##contig=<ID=chr6,length=171115067> ##contig=<ID=chr7,length=159138663> ##contig=<ID=chr8,length=146364022> ##contig=<ID=chr9,length=141213431> ##contig=<ID=chr10,length=135534747> ##contig=<ID=chr11,length=135006516> ##contig=<ID=chr12,length=133851895> ##contig=<ID=chr13,length=115169878> ##contig=<ID=chr14,length=107349540> ##contig=<ID=chr15,length=102531392> ##contig=<ID=chr16,length=90354753> ##contig=<ID=chr17,length=81195210> ##contig=<ID=chr18,length=78077248> ##contig=<ID=chr19,length=59128983> ##contig=<ID=chr20,length=63025520> ##contig=<ID=chr21,length=48129895> ##contig=<ID=chr22,length=51304566> ##contig=<ID=chrX,length=155270560> ##contig=<ID=chrY,length=59373566> ##contig=<ID=chrMT,length=16569> #CHROM POS ID REF ALT QUAL FILTER INFO chr22 41320486 4 G T . . KV:kipoi:DeepSEA/variantEffects:DIFF=-0.00285008|-0.000... chr22 31009031 9 T G . . KV:kipoi:DeepSEA/variantEffects:DIFF=-0.02733281|-0.008... chr22 43024150 15 C G . . KV:kipoi:DeepSEA/variantEffects:DIFF=0.01077350|0.0007... chr22 43027392 16 A G . . KV:kipoi:DeepSEA/variantEffects:DIFF=-0.12174654|-0.24... chr22 37469571 122 C T . . KV:kipoi:DeepSEA/variantEffects:DIFF=-0.00654625|0.00... chr22 37465112 123 C G . . KV:kipoi:DeepSEA/variantEffects:DIFF=0.00574893|0.003... chr22 37494466 124 G T . . KV:kipoi:DeepSEA/variantEffects:DIFF=0.01308702|0.001... chr22 18561373 177 G T . . KV:kipoi:DeepSEA/variantEffects:DIFF=-0.00669485|0.00... chr22 51065593 241 C T . . KV:kipoi:DeepSEA/variantEffects:DIFF=0.00409312|0.001... chr22 51064006 242 C T . . KV:kipoi:DeepSEA/variantEffects:DIFF=0.00095593|0.000... This shows that variants have been annotated with variant effect scores. For every different scoring method a different INFO tag was created and the score of every model output is concantenated with the | separator symbol. A legend is given in the header section of the VCF. The name tag indicates with model was used, wich version of it and it displays the scoring function label ( DIFF ) which is derived from the scoring function label defined in the evaluation_function_kwargs dictionary ( 'diff' ). The most comprehensive representation of effect preditions is in the annotated VCF. Kipoi offers a VCF parser class that enables simple parsing of annotated VCFs: from kipoi_veff.parsers import KipoiVCFParser vcf_reader = KipoiVCFParser(\"example_data/clinvar_donor_acceptor_chr22DeepSEA_variantEffects.vcf\") #We can have a look at the different labels which were created in the VCF print(list(vcf_reader.kipoi_parsed_colnames.values())) [('kipoi', 'DeepSEA/variantEffects', 'DIFF'), ('kipoi', 'DeepSEA/variantEffects', 'DEEPSEA_EFFECT'), ('kipoi', 'DeepSEA/variantEffects', 'rID')] We can see that two scores have been saved - 'DEEPSEA_EFFECT' and 'DIFF' . Additionally there is 'rID' which is the region ID - that is the ID given by the dataloader for a genomic region which was overlapped with the variant to get the prediction that is listed in the effect score columns mentioned before. Let's take a look at the VCF entries: import pandas as pd entries = [el for el in vcf_reader] print(pd.DataFrame(entries).head().iloc[:,:7]) variant_id variant_chr variant_pos variant_ref variant_alt \\ 0 4 chr22 41320486 G T 1 9 chr22 31009031 T G 2 15 chr22 43024150 C G 3 16 chr22 43027392 A G 4 122 chr22 37469571 C T KV_DeepSEA/variantEffects_DIFF_8988T_DNase_None_0 \\ 0 -0.002850 1 -0.027333 2 0.010774 3 -0.121747 4 -0.006546 KV_DeepSEA/variantEffects_DIFF_AoSMC_DNase_None_1 0 -0.000094 1 -0.008740 2 0.000702 3 -0.247321 4 0.000784 Another way to access effect predicitons programmatically is to keep all the results in memory and receive them as a dictionary of pandas dataframes: effects = sp.predict_snvs(model, Dataloader, vcf_path, batch_size = 32, dataloader_args=dataloader_arguments, vcf_to_region=vcf_to_region, evaluation_function_kwargs={'diff_types': {'diff': Diff(\"mean\"), 'deepsea_effect': DeepSEA_effect(\"mean\")}}, return_predictions=True) 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 14/14 [00:33<00:00, 2.41s/it] For every key in the evaluation_function_kwargs dictionary there is a key in effects and (the equivalent of an additional INFO tag in the VCF). Now let's take a look at the results: for k in effects: print(k) print(effects[k].head().iloc[:,:4]) print(\"-\"*80) diff 8988T_DNase_None AoSMC_DNase_None \\ chr22:41320486:G:['T'] -0.002850 -0.000094 chr22:31009031:T:['G'] -0.027333 -0.008740 chr22:43024150:C:['G'] 0.010773 0.000702 chr22:43027392:A:['G'] -0.121747 -0.247321 chr22:37469571:C:['T'] -0.006546 0.000784 Chorion_DNase_None CLL_DNase_None chr22:41320486:G:['T'] -0.001533 -0.000353 chr22:31009031:T:['G'] -0.003499 -0.008143 chr22:43024150:C:['G'] 0.004689 -0.000609 chr22:43027392:A:['G'] -0.167689 -0.010695 chr22:37469571:C:['T'] -0.000383 -0.000924 -------------------------------------------------------------------------------- deepsea_effect 8988T_DNase_None AoSMC_DNase_None \\ chr22:41320486:G:['T'] 0.000377 9.663903e-07 chr22:31009031:T:['G'] 0.004129 3.683221e-03 chr22:43024150:C:['G'] 0.001582 1.824510e-04 chr22:43027392:A:['G'] 0.068382 2.689577e-01 chr22:37469571:C:['T'] 0.001174 4.173280e-04 Chorion_DNase_None CLL_DNase_None chr22:41320486:G:['T'] 0.000162 0.000040 chr22:31009031:T:['G'] 0.000201 0.002139 chr22:43024150:C:['G'] 0.000322 0.000033 chr22:43027392:A:['G'] 0.133855 0.000773 chr22:37469571:C:['T'] 0.000008 0.000079 -------------------------------------------------------------------------------- We see that for diff and deepsea_effect there is a dataframe with variant identifiers as rows and model output labels as columns. The DeepSEA model predicts 919 tasks simultaneously hence there are 919 columns in the dataframe.","title":"Variant centered effect prediction"},{"location":"tutorials/variant_effect_prediction/#overlap-based-prediction","text":"Models that cannot predict on every region of the genome might not accept a .bed file as dataloader input. An example of such a model is a splicing model. Those models only work in certain regions of the genome. Here variant effect prediction can be executed based on overlaps between the regions generated by the dataloader and the variants defined in the VCF: The procedure is similar to the variant centered effect prediction explained above, but in this case no temporary bed file is generated and the effect prediction is based on all the regions generated by the dataloader which overlap any variant in the VCF. If a region is overlapped by two variants the effect of the two variants is predicted independently. Here the VCF has to be tabixed so that a regional lookup can be performed efficiently, this can be done by using the ensure_tabixed function, the rest remains the same as before: import kipoi from kipoi_veff import VcfWriter from kipoi_veff import ensure_tabixed_vcf # Use a splicing model model_name = \"HAL\" # get the model model = kipoi.get_model(model_name) # get the dataloader factory Dataloader = kipoi.get_dataloader_factory(model_name) # The input vcf path vcf_path = \"example_data/clinvar_donor_acceptor_chr22.vcf\" # Make sure that the vcf is bgzipped and tabixed, if not then generate the compressed vcf in the same place vcf_path_tbx = ensure_tabixed_vcf(vcf_path) # The output vcf path, based on the input file name out_vcf_fpath = vcf_path[:-4] + \"%s.vcf\"%model_name.replace(\"/\", \"_\") # The writer object that will output the annotated VCF writer = VcfWriter(model, vcf_path, out_vcf_fpath) This time we don't need an object that generates regions, hence we can directly define the dataloader arguments and run the prediction: from kipoi_veff import predict_snvs from kipoi_veff.scores import Diff dataloader_arguments = {\"gtf_file\":\"example_data/Homo_sapiens.GRCh37.75.filtered_chr22.gtf\", \"fasta_file\": \"example_data/hg19_chr22.fa\"} effects = predict_snvs(model, Dataloader, vcf_path_tbx, batch_size = 32, dataloader_args=dataloader_arguments, evaluation_function_kwargs={'diff_types': {'diff': Diff(\"mean\")}}, sync_pred_writer=writer, return_predictions=True) 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 709/709 [00:04<00:00, 150.84it/s] Let's have a look at the VCF: # A slightly convoluted way of printing out the first 40 lines and up to 80 characters per line maximum with open(\"example_data/clinvar_donor_acceptor_chr22HAL.vcf\") as ifh: for i,l in enumerate(ifh): long_line = \"\" if len(l)>80: long_line = \"...\" print(l[:80].rstrip() +long_line) if i >=40: break ##fileformat=VCFv4.0 ##INFO=<ID=KV:kipoi:HAL:DIFF,Number=.,Type=String,Description=\"DIFF SNV effect p... ##INFO=<ID=KV:kipoi:HAL:rID,Number=.,Type=String,Description=\"Range or region id... ##FILTER=<ID=PASS,Description=\"All filters passed\"> ##contig=<ID=chr1,length=249250621> ##contig=<ID=chr2,length=243199373> ##contig=<ID=chr3,length=198022430> ##contig=<ID=chr4,length=191154276> ##contig=<ID=chr5,length=180915260> ##contig=<ID=chr6,length=171115067> ##contig=<ID=chr7,length=159138663> ##contig=<ID=chr8,length=146364022> ##contig=<ID=chr9,length=141213431> ##contig=<ID=chr10,length=135534747> ##contig=<ID=chr11,length=135006516> ##contig=<ID=chr12,length=133851895> ##contig=<ID=chr13,length=115169878> ##contig=<ID=chr14,length=107349540> ##contig=<ID=chr15,length=102531392> ##contig=<ID=chr16,length=90354753> ##contig=<ID=chr17,length=81195210> ##contig=<ID=chr18,length=78077248> ##contig=<ID=chr19,length=59128983> ##contig=<ID=chr20,length=63025520> ##contig=<ID=chr21,length=48129895> ##contig=<ID=chr22,length=51304566> ##contig=<ID=chrX,length=155270560> ##contig=<ID=chrY,length=59373566> ##contig=<ID=chrMT,length=16569> #CHROM POS ID REF ALT QUAL FILTER INFO chr22 17684454 4461 G A . . KV:kipoi:HAL:DIFF=0.10586491;KV:kipoi:HAL:rID=290 chr22 17669232 7178 T C . . KV:kipoi:HAL:DIFF=0.00000000;KV:kipoi:HAL:rID=293 chr22 17669232 7178 T C . . KV:kipoi:HAL:DIFF=0.00000000;KV:kipoi:HAL:rID=299 chr22 17684454 4461 G A . . KV:kipoi:HAL:DIFF=0.10586491;KV:kipoi:HAL:rID=304 chr22 17669232 7178 T C . . KV:kipoi:HAL:DIFF=0.00000000;KV:kipoi:HAL:rID=307 chr22 17684454 4461 G A . . KV:kipoi:HAL:DIFF=0.10586491;KV:kipoi:HAL:rID=313 chr22 17669232 7178 T C . . KV:kipoi:HAL:DIFF=0.00000000;KV:kipoi:HAL:rID=316 chr22 17684454 4461 G A . . KV:kipoi:HAL:DIFF=0.10586491;KV:kipoi:HAL:rID=322 chr22 17669232 7178 T C . . KV:kipoi:HAL:DIFF=0.00000000;KV:kipoi:HAL:rID=325 chr22 17669232 7178 T C . . KV:kipoi:HAL:DIFF=0.00000000;KV:kipoi:HAL:rID=328 chr22 18561370 7302 C T . . KV:kipoi:HAL:DIFF=-1.33794269;KV:kipoi:HAL:rID=824 And the prediction output this time is less helpful because it's the ids that the dataloader created which are displayed as index. In general it is advisable to use the output VCF for more detailed information on which variant was overlapped with which region fo produce a prediction. for k in effects: print(k) print(effects[k].head()) print(\"-\"*80) diff 0 290 0.105865 293 0.000000 299 0.000000 304 0.105865 307 0.000000 --------------------------------------------------------------------------------","title":"Overlap based prediction"},{"location":"tutorials/variant_effect_prediction/#command-line-based-effect-prediction","text":"The above command can also conveniently be executed using the command line: import json import os model_name = \"DeepSEA/variantEffects\" dl_args = json.dumps({\"fasta_file\": \"example_data/hg19_chr22.fa\"}) out_vcf_fpath = vcf_path[:-4] + \"%s.vcf\"%model_name.replace(\"/\", \"_\") scorings = \"diff deepsea_effect\" command = (\"kipoi veff score_variants {model} \" \"--dataloader_args='{dl_args}' \" \"-i {input_vcf} \" \"-o {output_vcf} \" \"-s {scorings}\").format(model=model_name, dl_args=dl_args, input_vcf=vcf_path, output_vcf=out_vcf_fpath, scorings=scorings) # Print out the command: print(command) kipoi veff score_variants DeepSEA/variantEffects --dataloader_args='{\"fasta_file\": \"example_data/hg19_chr22.fa\"}' -i example_data/clinvar_donor_acceptor_chr22.vcf -o example_data/clinvar_donor_acceptor_chr22DeepSEA_variantEffects.vcf -s diff deepsea_effect ! $command \u001b[32mINFO\u001b[0m \u001b[44m[kipoi.sources]\u001b[0m Update /nfs/research1/stegle/users/rkreuzhu/.kipoi/models/\u001b[0m Already up-to-date. \u001b[32mINFO\u001b[0m \u001b[44m[kipoi.sources]\u001b[0m git-lfs pull -I DeepSEA/variantEffects/**\u001b[0m \u001b[32mINFO\u001b[0m \u001b[44m[kipoi.sources]\u001b[0m git-lfs pull -I DeepSEA/template/**\u001b[0m \u001b[32mINFO\u001b[0m \u001b[44m[kipoi.sources]\u001b[0m git-lfs pull -I DeepSEA/template/model_files/**\u001b[0m \u001b[32mINFO\u001b[0m \u001b[44m[kipoi.sources]\u001b[0m git-lfs pull -I DeepSEA/template/example_files/**\u001b[0m \u001b[32mINFO\u001b[0m \u001b[44m[kipoi.sources]\u001b[0m model DeepSEA/variantEffects loaded\u001b[0m \u001b[32mINFO\u001b[0m \u001b[44m[kipoi.sources]\u001b[0m git-lfs pull -I DeepSEA/variantEffects/./**\u001b[0m \u001b[32mINFO\u001b[0m \u001b[44m[kipoi.sources]\u001b[0m git-lfs pull -I DeepSEA/template/**\u001b[0m \u001b[32mINFO\u001b[0m \u001b[44m[kipoi.sources]\u001b[0m git-lfs pull -I DeepSEA/template/model_files/**\u001b[0m \u001b[32mINFO\u001b[0m \u001b[44m[kipoi.sources]\u001b[0m git-lfs pull -I DeepSEA/template/example_files/**\u001b[0m \u001b[32mINFO\u001b[0m \u001b[44m[kipoi.sources]\u001b[0m dataloader DeepSEA/variantEffects/. loaded\u001b[0m \u001b[32mINFO\u001b[0m \u001b[44m[kipoi.data]\u001b[0m successfully loaded the dataloader from /nfs/research1/stegle/users/rkreuzhu/.kipoi/models/DeepSEA/variantEffects/dataloader.py::SeqDataset\u001b[0m \u001b[32mINFO\u001b[0m \u001b[44m[kipoi.pipeline]\u001b[0m dataloader.output_schema is compatible with model.schema\u001b[0m 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 14/14 [00:35<00:00, 2.53s/it]","title":"Command-line based effect prediction"},{"location":"tutorials/variant_effect_prediction/#batch-prediction","text":"Since the syntax basically doesn't change for different kinds of models a simple for-loop can be written to do what we just did on many models: import kipoi # Run effect predicton models_df = kipoi.list_models() models_substr = [\"HAL\", \"MaxEntScan\", \"labranchor\", \"rbp\"] models_df_subsets = {ms: models_df.loc[models_df[\"model\"].str.contains(ms)] for ms in models_substr} /nfs/research1/stegle/users/rkreuzhu/opt/model-zoo/kipoi/config.py:110: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version of pandas will change to not sort by default. To accept the future behavior, pass 'sort=False'. To retain the current behavior and silence the warning, pass 'sort=True'. return pd.concat(pd_list)[pd_list[0].columns] # Run variant effect prediction using a basic Diff import kipoi from kipoi_veff import ensure_tabixed_vcf import kipoi_veff.snv_predict as sp from kipoi_veff import VcfWriter from kipoi_veff.scores import Diff splicing_dl_args = {\"gtf_file\":\"example_data/Homo_sapiens.GRCh37.75.filtered_chr22.gtf\", \"fasta_file\": \"example_data/hg19_chr22.fa\"} dataloader_args_dict = {\"HAL\": splicing_dl_args, \"labranchor\": splicing_dl_args, \"MaxEntScan\":splicing_dl_args, \"rbp\": {\"fasta_file\": \"example_data/hg19_chr22.fa\", \"gtf_file\":\"example_data/Homo_sapiens.GRCh37.75_chr22.gtf\"} } for ms in models_substr: model_name = models_df_subsets[ms][\"model\"].iloc[0] #kipoi.pipeline.install_model_requirements(model_name) model = kipoi.get_model(model_name) vcf_path = \"example_data/clinvar_donor_acceptor_chr22.vcf\" vcf_path_tbx = ensure_tabixed_vcf(vcf_path) out_vcf_fpath = vcf_path[:-4] + \"%s.vcf\"%model_name.replace(\"/\", \"_\") writer = VcfWriter(model, vcf_path, out_vcf_fpath) print(model_name) Dataloader = kipoi.get_dataloader_factory(model_name) dataloader_arguments = dataloader_args_dict[ms] model_info = kipoi_veff.ModelInfoExtractor(model, Dataloader) vcf_to_region = None if ms == \"rbp\": vcf_to_region = kipoi_veff.SnvCenteredRg(model_info) sp.predict_snvs(model, Dataloader, vcf_path_tbx, batch_size = 32, dataloader_args=dataloader_arguments, vcf_to_region=vcf_to_region, evaluation_function_kwargs={'diff_types': {'diff': Diff(\"mean\")}}, sync_pred_writer=writer) writer.close() HAL 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 709/709 [00:04<00:00, 167.58it/s] MaxEntScan/3prime 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 709/709 [00:02<00:00, 329.18it/s] Using TensorFlow backend. WARNING:tensorflow:From /nfs/research1/stegle/users/rkreuzhu/conda-envs/kipoi_interpret/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1238: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version. Instructions for updating: keep_dims is deprecated, use keepdims instead WARNING:tensorflow:From /nfs/research1/stegle/users/rkreuzhu/conda-envs/kipoi_interpret/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1340: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version. Instructions for updating: keep_dims is deprecated, use keepdims instead /nfs/research1/stegle/users/rkreuzhu/conda-envs/kipoi_interpret/lib/python3.6/site-packages/keras/models.py:287: UserWarning: Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer. warnings.warn('Error in loading the saved optimizer ' labranchor 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 709/709 [00:05<00:00, 122.95it/s] 2018-07-25 11:37:28,705 [INFO] successfully loaded the dataloader from /nfs/research1/stegle/users/rkreuzhu/.kipoi/models/rbp_eclip/AARS/dataloader.py::SeqDistDataset WARNING:tensorflow:From /nfs/research1/stegle/users/rkreuzhu/conda-envs/kipoi_interpret/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1255: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version. Instructions for updating: keep_dims is deprecated, use keepdims instead 2018-07-25 11:37:28,851 [WARNING] From /nfs/research1/stegle/users/rkreuzhu/conda-envs/kipoi_interpret/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1255: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version. Instructions for updating: keep_dims is deprecated, use keepdims instead /nfs/research1/stegle/users/rkreuzhu/conda-envs/kipoi_interpret/lib/python3.6/site-packages/keras/models.py:287: UserWarning: Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer. warnings.warn('Error in loading the saved optimizer ' 2018-07-25 11:37:30,996 [INFO] successfully loaded the model from model_files/model.h5 2018-07-25 11:37:30,999 [INFO] dataloader.output_schema is compatible with model.schema 2018-07-25 11:37:31,157 [INFO] git-lfs pull -I rbp_eclip/AARS/** rbp_eclip/AARS 2018-07-25 11:37:32,071 [INFO] git-lfs pull -I rbp_eclip/template/** 2018-07-25 11:37:33,219 [INFO] dataloader rbp_eclip/AARS loaded 2018-07-25 11:37:33,252 [INFO] successfully loaded the dataloader from /nfs/research1/stegle/users/rkreuzhu/.kipoi/models/rbp_eclip/AARS/dataloader.py::SeqDistDataset 2018-07-25 11:37:34,411 [INFO] Extracted GTF attributes: ['gene_id', 'gene_name', 'gene_source', 'gene_biotype', 'transcript_id', 'transcript_name', 'transcript_source', 'exon_number', 'exon_id', 'tag', 'protein_id', 'ccds_id'] /nfs/research1/stegle/users/rkreuzhu/conda-envs/kipoi_interpret/lib/python3.6/site-packages/sklearn/base.py:311: UserWarning: Trying to unpickle estimator MinMaxScaler from version 0.18.1 when using version 0.19.1. This might lead to breaking code or invalid results. Use at your own risk. UserWarning) /nfs/research1/stegle/users/rkreuzhu/conda-envs/kipoi_interpret/lib/python3.6/site-packages/sklearn/base.py:311: UserWarning: Trying to unpickle estimator Imputer from version 0.18.1 when using version 0.19.1. This might lead to breaking code or invalid results. Use at your own risk. UserWarning) 0%| | 0/14 [00:00<?, ?it/s]INFO:2018-07-25 11:37:34,812:genomelake] Running landmark extractors.. 2018-07-25 11:37:34,812 [INFO] Running landmark extractors.. /nfs/research1/stegle/users/rkreuzhu/conda-envs/kipoi_interpret/lib/python3.6/site-packages/concise/utils/position.py:55: FutureWarning: from_items is deprecated. Please use DataFrame.from_dict(dict(items), ...) instead. DataFrame.from_dict(OrderedDict(items)) may be used to preserve the key order. (\"strand\", gtf.strand)]) /nfs/research1/stegle/users/rkreuzhu/conda-envs/kipoi_interpret/lib/python3.6/site-packages/concise/utils/position.py:62: FutureWarning: from_items is deprecated. Please use DataFrame.from_dict(dict(items), ...) instead. DataFrame.from_dict(OrderedDict(items)) may be used to preserve the key order. (\"strand\", gtf.strand)]) INFO:2018-07-25 11:37:34,975:genomelake] Done! 2018-07-25 11:37:34,975 [INFO] Done! 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 14/14 [00:03<00:00, 4.05it/s] let's validate that things have worked: ! wc -l example_data/clinvar_donor_acceptor_chr22*.vcf 450 example_data/clinvar_donor_acceptor_chr22DeepSEA_variantEffects.vcf 2035 example_data/clinvar_donor_acceptor_chr22HAL.vcf 794 example_data/clinvar_donor_acceptor_chr22labranchor.vcf 1176 example_data/clinvar_donor_acceptor_chr22MaxEntScan_3prime.vcf 449 example_data/clinvar_donor_acceptor_chr22rbp_eclip_AARS.vcf 447 example_data/clinvar_donor_acceptor_chr22.vcf 5351 total","title":"Batch prediction"},{"location":"tutorials/variant_effect_prediction_simple/","text":"Generated from notebooks/variant_effect_prediction_simple.ipynb Variant effect prediction - simple NOTE: This notebook is a companion notebook to variant_effect_prediction.ipynb and shows a simpler way to run variant effect predictions in python. If you want to know more details about variant effect prediction, the details of how to customise things and how to run it on the command line and in batch please refer to the variant_effect_prediction.ipynb . Variant effect prediction offers a simple way to predict effects of SNVs using any model that uses DNA sequence as an input. Many different scoring methods can be chosen, but the principle relies on in-silico mutagenesis. The default input is a VCF and the default output again is a VCF annotated with predictions of variant effects. First we set up the model and make sure the requirements are installed in the current environment. import kipoi model_name = \"DeepSEA/variantEffects\" Then we need to know where the query VCF is located and where we want to store the results. # The input vcf path vcf_path = \"example_data/clinvar_donor_acceptor_chr22.vcf\" # The output vcf path, based on the input file name out_vcf_fpath = vcf_path[:-4] + \"%s.vcf\"%model_name.replace(\"/\", \"_\") Finally the dataloader arguments are set that are required to run the dataloader. Here we omit the intervals_file argument of the dataloader, because that has been tagged as bed file input in the dataloader.yaml file, which means that score_variants will automatically populate that argument with a temporary bed file that is generated from the VCF in order to query every variant contained in the input VCF. (\"Variant-centered approach\") # The datalaoder keyword arguments dataloader_arguments = {\"fasta_file\": \"example_data/hg19_chr22.fa\"} !ls example_data/ chr22.101bp.2000_intervals.JUND.HepG2.tsv clinvar_donor_acceptor_annotated_chr22.csv clinvar_donor_acceptor_annotated_w_rbp_chr22.csv clinvar_donor_acceptor_chr22DeepSEA_variantEffects.vcf clinvar_donor_acceptor_chr22.vcf clinvar_donor_acceptor_chr22.vcf.gz clinvar_donor_acceptor_chr22.vcf.gz.tbi dbsnp_chr22_29108009.vcf hg19_chr22.fa hg19_chr22.fa.fai Homo_sapiens.GRCh37.75_chr22.gtf Homo_sapiens.GRCh37.75.filtered_chr22.gtf import kipoi_veff.snv_predict as sp sp.score_variants(model = model_name, dl_args = dataloader_arguments, input_vcf = vcf_path, output_vcf = out_vcf_fpath) 29%|\u2588\u2588\u258a | 4/14 [00:11<00:28, 2.83s/it] Now we can have a look at the generated output: # Let's print out the first 40 lines of the annotated VCF (up to 80 characters per line maximum) with open(\"example_data/clinvar_donor_acceptor_chr22DeepSEA_variantEffects.vcf\") as ifh: for i,l in enumerate(ifh): long_line = \"\" if len(l)>80: long_line = \"...\" print(l[:80].rstrip() +long_line) if i >=40: break Here we have shown a simpler function score_variants that covers most use-cases for variant effect prediction. For a more fine-grain control please use predict_snvs and take a look at the variant_effect_prediction.ipynb notebook. An important thing to remember when using score_variants or the command-line interface is that for all dataloaders that support bed-file inputs, the bed file generation will be used and only model that do not have the postprocessing > variant_effects > bed_input field set in dataloader.yaml will be executed in overlap-based mode. For details on how variant region overlap works please take a look at the variant effect prediction documentation.","title":"Simple"},{"location":"tutorials/variant_effect_prediction_simple/#variant-effect-prediction-simple","text":"NOTE: This notebook is a companion notebook to variant_effect_prediction.ipynb and shows a simpler way to run variant effect predictions in python. If you want to know more details about variant effect prediction, the details of how to customise things and how to run it on the command line and in batch please refer to the variant_effect_prediction.ipynb . Variant effect prediction offers a simple way to predict effects of SNVs using any model that uses DNA sequence as an input. Many different scoring methods can be chosen, but the principle relies on in-silico mutagenesis. The default input is a VCF and the default output again is a VCF annotated with predictions of variant effects. First we set up the model and make sure the requirements are installed in the current environment. import kipoi model_name = \"DeepSEA/variantEffects\" Then we need to know where the query VCF is located and where we want to store the results. # The input vcf path vcf_path = \"example_data/clinvar_donor_acceptor_chr22.vcf\" # The output vcf path, based on the input file name out_vcf_fpath = vcf_path[:-4] + \"%s.vcf\"%model_name.replace(\"/\", \"_\") Finally the dataloader arguments are set that are required to run the dataloader. Here we omit the intervals_file argument of the dataloader, because that has been tagged as bed file input in the dataloader.yaml file, which means that score_variants will automatically populate that argument with a temporary bed file that is generated from the VCF in order to query every variant contained in the input VCF. (\"Variant-centered approach\") # The datalaoder keyword arguments dataloader_arguments = {\"fasta_file\": \"example_data/hg19_chr22.fa\"} !ls example_data/ chr22.101bp.2000_intervals.JUND.HepG2.tsv clinvar_donor_acceptor_annotated_chr22.csv clinvar_donor_acceptor_annotated_w_rbp_chr22.csv clinvar_donor_acceptor_chr22DeepSEA_variantEffects.vcf clinvar_donor_acceptor_chr22.vcf clinvar_donor_acceptor_chr22.vcf.gz clinvar_donor_acceptor_chr22.vcf.gz.tbi dbsnp_chr22_29108009.vcf hg19_chr22.fa hg19_chr22.fa.fai Homo_sapiens.GRCh37.75_chr22.gtf Homo_sapiens.GRCh37.75.filtered_chr22.gtf import kipoi_veff.snv_predict as sp sp.score_variants(model = model_name, dl_args = dataloader_arguments, input_vcf = vcf_path, output_vcf = out_vcf_fpath) 29%|\u2588\u2588\u258a | 4/14 [00:11<00:28, 2.83s/it] Now we can have a look at the generated output: # Let's print out the first 40 lines of the annotated VCF (up to 80 characters per line maximum) with open(\"example_data/clinvar_donor_acceptor_chr22DeepSEA_variantEffects.vcf\") as ifh: for i,l in enumerate(ifh): long_line = \"\" if len(l)>80: long_line = \"...\" print(l[:80].rstrip() +long_line) if i >=40: break Here we have shown a simpler function score_variants that covers most use-cases for variant effect prediction. For a more fine-grain control please use predict_snvs and take a look at the variant_effect_prediction.ipynb notebook. An important thing to remember when using score_variants or the command-line interface is that for all dataloaders that support bed-file inputs, the bed file generation will be used and only model that do not have the postprocessing > variant_effects > bed_input field set in dataloader.yaml will be executed in overlap-based mode. For details on how variant region overlap works please take a look at the variant effect prediction documentation.","title":"Variant effect prediction - simple"}]}